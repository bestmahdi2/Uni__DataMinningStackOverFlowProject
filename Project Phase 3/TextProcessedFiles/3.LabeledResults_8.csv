QuestionId,QuestionTitle,QuestionBody,QuestionTags,QuestionBodyLength,URLImageCount,LOC,UserReputation,UserGoldBadges,UserSilverBadges,UserBronzeBadges,QuestionAcceptRate,QuestionViewCount,QuestionFavoriteCount,UserUpVoteCount,QuestionAnswersCount,QuestionScore,QuestionCreationDate,FirstAnswerCreationDate,AcceptedAnswerCreationDate,FirstAnswerIntervalDays,AcceptedAnswerIntervalDays,QuestionLabel,QuestionLabelDefinition
53641403,Search in Json column with Laravel,"In my emails table, I have a column named To with column-type Json. This is how values are stored:
[
    {
        ""emailAddress"": {
            ""name"": ""Test"", 
            ""address"": ""test@example.com""
        }
    }, 
    {
        ""emailAddress"": {
            ""name"": ""Test 2"", 
            ""address"": ""test2@example.com""
        }
    }
]
Now I want a collection of all emails sent to ""test@example.com"". I tried:
DB::table('emails')-&gt;whereJsonContains('to-&gt;emailAddress-&gt;address', 'test@example.com')-&gt;get();
(see https://laravel.com/docs/5.7/queries#json-where-clauses)
but I do not get a match. Is there a better way to search using Laravel (Eloquent)?
In the debugbar, I can see that this query is ""translated"" as:
select * from `emails` where json_contains(`to`-&gt;'$.""emailAddress"".""address""', '\""test@example.com\""'))
",<php><mysql><json><laravel><laravel-5>,845,2,18,1571,3,21,43,44,49425,0.0,176,7,21,2018-12-05 21:59,2018-12-06 7:43,2018-12-06 15:27,1.0,1.0,Basic,7
52088355,FluentMySQL connection using Unix Socket,"I'm following the Getting started section for the MySQL package on the Vapor Documentation, which I'm able to follow step by step and, as a result, I have successfully established a connection to the MySQL database, using custom database credentials like this:
/// Register providers first
try services.register(FluentMySQLProvider())
// MySQL database
let mySQLConfig = MySQLDatabaseConfig(hostname: ""localhost"",
                                      port: 3306,
                                      username: ""root"",
                                      password: ""thisismyrootpassword"",
                                      database: ""lol_database"",
                                      capabilities: .default,
                                      characterSet: MySQLCharacterSet.utf8_general_ci,
                                      transport: MySQLTransportConfig.cleartext)
services.register(mySQLConfig)
Based on the MySQLDatabaseConfig object's documentation I'm unable to find if it is possible to connect to a MySQL database based on a Unix Socket configuration.
What I'll be able to provide to the application under the production environment it's just the database name, the username, password and the Socket path, which will be in the form /cloudsql/project1:us-central1:instance1
For more reference, what I'm trying to do is connect from a Google Cloud App Engine flexible environment to a SQL database based on this tutorial: https://cloud.google.com/appengine/docs/flexible/nodejs/using-cloud-sql#setting_up_your_local_environment The environment of course will be Vapor still that's the only way for a database client to establish connection to the database server.
Thank you for your help.
",<mysql><swift><vapor>,1714,4,16,1509,2,19,27,38,335,0.0,821,1,21,2018-08-30 2:17,2021-07-09 0:32,2021-07-09 0:32,1044.0,1044.0,Basic,3
58233866,SQLSTATE[HY000] [1045] Access denied for user 'root'@'localhost' (using password: NO) . DB_HOST set to localhost,"I moved the Laravel project from localhost to server. Which I have done every step on the server.
I am able to view the login page on my server. The problem is I am not able to connect with my MySQL server.
My .env file:
APP_NAME=Transport
APP_ENV=local
APP_KEY=base64:mrakeyidharhaikonsdf
APP_DEBUG=true
APP_URL=http://localhost
LOG_CHANNEL=stack
DB_CONNECTION=mysql
DB_HOST=localhost
DB_PORT=3306
DB_DATABASE=transport_db
DB_USERNAME=root
DB_PASSWORD=mypass
I tried to change the host to 127.0.0.1 and also tried to put my server's IP address. It didn't helped me. Am I missing something?
My error:
SQLSTATE[HY000] [1045] Access denied for user 'root'@'localhost' (using password: NO) (SQL: select count(*) as aggregate from users where email = user.email@gmail.com)
I know this question may have answers already on Stack Overflow. But I have different issue here.
",<php><mysql><laravel><laravel-6>,867,1,18,1603,2,17,34,45,170223,0.0,650,16,21,2019-10-04 9:46,2019-10-04 10:16,2019-10-04 10:17,0.0,0.0,Basic,6
48053955,Alembic Migrations on Multiple Models,"I am attempting to create a revision with --autogenerate using Alembic for two Models, but am receiving a duplicate table keys error. Does, a schema need to be specified?  If so, how can it be set?  The documentation I've read says to use __table_args__ = {'schema': 'somename'}, but that hasn't helped.  Any tips or suggestions are greatly appreciated.
My current setup is:
base.py
from sqlalchemy.ext.declarative import declarative_base
Base = declarative_base()
workspace.py
from sqlalchemy import Column, Integer, String
from base import Base
class WorkspaceModel(Base):
    __tablename__ = 'workspaces'
    id = Column(Integer, primary_key=True)
    name = Column(String)
host.py
from sqlalchemy import Column, Integer, String
from base import Base
class HostModel(Base):
    __tablename__ = 'hosts'
    id = Column(Integer, primary_key=true)
    ip = Column(String)
alembic/env.py
from host import HostModel
from workspace import WorkspaceModel
target_metadata = [HostModel.metadata, WorkspaceModel.metadata]
Error
ValueError: Duplicate table keys across multiple MetaData objects: ""hosts"", ""workspaces""
",<python><sqlalchemy><alembic>,1110,0,26,4468,2,29,39,66,10030,0.0,136,3,21,2018-01-01 22:59,2020-02-25 6:14,2020-07-15 23:34,785.0,926.0,Basic,6
59582390,Confusion Around Creating a VPC Access Connector,"I am trying to set up Serverless VPC access
  Serverless VPC Access enables you to connect from your Cloud Functions directly to Compute Engine VM instances, Memorystore instances, Cloud SQL instances,
Sounds great. But the documentation is not super friendly to a beginner. Step 2 is to create a connector, about which I have a couple of questions:
  In the Network field, select the VPC network to connect to.
My dropdown here contains only ""Default"". Is this normal? What should IO expect to see here?
  In the IP range field, enter an unused CIDR /28 IP range. Addresses in this range are used as source addresses for traffic sent through the connector. This IP range must not overlap with any existing IP address reservations in your VPC network.
I don't know what to do here. I tried using the information in the linked document to first) enter an IP from the region I had selected, and, second) enter an IP from outside that region. Both resulted in connectors that were created with the error. ""Connector is in a bad state, manual deletion is recommended""
The documentation continues with a couple of troubleshooting steps if the creation fails:
  Specify an IP range that does not overlap with any existing IP address reservations in the VPC network.
I don't know what this means. Maybe like, if I have other connectors I should be sure the IP range for the new one doesn't overlap with those. That's just a guess, but anyway I have none.
  Grant your project permission to use Compute Engine VM images from the project with ID serverless-vpc-access-images. See Setting image access constraints for information on how to update your organization policy accordingly.
This leads me to another document about updating my organization's ""Image Policy"". This one has me so out of my depth, I don't even think I should be here.
This has all started with just wanting to connect to a SQL Server instance from Firebase. Creating the VPC connector seems like a good step, but I've just fallen at every hurdle. Can a cloud-dweller please help me with a few of these points of confusion? 
",<google-cloud-platform><cloud><google-cloud-sql><vpc>,2087,4,1,14803,32,109,235,56,12457,0.0,2623,3,21,2020-01-03 16:56,2020-01-04 4:10,,1.0,,Basic,3
58676909,How to speed up spark df.write jdbc to postgres database?,"I am new to spark and am attempting to speed up appending the contents of a dataframe, (that can have between 200k and 2M rows) to a postgres database using df.write:
df.write.format('jdbc').options(
      url=psql_url_spark,
      driver=spark_env['PSQL_DRIVER'],
      dbtable=""{schema}.{table}"".format(schema=schema, table=table),
      user=spark_env['PSQL_USER'],
      password=spark_env['PSQL_PASS'],
      batchsize=2000000,
      queryTimeout=690
      ).mode(mode).save()
I tried increasing the batchsize but that didn't help, as completing this task still took ~4hours. I've also included some snapshots below from aws emr showing more details about how the job ran. The task to save the dataframe to the postgres table was only assigned to one executor (which I found strange), would speeding this up involve dividing this task between executors?
Also, I have read spark's performance tuning docs but increasing the batchsize, and queryTimeout have not seemed to improve performance. (I tried calling df.cache() in my script before df.write, but runtime for the script was still 4hrs)
Additionally, my aws emr hardware setup and spark-submit are:
Master Node (1): m4.xlarge
Core Nodes (2): m5.xlarge
spark-submit --deploy-mode client --executor-cores 4 --num-executors 4 ...
",<postgresql><apache-spark><pyspark><apache-spark-sql>,1287,3,15,1040,1,15,44,41,19782,0.0,57,4,21,2019-11-03 2:15,2020-04-25 22:10,2020-04-26 8:59,174.0,175.0,Intermediate,23
50945477,Count rows in partition with Order By,"I was trying to understand PARTITION BY in postgres by writing a few sample queries. I have a test table on which I run my query.
id integer | num integer
___________|_____________
1          | 4 
2          | 4
3          | 5
4          | 6
When I run the following query, I get the output as I expected.
SELECT id, COUNT(id) OVER(PARTITION BY num) from test;
id         | count
___________|_____________
1          | 2 
2          | 2
3          | 1
4          | 1
But, when I add ORDER BY to the partition,
SELECT id, COUNT(id) OVER(PARTITION BY num ORDER BY id) from test;
id         | count
___________|_____________
1          | 1 
2          | 2
3          | 1
4          | 1
My understanding is that COUNT is computed across all rows that fall into a partition. Here, I have partitioned the rows by num. The number of rows in the partition is the same, with or without an ORDER BY clause. Why is there a difference in the outputs?
",<sql><postgresql><window-functions>,939,0,22,612,3,7,13,80,54789,0.0,352,3,21,2018-06-20 10:00,2018-06-20 10:18,2018-06-20 10:18,0.0,0.0,Basic,3
52355143,Is it possible to delete old records from clickhouse table?,"As far as I know, clickhouse allows only inserting new data. But is it possible to delete block older then some period to avoid overflow of HDD?
",<sql><clickhouse>,145,0,0,8840,28,117,207,76,39391,0.0,2932,3,21,2018-09-16 14:36,2018-10-05 14:27,2018-10-23 9:05,19.0,37.0,Basic,3
63997315,UNION types text and bigint cannot be matched,"I'm running a complex stored procedure and I'm getting an error when I have 3 unions, but with 2 unions no error. If I remove either of the top two unions it runs fine. If I make one of the NULLs a 0, it runs fine. The error is &quot;UNION types text and bigint cannot be matched&quot;
```lang-sql
SELECT NULL AS total_time_spent 
FROM tbl1
GROUP BY student_id 
UNION ALL 
SELECT NULL AS total_time_spent
FROM tbl2
GROUP BY student_id 
UNION ALL 
SELECT sum(cast((&quot;value&quot; -&gt;&gt; 'seconds') AS integer)) AS total_time_spent 
FROM tbl3 
GROUP BY student_id
```
I've tried all kinds of casting on the sum result or the sum input. The json that I'm pulling from is either NULL, [] or something like this:
[{&quot;date&quot;: &quot;2020-09-17&quot;, &quot;seconds&quot;: 458}]
",<postgresql><union-all>,785,0,14,1643,5,21,41,54,43648,0.0,73,1,21,2020-09-21 17:34,2020-09-22 2:21,2020-09-22 2:21,1.0,1.0,Basic,2
55825283,How to convert array to string in laravel?,"I am getting input from checkbox values in array using bootstrap form.
I am using array for storing checkbox values. How i convert this array to string . Because database only take string values.
Here is my code
&lt;div class=""form-group col-md-12""&gt;
    &lt;div class=""custom-control custom-checkbox custom-control-inline""&gt;
        &lt;input type=""checkbox"" id=""eduPrimary"" name=""education[]"" 
        class=""custom-control-input"" value=""primary"" /&gt;
        &lt;label class=""custom-control-label"" for=""eduPrimary""&gt;primary&lt;/label&gt;
    &lt;/div&gt;
&lt;/div&gt;
&lt;div class=""form-group col-md-12""&gt;
    &lt;div class=""custom-control custom-checkbox custom-control-inline""&gt;
        &lt;input type=""checkbox"" id=""eduSecondary"" name=""education[]"" 
        class=""custom-control-input"" value=""secondary"" /&gt;
        &lt;label class=""custom-control-label"" for=""eduSecondary""&gt;secondary&lt;/label&gt;
    &lt;/div&gt;
&lt;/div&gt;
&lt;div class=""form-group col-md-12""&gt;
    &lt;div class=""custom-control custom-checkbox custom-control-inline""&gt;
        &lt;input type=""checkbox"" id=""eduUniversity"" name=""education[]"" 
        class=""custom-control-input"" value=""university"" /&gt;
        &lt;label class=""custom-control-label""for=""eduUniversity""&gt;university&lt;/label&gt;
    &lt;/div&gt;
&lt;/div&gt;
In backend i am using laravel to store values to database But it run error that storing array to string in mysql.
public function store(Request $request,AdProfile $adprofile)
{
    $adprofile-&gt;education = $request-&gt;education[];
    $adprofile-&gt;save();
    return redirect()-&gt;route('adprofile.profilecomplete');
}
",<php><mysql><laravel>,1654,0,27,792,1,6,17,78,99378,0.0,128,8,21,2019-04-24 8:11,2019-04-24 8:17,2019-04-24 9:59,0.0,0.0,Basic,2
61148791,PostgreSQL on Elastic Beanstalk (Amazon Linux 2),"With former generation of Amazon Linux, all I needed to do is add the following in .ebextensions in order to use PostgreSQL:
packages:
    yum:
        postgresql93-devel: []
Now when I deploy on EB with the following platform:
Python 3.7 running on 64bit Amazon Linux 2/3.0.0
I get the following error on deployment:
[ERROR] Error occurred during build: Yum does not have postgresql93-devel available for installation
Therefore it is impossible to deploy as I need to connect to a PostgreSQL database in RDS.
What config in .ebextensions do I need to do?
",<linux><postgresql><amazon-web-services><amazon-elastic-beanstalk><yum>,556,0,4,916,0,10,19,64,7173,0.0,73,4,21,2020-04-10 21:14,2020-04-10 21:22,2020-08-01 10:59,0.0,113.0,Basic,14
56022874,"BigQuery replaced most of my Spark jobs, am I missing something?","I've been developing Spark jobs for some years using on-premise clusters and our team recently moved to the Google Cloud Platform allowing us to leverage the power of BigQuery and such.
The thing is, I now often find myself writing processing steps in SQL more than in PySpark since it is : 
easier to reason about (less verbose)
easier to maintain (SQL vs scala/python code)
you can run it easily on the GUI if needed
fast without having to really reason about partitioning, caching and so on...
In the end, I only use Spark when I've got something to do that I can't express using SQL. 
To be clear, my workflow is often like : 
preprocessing (previously in Spark, now in SQL)
feature engineering (previously in Spark, now mainly in SQL)
machine learning model and predictions (Spark ML)
Am I missing something ?
Is there any con in using BigQuery this way instead of Spark ?
Thanks
",<sql><apache-spark><apache-spark-sql><google-bigquery><bigdata>,885,0,0,667,0,5,16,60,5633,0.0,1,2,20,2019-05-07 12:41,2019-07-31 23:26,,85.0,,Intermediate,20
50907968,Server is not configured for RPC,"Looking for my job history I foudn the error below:
06/18/2018 00:00:01,MBS_Lojas_ExportaMR_OutrasLojas,Error,1,WIN-VRT-01\SQL2008,MBS_Lojas_ExportaMR_OutrasLojas,Passo1,,Executed as user: WIN-VRT-01\integracao. Server 'x.y.z' is not configured for RPC. [SQLSTATE 42000] (Error 7411).  The step failed.,01:11:15,16,7411,,,,0
I have this linked server with the option RPC and RPC Out with the values assigned to true.
In the job I have this
EXEC master.dbo.sp_serveroption @server=N'x.y.z', @optname=N'rpc', @optvalue=N'true'
EXEC master.dbo.sp_serveroption @server=N'x.y.z', @optname=N'rpc out', @optvalue=N'true'
I can't find out why is this happening and none of the solutions posted for this error could help me to debug this issue.
",<sql-server>,736,0,3,840,2,8,27,41,47285,0.0,8,3,20,2018-06-18 10:59,2019-04-22 16:54,,308.0,,Basic,13
56503583,Error while installing SQL Server 2017 Express showing sqlncli.msi is missing in some path,"I am trying to install SQL Server 2017 Express, but it is throwing this error:
sqlncli.msi is not found in the path
Screenshot illustrating the sqlncli.msi error:
",<sql-server-2017-express>,163,1,0,265,1,3,12,45,18529,0.0,0,3,20,2019-06-08 5:01,2019-06-12 13:40,,4.0,,Basic,14
51893065,"PostgreSQL & BDR: Is BDR truly multi-master, is it Open Source and EOL for 1.x in 2019?","I am confused regarding PostgreSQL BDR and I have several questions:
Question 1: Is BDR truly multi-master for PostgreSQL?
According to the docs here, it says that:
  The BDR (Bi-Directional Replication) project adds multi-master
  replication to PostgreSQL 9.4
but if I read on 2ndQuadrant, I read the following:
If I read that part, they don't mention multi-master much at all; just that a ""second master, working in passive"", which indicates its not a real master?
Question 2: Is BDR open-source?
I read here that it is, at least that it was:
  BDR is the first open source multi-master replication system for PostgreSQL
Is it still? Because when I look, I am often directed to 2ndQuadrants webpage, and that gives me the impression that its not open-source, when they say that:
  How can you get Postgres-BDR?
  Just fill out the contact form below and a PostgreSQL expert will be in touch shortly!
Sounds like selling to me =)
Question 3: What version is what?
I read that 2ndQuadrant released version 1.0.5 in March this year. I also read on 2ndQuadrants webpage that
  In the complex environment of replication, the 3rd generation of BDR achieves...
The 3rd gen? Is version 1.0.5 that same 3rd gen, or is it something else?
Also, the same page says that:
  Note for current Postgres-BDR users: BDR 1.x  will reach EOL in December 2019. Our team of PostgreSQL experts can help plan and execute your upgrade with minimal impact and almost zero downtime. Contact us today and a member of our professional services team will be in touch with you as soon as possible.
So, 1.0.5 was released in March, but has EOL in December 2019? Is 2.x not open-source, so some license cost associated with it, and 1.x is EOL 2019?
",<postgresql><postgresql-bdr><postgres-bdr>,1719,4,0,19797,35,97,156,76,11323,0.0,615,3,20,2018-08-17 10:08,2018-08-24 10:50,2018-11-13 1:41,7.0,88.0,Intermediate,19
50828041,How to open database sqlite file on iPhone real device?,"I'm debbuging a app in my real device by cable. I've a iPhone 6. I want check my database and operate with sqlite3 to query my results. The other questions and tutorials explain to do this only in simulator but I'm using a real iPhone.
In AppDelegate, I prints the path of database:
print(NSSearchPathForDirectoriesInDomains(.documentDirectory, .userDomainMask, true).last! as String)
/Users/myname/Library/Developer/CoreSimulator/Devices/DAE93E57-7004-45F6-9B93-E79CA1AEEEFA/data/Containers/Data/Application/D7A4F27E-6F11-4941-A1B0-0337ABF788AB/Documents
So, I take the path and access from terminal and access my database with sqlite3 DatabaseFile
But when I debugging in my device, the path that's printed not works. I tried use the printed path
cd /var/mobile/Containers/Data/Application/3257D423-C198-41A5-B29D-B31E99F84F34/Documents
/usr/bin/CD: line 4: cd: /var/mobile/Containers/Data/Application/3257D423-C198-41A5-B29D-B31E99F84F34/Documents: No such file or directory
This error happens because this is of iOS system, I think.
",<ios><swift><xcode><sqlite>,1037,0,5,3905,9,45,100,55,14829,0.0,529,5,20,2018-06-13 1:45,2018-06-13 5:49,,0.0,,Basic,9
52000903,How to start flyway after database initialization in Docker,"I have following docker compose file(docker-compose-dev.yml):
version: '3'
services:
  my_sql_db:
    image: percona:latest
    container_name: my_sql_db
    environment:
      MYSQL_ROOT_PASSWORD: password
      MYSQL_DATABASE: abhs
    ports:
    - ""3306:3306""
  migration:
    image: boxfuse/flyway:latest
    container_name: flyway_migration
    volumes:
      - ./flyway_scripts/src/main/resources/db/migration:/flyway/sql
    command: -url=jdbc:mysql://my_sql_db:3306/abhs?useUnicode=true&amp;characterEncoding=utf8&amp;useSSL=false -user=root -password=password migrate
    depends_on:
    - my_sql_db
and following docker-compose.yml:
version: '3'
services:
  migration:
    image: boxfuse/flyway:latest
    container_name: flyway_migration
    volumes:
     - ./flyway_scripts/src/main/resources/db/migration:/flyway/sql
Then I execute following command:
docker-compose -f docker-compose.yml -f docker-compose-dev.yml up
And It lead to error:
In logs I see following:
my_sql_db    | Initializing database
flyway_migration  | Flyway Community Edition 5.1.4 by Boxfuse
flyway_migration  |
my_sql_db    | 2018-08-24T08:47:41.616694Z 0 [Warning] 'NO_ZERO_DATE', 'NO_ZERO_IN_DATE' and 'ERROR_FOR_DIVISION_BY_ZERO' sql modes should be used with strict mode. They will be merged with strict mode in a future release.
my_sql_db    | 2018-08-24T08:47:41.616747Z 0 [Warning] 'NO_AUTO_CREATE_USER' sql mode was not set.
flyway_migration  | ERROR:
flyway_migration  | Unable to obtain connection from database (jdbc:mysql://my_sql_db:3306/abhs?useUnicode=true&amp;characterEncoding=utf8&amp;useSSL=false) for user 'root': Could not connect to address=(host=my_sql_db)(port=3306)(type=master) : Connection refused (Connection refused)
flyway_migration  | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
flyway_migration  | SQL State  : 08
flyway_migration  | Error Code : -1
flyway_migration  | Message    : Could not connect to address=(host=my_sql_db)(port=3306)(type=master) : Connection refused (Connection refused)
my_sql_db    | 2018-08-24T08:47:43.024690Z 0 [Warning] InnoDB: New log files created, LSN=45790
flyway_migration  |
my_sql_db    | 2018-08-24T08:47:43.443625Z 0 [Warning] InnoDB: Creating foreign key constraint system tables.
my_sql_db    | 2018-08-24T08:47:43.588008Z 0 [Warning] No existing UUID has been found, so we assume that this is the first time that this server has been started. Generating a new UUID: 5dc59a4f-a77a-11e8-b6cb-0242ac130002.
my_sql_db    | 2018-08-24T08:47:43.760654Z 0 [Warning] Gtid table is not ready to be used. Table 'mysql.gtid_executed' cannot be opened.
my_sql_db    | 2018-08-24T08:47:44.518107Z 0 [Warning] CA certificate ca.pem is self signed.
my_sql_db    | 2018-08-24T08:47:44.925466Z 1 [Warning] root@localhost is created with an empty password ! Please consider switching off the --initialize-insecure option.
my_sql_db    | 2018-08-24T08:47:54.762213Z 1 [Warning] 'user' entry 'root@localhost' ignored in --skip-name-resolve mode.
my_sql_db    | 2018-08-24T08:47:54.762517Z 1 [Warning] 'user' entry 'mysql.session@localhost' ignored in --skip-name-resolve mode.
my_sql_db    | 2018-08-24T08:47:54.762889Z 1 [Warning] 'user' entry 'mysql.sys@localhost' ignored in --skip-name-resolve mode.
my_sql_db    | 2018-08-24T08:47:54.763244Z 1 [Warning] 'db' entry 'performance_schema mysql.session@localhost' ignored in --skip-name-resolve mode.
my_sql_db    | 2018-08-24T08:47:54.763472Z 1 [Warning] 'db' entry 'sys mysql.sys@localhost' ignored in --skip-name-resolve mode.
my_sql_db    | 2018-08-24T08:47:54.763788Z 1 [Warning] 'proxies_priv' entry '@ root@localhost' ignored in --skip-name-resolve mode.
my_sql_db    | 2018-08-24T08:47:54.763928Z 1 [Warning] 'tables_priv' entry 'user mysql.session@localhost' ignored in --skip-name-resolve mode.
my_sql_db    | 2018-08-24T08:47:54.764128Z 1 [Warning] 'tables_priv' entry 'sys_config mysql.sys@localhost' ignored in --skip-name-resolve mode.
my_sql_db    | Database initialized
my_sql_db    | MySQL init process in progress...
my_sql_db    | 2018-08-24T08:47:58.970290Z 0 [Warning] 'NO_ZERO_DATE', 'NO_ZERO_IN_DATE' and 'ERROR_FOR_DIVISION_BY_ZERO' sql modes should be used with strict mode. They will be merged with strict mode in a future release.
my_sql_db    | 2018-08-24T08:47:58.970345Z 0 [Warning] 'NO_AUTO_CREATE_USER' sql mode was not set.
my_sql_db    | 2018-08-24T08:47:58.974061Z 0 [Note] mysqld (mysqld 5.7.22-22) starting as process 58 ...
my_sql_db    | 2018-08-24T08:47:58.999651Z 0 [Note] InnoDB: PUNCH HOLE support available
my_sql_db    | 2018-08-24T08:47:58.999685Z 0 [Note] InnoDB: Mutexes and rw_locks use GCC atomic builtins
my_sql_db    | 2018-08-24T08:47:58.999689Z 0 [Note] InnoDB: Uses event mutexes
my_sql_db    | 2018-08-24T08:47:58.999692Z 0 [Note] InnoDB: GCC builtin __atomic_thread_fence() is used for memory barrier
my_sql_db    | 2018-08-24T08:47:58.999695Z 0 [Note] InnoDB: Compressed tables use zlib 1.2.8
my_sql_db    | 2018-08-24T08:47:58.999698Z 0 [Note] InnoDB: Using Linux native AIO
my_sql_db    | 2018-08-24T08:47:59.000153Z 0 [Note] InnoDB: Number of pools: 1
my_sql_db    | 2018-08-24T08:47:59.000426Z 0 [Note] InnoDB: Using CPU crc32 instructions
my_sql_db    | 2018-08-24T08:47:59.002306Z 0 [Note] InnoDB: Initializing buffer pool, total size = 128M, instances = 1, chunk size = 128M
my_sql_db    | 2018-08-24T08:47:59.006893Z 0 [Note] InnoDB: Completed initialization of buffer pool
my_sql_db    | 2018-08-24T08:47:59.013219Z 0 [Note] InnoDB: If the mysqld execution user is authorized, page cleaner thread priority can be changed. See the man page of setpriority().
my_sql_db    | 2018-08-24T08:47:59.024242Z 0 [Note] InnoDB: Crash recovery did not find the parallel doublewrite buffer at /var/lib/mysql/xb_doublewrite
my_sql_db    | 2018-08-24T08:47:59.026263Z 0 [Note] InnoDB: Highest supported file format is Barracuda.
my_sql_db    | 2018-08-24T08:47:59.066469Z 0 [Note] InnoDB: Created parallel doublewrite buffer at /var/lib/mysql/xb_doublewrite, size 3932160 bytes
my_sql_db    | 2018-08-24T08:47:59.071752Z 0 [Note] InnoDB: Creating shared tablespace for temporary tables
my_sql_db    | 2018-08-24T08:47:59.072052Z 0 [Note] InnoDB: Setting file './ibtmp1' size to 12 MB. Physically writing the file full; Please wait ...
my_sql_db    | 2018-08-24T08:47:59.422155Z 0 [Note] InnoDB: File './ibtmp1' size is now 12 MB.
my_sql_db    | 2018-08-24T08:47:59.423325Z 0 [Note] InnoDB: 96 redo rollback segment(s) found. 96 redo rollback segment(s) are active.
my_sql_db    | 2018-08-24T08:47:59.423376Z 0 [Note] InnoDB: 32 non-redo rollback segment(s) are active.
my_sql_db    | 2018-08-24T08:47:59.423900Z 0 [Note] InnoDB: Waiting for purge to start
my_sql_db    | 2018-08-24T08:47:59.474066Z 0 [Note] InnoDB: Percona XtraDB (http://www.percona.com) 5.7.22-22 started; log sequence number 2595255
my_sql_db    | 2018-08-24T08:47:59.474647Z 0 [Note] Plugin 'FEDERATED' is disabled.
my_sql_db    | 2018-08-24T08:47:59.499970Z 0 [Note] Found ca.pem, server-cert.pem and server-key.pem in data directory. Trying to enable SSL support using them.
my_sql_db    | 2018-08-24T08:47:59.500004Z 0 [Note] Skipping generation of SSL certificates as certificate files are present in data directory.
my_sql_db    | 2018-08-24T08:47:59.500382Z 0 [Note] InnoDB: Loading buffer pool(s) from /var/lib/mysql/ib_buffer_pool
my_sql_db    | 2018-08-24T08:47:59.501263Z 0 [Warning] CA certificate ca.pem is self signed.
my_sql_db    | 2018-08-24T08:47:59.522151Z 0 [Note] Skipping generation of RSA key pair as key files are present in data directory.
my_sql_db    | 2018-08-24T08:47:59.531657Z 0 [Note] InnoDB: Buffer pool(s) load completed at 180824  8:47:59
Looks like flyway starts before database initialization and hence could not connect to database and I see the error below.
How can I fix that problem?
P.S.
I googled similar questions and I found the following piece of advice: https://github.com/vishnubob/wait-for-it but I am novice in docker  and I don't understand how to put it into my docker compose file
P.S.2
I tried to put file wait-fot-it.sh near the compose file and execute:
command: [""./wait-for-it.sh"", ""mysql:3306"", ""--"", ""-url=jdbc:mysql://my_sql_db:3306/abhs?useUnicode=true&amp;characterEncoding=utf8&amp;useSSL=false -user=root -password=password migrate""]
But I returns ERROR: Invalid argument: ./wait-for-it.sh
P.S.3
I tried approach from ""Duplicated"" topic:
version: '3'
services:
  my_sql_db:
    image: percona:latest
    container_name: my_sql_db
    environment:
      MYSQL_ROOT_PASSWORD: password
      MYSQL_DATABASE: abhs
    ports:
    - ""3306:3306""
    healthcheck:
      test: [""CMD"", ""mysqladmin"" ,""ping"", ""-h"", ""localhost""]
      timeout: 20s
      retries: 10
  migration:
    image: boxfuse/flyway:latest
    container_name: flyway_migration
    volumes:
      - ./flyway_scripts/src/main/resources/db/migration:/flyway/sql
    command: -url=jdbc:mysql://my_sql_db:3306/abhs?useUnicode=true&amp;characterEncoding=utf8&amp;useSSL=false -user=root -password=password migrate
    depends_on:
      my_sql_db:
        condition: service_healthy
but I see following error:
$ docker-compose -f docker-compose.yml -f docker-compose-dev.yml up
The Compose file '.\docker-compose-dev.yml' is invalid because:
services.migration.depends_on contains an invalid type, it should be an array
P.S.4
for that approach I see following error:
version: '3'
services:
  my_sql_db:
    image: percona:latest
    container_name: my_sql_db
    environment:
      MYSQL_ROOT_PASSWORD: password
      MYSQL_DATABASE: abhs
    ports:
    - ""3306:3306""
    healthcheck:
      test: [""CMD"", ""mysqladmin"" ,""ping"", ""-h"", ""localhost""]
      timeout: 20s
      retries: 10
  migration:
    image: boxfuse/flyway:latest
    container_name: flyway_migration
    volumes:
      - ./flyway_scripts/src/main/resources/db/migration:/flyway/sql
    command: dockerize wait jdbc:mysql://my_sql_db:3306 -url=jdbc:mysql://my_sql_db:3306/abhs?useUnicode=true&amp;characterEncoding=utf8&amp;useSSL=false -user=root -password=password migrate
    depends_on:
      - my_sql_db
I see following error:
flyway_migration  | ERROR: Invalid argument: dockerize
UPDATE_1
wait-for-it.sh content:
#!/usr/bin/env bash
#   Use this script to test if a given TCP host/port are available
cmdname=$(basename $0)
echoerr() { if [[ $QUIET -ne 1 ]]; then echo ""$@"" 1&gt;&amp;2; fi }
usage()
{
    cat &lt;&lt; USAGE &gt;&amp;2
Usage:
    $cmdname host:port [-s] [-t timeout] [-- command args]
    -h HOST | --host=HOST       Host or IP under test
    -p PORT | --port=PORT       TCP port under test
                                Alternatively, you specify the host and port as host:port
    -s | --strict               Only execute subcommand if the test succeeds
    -q | --quiet                Don't output any status messages
    -t TIMEOUT | --timeout=TIMEOUT
                                Timeout in seconds, zero for no timeout
    -- COMMAND ARGS             Execute command with args after the test finishes
USAGE
    exit 1
}
wait_for()
{
    if [[ $TIMEOUT -gt 0 ]]; then
        echoerr ""$cmdname: waiting $TIMEOUT seconds for $HOST:$PORT""
    else
        echoerr ""$cmdname: waiting for $HOST:$PORT without a timeout""
    fi
    start_ts=$(date +%s)
    while :
    do
        if [[ $ISBUSY -eq 1 ]]; then
            nc -z $HOST $PORT
            result=$?
        else
            (echo &gt; /dev/tcp/$HOST/$PORT) &gt;/dev/null 2&gt;&amp;1
            result=$?
        fi
        if [[ $result -eq 0 ]]; then
            end_ts=$(date +%s)
            echoerr ""$cmdname: $HOST:$PORT is available after $((end_ts - start_ts)) seconds""
            break
        fi
        sleep 1
    done
    return $result
}
wait_for_wrapper()
{
    # In order to support SIGINT during timeout: http://unix.stackexchange.com/a/57692
    if [[ $QUIET -eq 1 ]]; then
        timeout $BUSYTIMEFLAG $TIMEOUT $0 --quiet --child --host=$HOST --port=$PORT --timeout=$TIMEOUT &amp;
    else
        timeout $BUSYTIMEFLAG $TIMEOUT $0 --child --host=$HOST --port=$PORT --timeout=$TIMEOUT &amp;
    fi
    PID=$!
    trap ""kill -INT -$PID"" INT
    wait $PID
    RESULT=$?
    if [[ $RESULT -ne 0 ]]; then
        echoerr ""$cmdname: timeout occurred after waiting $TIMEOUT seconds for $HOST:$PORT""
    fi
    return $RESULT
}
# process arguments
while [[ $# -gt 0 ]]
do
    case ""$1"" in
        *:* )
        hostport=(${1//:/ })
        HOST=${hostport[0]}
        PORT=${hostport[1]}
        shift 1
        ;;
        --child)
        CHILD=1
        shift 1
        ;;
        -q | --quiet)
        QUIET=1
        shift 1
        ;;
        -s | --strict)
        STRICT=1
        shift 1
        ;;
        -h)
        HOST=""$2""
        if [[ $HOST == """" ]]; then break; fi
        shift 2
        ;;
        --host=*)
        HOST=""${1#*=}""
        shift 1
        ;;
        -p)
        PORT=""$2""
        if [[ $PORT == """" ]]; then break; fi
        shift 2
        ;;
        --port=*)
        PORT=""${1#*=}""
        shift 1
        ;;
        -t)
        TIMEOUT=""$2""
        if [[ $TIMEOUT == """" ]]; then break; fi
        shift 2
        ;;
        --timeout=*)
        TIMEOUT=""${1#*=}""
        shift 1
        ;;
        --)
        shift
        CLI=(""$@"")
        break
        ;;
        --help)
        usage
        ;;
        *)
        echoerr ""Unknown argument: $1""
        usage
        ;;
    esac
done
if [[ ""$HOST"" == """" || ""$PORT"" == """" ]]; then
    echoerr ""Error: you need to provide a host and port to test.""
    usage
fi
TIMEOUT=${TIMEOUT:-15}
STRICT=${STRICT:-0}
CHILD=${CHILD:-0}
QUIET=${QUIET:-0}
# check to see if timeout is from busybox?
# check to see if timeout is from busybox?
TIMEOUT_PATH=$(realpath $(which timeout))
if [[ $TIMEOUT_PATH =~ ""busybox"" ]]; then
        ISBUSY=1
        BUSYTIMEFLAG=""-t""
else
        ISBUSY=0
        BUSYTIMEFLAG=""""
fi
if [[ $CHILD -gt 0 ]]; then
    wait_for
    RESULT=$?
    exit $RESULT
else
    if [[ $TIMEOUT -gt 0 ]]; then
        wait_for_wrapper
        RESULT=$?
    else
        wait_for
        RESULT=$?
    fi
fi
if [[ $CLI != """" ]]; then
    if [[ $RESULT -ne 0 &amp;&amp; $STRICT -eq 1 ]]; then
        echoerr ""$cmdname: strict mode, refusing to execute subprocess""
        exit $RESULT
    fi
    exec ""${CLI[@]}""
else
    exit $RESULT
fi
P.S.5
Also I tried this:
version: '3'
services:
  my_sql_db:
    image: percona:latest
    container_name: my_sql_db
    environment:
      MYSQL_ROOT_PASSWORD: password
      MYSQL_DATABASE: abhs
    ports:
    - ""3306:3306""
    healthcheck:
      test: [""CMD"", ""mysqladmin"" ,""ping"", ""-h"", ""localhost""]
      timeout: 20s
      retries: 10
  migration:
    image: boxfuse/flyway:latest
    container_name: flyway_migration
    volumes:
     - ./flyway_scripts/src/main/resources/db/migration:/flyway/sql
    entrypoint: [""wait-for-it.sh"", ""mysql:3306"", ""--"", ""docker-entrypoint.sh""]      
    command: -url=jdbc:mysql://my_sql_db:3306/abhs?useUnicode=true&amp;characterEncoding=utf8&amp;useSSL=false -user=root -password=password migrate
    depends_on:
      - my_sql_db
It leads to error:
Creating flyway_migration ... error
ERROR: for flyway_migration  Cannot start service migration: OCI runtime create failed: container_linux.go:348: starting container process caused ""exec: \""wait-for-it.sh\"": executable file not found in $PATH"": unknown
ERROR: for migration  Cannot start service migration: OCI runtime create failed: container_linux.go:348: starting container process caused ""exec: \""wait-for-it.sh\"": executable file not found in $PATH"": unknown
Encountered errors while bringing up the project.
",<java><mysql><docker><flyway><depends>,15862,4,344,36992,119,374,727,63,20204,0.0,3581,3,20,2018-08-24 8:59,2018-08-27 12:12,,3.0,,Advanced,32
60014874,How to use TypeScript with Sequelize,"I already have my server application written in Node, PostgreSQL, Sequelize using Fastify.
Now I would like to use TypeScript. Can anyone tell me how to begin rewriting my Server application using TypeScript.
",<node.js><postgresql><typescript><sequelize.js><fastify>,209,0,0,499,1,3,13,48,43713,0.0,61,3,20,2020-02-01 7:20,2020-02-02 2:08,2020-02-24 3:31,1.0,23.0,Intermediate,20
59563423,"Cannot drop a database in Azure Data Studio, because it's currently in use","I cannot drop custom databases in Azure Data Studio, because they are currently in use.
I've been looking for various ways to close the zap database, but I cannot find any in the UI. 
Only by restarting Azure Data Studio, is the zap database in an ""Auto Closed"" state, which lets me drop it using:
drop database zap;
How do I close a connection to a database without restarting Azure Data Studio?
Open:
Auto-closed:
",<sql><sql-server><windows>,416,2,3,11770,22,94,194,48,23330,0.0,364,2,20,2020-01-02 12:33,2020-01-02 12:35,2020-01-02 12:36,0.0,0.0,Intermediate,15
52719378,Failed to find valid data directory. MySQL generic binary installion,"Im going to install mysql to linux server. But I dont have root access to that server. So I created two folders called mysql and mysqldata. mysql folder holds binary files. mysqldata folder holds data and the logs.
my.cnf
[mysqld]
user                    = mysql
port                    = 3306
bind-address            = localhost
basedir                 = /home/nwn/mysql/mysql-8.0
socket                  = /home/nwn/mysqldata/instA/socket/mysql.sock
datadir                 = /home/nwn/mysqldata/instA/data
tmpdir                  = /home/nwn/mysqldata/instA/tmp
secure_file_priv        = /home/nwn/mysqldata/instA/mysql-files
max_connections         = 150
# Logging
log-bin                 = /home/nwn/mysqldata/instA/logs/instA-binlog
log-error               = /home/nwn/mysqldata/instA/logs/instA-errorlog.err
slow_query_log          = 1
slow_query_log_file     = /home/nwn/mysqldata/instA/logs/instA-slowquery.log
long_query_time         = 0.5
# InnoDB
innodb_data_home_dir    = /home/nwn/mysqldata/instA/innodb/data
innodb_data_file_path   = ibdata1:50M;ibdata2:12M:autoextend:max:500M
innodb_log_group_home_dir = /home/nwn/mysqldata/instA/innodb/log
innodb_buffer_pool_size = 32M
# MyISAM
key_buffer_size         = 16M
server_id                = 1
I did all the other configurations.
when I run following command 
mysql-8.0]$ bin/mysqld --defaults-file=~/mysqldata/instA/my.cnf --initialize-insercure
I have following logs in the error_log
 cat ~/mysqldata/instA/logs/instA-errorlog.err
2018-10-09T10:39:51.127424Z 0 [Warning] [MY-010139] [Server] Changed limits: max_open_files: 1024 (requested 8160)
2018-10-09T10:39:51.127523Z 0 [Warning] [MY-010142] [Server] Changed limits: table_open_cache: 432 (requested 4000)
2018-10-09T10:39:51.383986Z 0 [Warning] [MY-010101] [Server] Insecure configuration for --secure-file-priv: Location is accessible to all OS users. Consider choosing a different directory.
2018-10-09T10:39:51.384043Z 0 [System] [MY-010116] [Server] /home/nwn/mysql/mysql-8.0/bin/mysqld (mysqld 8.0.12) starting as process 32654
2018-10-09T10:39:51.386625Z 0 [Warning] [MY-010122] [Server] One can only use the --user switch if running as root
2018-10-09T10:39:51.394675Z 1 [ERROR] [MY-011011] [Server] Failed to find valid data directory.
2018-10-09T10:39:51.394817Z 0 [ERROR] [MY-010020] [Server] Data Dictionary initialization failed.
2018-10-09T10:39:51.394831Z 0 [ERROR] [MY-010119] [Server] Aborting
2018-10-09T10:39:51.395363Z 0 [System] [MY-010910] [Server] /home/nwn/mysql/mysql-8.0/bin/mysqld: Shutdown complete (mysqld 8.0.12)  MySQL Community Server - GPL.
",<mysql><mysqladministrator>,2594,0,39,267,1,3,10,72,65137,0.0,1,6,20,2018-10-09 10:57,2020-05-25 13:45,,594.0,,Basic,14
48370045,Android Room Persistence Library - How to find entities with ids contained in list of ids?,"I am trying to do the following query in my DAO.
   @Query(""SELECT * FROM objects WHERE obj_id IN :ids"")
   List&lt;Object&gt; queryObjects(List&lt;String&gt; ids);
It gives me this compile-time error:
Error: no viable alternative at input 'SELECT * FROM objects WHERE obj_id IN :ids'
Both List&lt;String&gt; ids as well as String... ids and Sring[] ids don't work. However, since I don't know how many ids I will have in compile-time and therefore, I need a list/array and not varargs. 
How can I make this SQL query work?
",<java><android><sql><sqlite><android-room>,524,0,6,5875,6,34,62,42,10642,0.0,70,2,20,2018-01-21 18:07,2018-01-21 18:23,2018-01-21 18:23,0.0,0.0,Basic,10
51062920,pip install mysqlclient : Microsoft Visual C++ 14.0 is required,"i'm tryng to import mysqlclient library for python with pip, when i use the command
pip install mysqlclient it return an error:
Collecting mysqlclient
Using cached     https://files.pythonhosted.org/packages/ec/fd/83329b9d3e14f7344d1cb31f128e6dbba70c5975c9e57896815dbb1988ad/mysqlclient-1.3.13.tar.gz
Installing collected packages: mysqlclient
Running setup.py install for mysqlclient ... error
Complete output from command c:\users\astrina\appdata\local\programs\python\python36\python.exe -u -c ""import setuptools, tokenize;__file__='C:\\Users\\astrina\\AppData\\Local\\Temp\\pip-install-40l_x_f4\\mysqlclient\\setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\r\n', '\n');f.close();exec(compile(code, __file__, 'exec'))"" install --record C:\Users\astrina\AppData\Local\Temp\pip-record-va173t5v\install-record.txt --single-version-externally-managed --compile:
c:\users\astrina\appdata\local\programs\python\python36\lib\distutils\dist.py:261: UserWarning: Unknown distribution option: 'long_description_content_type'
  warnings.warn(msg)
running install
running build
running build_py
creating build
creating build\lib.win-amd64-3.6
copying _mysql_exceptions.py -&gt; build\lib.win-amd64-3.6
creating build\lib.win-amd64-3.6\MySQLdb
copying MySQLdb\__init__.py -&gt; build\lib.win-amd64-3.6\MySQLdb
copying MySQLdb\compat.py -&gt; build\lib.win-amd64-3.6\MySQLdb
copying MySQLdb\connections.py -&gt; build\lib.win-amd64-3.6\MySQLdb
copying MySQLdb\converters.py -&gt; build\lib.win-amd64-3.6\MySQLdb
copying MySQLdb\cursors.py -&gt; build\lib.win-amd64-3.6\MySQLdb
copying MySQLdb\release.py -&gt; build\lib.win-amd64-3.6\MySQLdb
copying MySQLdb\times.py -&gt; build\lib.win-amd64-3.6\MySQLdb
creating build\lib.win-amd64-3.6\MySQLdb\constants
copying MySQLdb\constants\__init__.py -&gt; build\lib.win-amd64-3.6\MySQLdb\constants
copying MySQLdb\constants\CLIENT.py -&gt; build\lib.win-amd64-3.6\MySQLdb\constants
copying MySQLdb\constants\CR.py -&gt; build\lib.win-amd64-3.6\MySQLdb\constants
copying MySQLdb\constants\ER.py -&gt; build\lib.win-amd64-3.6\MySQLdb\constants
copying MySQLdb\constants\FIELD_TYPE.py -&gt; build\lib.win-amd64-3.6\MySQLdb\constants
copying MySQLdb\constants\FLAG.py -&gt; build\lib.win-amd64-3.6\MySQLdb\constants
copying MySQLdb\constants\REFRESH.py -&gt; build\lib.win-amd64-3.6\MySQLdb\constants
running build_ext
building '_mysql' extension
error: Microsoft Visual C++ 14.0 is required. Get it with ""Microsoft Visual C++ Build Tools"": http://landinghub.visualstudio.com/visual-cpp-build-tools
----------------------------------------
Command ""c:\users\astrina\appdata\local\programs\python\python36\python.exe -u -c ""import setuptools, 
tokenize;__file__='C:\\Users\\astrina\\AppData\\Local\\Temp\\pip-install- 
40l_x_f4\\mysqlclient\\setup.py';f=getattr(tokenize, 'open', open) 
(__file__);code=f.read().replace('\r\n', '\n');f.close();exec(compile(code, 
__file__, 'exec'))"" install --record C:\Users\astrina\AppData\Local\Temp\pip- 
record-va173t5v\install-record.txt --single-version-externally-managed -- 
compile"" failed with error code 1 in C:\Users\astrina\AppData\Local\Temp\pip- 
install-40l_x_f4\mysqlclient\
I've already installed Microsoft Build Tools 2015 but the problem persist
",<python><mysql><pip><build-tools>,3259,2,43,420,2,5,18,37,85328,0.0,42,13,20,2018-06-27 12:33,2018-08-09 7:00,2018-08-10 6:19,43.0,44.0,Intermediate,24
50151476,"""HostName not verified error message"" on SSL connection in postgresql","I created server.crt, server.key and root.crt files on Centos 7 and put the same onto the C:\Users\xxxx\AppData\Roaming\postgresql folder in windows as i am running the postgresql server on windows. Now on running my applications using SSL, i am getting the error as 
  ""The host name could not be verified""
Any help please.
",<postgresql><ssl><ssl-certificate>,325,0,4,355,1,3,15,64,16822,0.0,4,3,20,2018-05-03 9:26,2018-05-03 10:38,,0.0,,Advanced,45
56416437,Confusion about URI path to configure SQLite database,"Hi I am building a web application using Flask and Sqlite3. I had issues with connecting the database for a while and it did not work when I wrote this:
#version 1
app.config['SQLALCHEMY_DATABASE_URI'] =
'sqlite:////C:/Users/Giang/PyCharmProjects/FlaskWebBlog/FlaskWebBlog/site.db'
Python gave me operational error: can not open database because I wrote with 4 slashes after the colon. After reading sqlalchemy documentation and doing so many trials, I found out this worked:
#with 3 slashes, version 2
app.config['SQLALCHEMY_DATABASE_URI'] = 
 'sqlite:///C:/Users/Giang/PyCharmProjects/FlaskWebBlog/FlaskWebBlog/site.db'
or this with 4 slashes but no C:
#version 3
app.config['SQLALCHEMY_DATABASE_URI'] = 
'sqlite:////Users/Giang/PyCharmProjects/FlaskWebBlog/FlaskWebBlog/site.db'
I am confused because based on the documentation of connecting strings: The file specification for the SQLite database is taken as the “database” portion of the URL. Note that the format of a SQLAlchemy url is:
driver://user:pass@host/database
This means that the actual filename to be used starts with the characters to the right of the third slash. So connecting to a relative filepath looks like:
# relative path
e = create_engine('sqlite:///path/to/database.db')
An absolute path, which is denoted by starting with a slash, means you need four slashes:
# absolute path
e = create_engine('sqlite:////path/to/database.db')
SO according to this, if I use absolute path, I need 4 slashes, but when I did that with version 1, python gave me errors. And when I used 3 slashes for absolute path in version 2, it worked.
So I am really confused. Can anyone explain for me why ? I would really appreciate it. Thank you
",<python><sqlite><uri><relative-path><absolute-path>,1696,0,16,411,1,5,10,77,36603,0.0,13,2,20,2019-06-02 15:30,2019-06-02 16:53,,0.0,,Basic,4
51972843,Polymorphic entities in Room,"There are 3 entities in my Room DB:
Album, PhotosMediaItem and VideosMediaItem.
VideosMediaItem and PhotosMediaItem inherit from MediaItem.
MediaItem is not an entity in the DB, it's just an abstract base class.
I would like to create a query that returns all the photos and videos media items in a specific album with descending order based on their creation date.
So the query will create a list of MediaItems but with the derived types. (PhotoMediaItem or VideoMediaItem) in a polymorphic way.
Here's what I've tried:
    @Query(""SELECT * FROM PhotosMediaItem WHERE PhotosMediaItem = :albumId "" +
        ""UNION SELECT * FROM VideosMediaItem WHERE VideosMediaItem = :albumId"" +
        "" ORDER by CreationDate DESC"")
    List&lt;MediaItem&gt; getAllMediaInAlbum(int albumId);
This won't work obviously, because it tries to initiate MediaItem object, and it is not my intention. I want this query to initiate the derived class, PhotoMediaItem or VideoMediaItem
Here's how my query looked like before the migration to Room, using the regular SQLiteHelper, and it worked just fine:
public ArrayList&lt;MediaItem&gt; getMediaListByAlbumId(int palbumId)
{
    Cursor cursor = null;
    try{
        ArrayList&lt;MediaItem&gt; mediaList = new ArrayList&lt;&gt;();
        String selectQuery = ""SELECT ""+ mPhotoId +"",""+ mPhotoCreationDate +"", 0 AS mediaType, '' FROM ""+ mPhotosTableName + "" WHERE "" + this.mPhotoAlbumId + ""=""+palbumId +
                "" UNION "" +
                ""SELECT ""+ mVideoId +"",""+ mVideoCreationDate + "" ,1 AS mediaType, "" + mVideoLength + "" FROM "" + mVideosTableName + "" WHERE "" + this.mVideoAlbumId +""=""+palbumId +
                "" ORDER BY CreationDate DESC"";
        cursor = mDB.rawQuery(selectQuery, null);
        // looping through all rows and adding to list
        if (cursor.moveToFirst()){
            do {
                // MediaHolder consists of the media ID and its type
                int mediaType = cursor.getInt(2);
                MediaItem mediaItem = null;
                if (mediaType == 0) {
                    mediaItem = new PhotoMediaItem(cursor.getInt(0), null, palbumId);
                } else if (mediaType == 1) {
                    mediaItem = new VideoMediaItem(cursor.getInt(0), null, palbumId, cursor.getLong(3));
                }
                mediaList.add(mediaItem);
            }
            while (cursor.moveToNext());
        }
        return mediaList;
    }
    finally  {
        if(cursor != null){
            cursor.close();
        }
    }
}
How can I achieve the same effect using Room then?
",<android><sqlite><polymorphism><union><android-room>,2577,0,49,3190,13,53,85,52,4819,0.0,215,2,20,2018-08-22 18:13,2018-08-31 10:42,2018-08-31 10:42,9.0,9.0,Basic,10
49610908,Exporting a PostgreSQL query to a csv file using Python,"I need to export some rows from a table in a PostgreSQL database to a .csv file using a Python script:
#!/usr/bin/python
# -*- coding: utf-8 -*-
import sys, psycopg2
...
    conn = psycopg2.connect(""dbname=dbname user=user password=password"")
    cur = conn.cursor()
    sql = ""\copy (SELECT * FROM table WHERE month=6) TO '/mnt/results/month/table.csv' WITH CSV DELIMITER ';';""
    cur.execute(sql)
    cur.close()
...
But when I run the script I get this:
Syntax error at or near «\»
LINE 1: \copy (SELECT * FROM TABLE WHERE month=6) TO '...
Does anyone know what can be wrong or give me a tip about?
",<python><sql><postgresql><export-to-csv><psycopg2>,603,0,17,435,1,3,13,43,26778,0.0,175,4,20,2018-04-02 12:00,2018-04-02 13:43,2018-04-02 13:51,0.0,0.0,Basic,10
51538158,PostgreSQL update all value to upper case for one column,"I have a table : Customer and column = [name,surname,language]
I want to update all language columns value to upper case how can I do it?
I have seen upper() method but it used on select operations. I need to update.
",<sql><postgresql>,217,0,0,1103,4,14,27,46,14405,0.0,19,1,20,2018-07-26 11:50,2018-07-26 11:59,2018-07-26 11:59,0.0,0.0,Basic,2
59553246,What's the recommended way to do database migrations with Ktor + Exposed (Kotlin)?,"The Ktor or Exposed frameworks do not have any built-in support for database migrations. What's the recommended way to do this?
",<sql><database><kotlin><migration>,128,0,0,806,2,11,29,71,11334,0.0,14,4,20,2020-01-01 14:14,2020-01-23 21:24,,22.0,,Basic,3
62955635,How to restore a PostgreSQL database from dump file in dbeaver?,"In our company we have a dump of PostgreSQL database - file db.sql. It weighs 8 Gigabyte. How to restore this database in DBeaver? And we don't have another databases in DBeaver 7.0.5.
I have digged all Internet and haven't found anything how to do this without another database/
",<postgresql><dump><dbeaver>,280,0,1,381,1,2,12,37,49790,,25,2,20,2020-07-17 14:02,2020-07-17 14:57,2020-07-17 14:57,0.0,0.0,Basic,10
54973536,FOR JSON PATH results in SSMS truncated to 2033 characters,"I'm concatenating strings together using ""for JSON path('')"".
I have set the Tools->Options->SQL Server->Results to Grid options to max.
I have set the Tools->Options->SQL Server->Results to Text options to max.
Executing the query in Grid mode and copying the one row/one column results, I see the return value is limited to 2033 characters.
How can I ensure the returned value isn't truncated?
",<sql-server><t-sql><ssms>,396,0,0,371,1,3,9,48,14922,0.0,8,10,20,2019-03-03 20:42,2019-03-03 20:57,2019-03-03 20:57,0.0,0.0,Basic,10
48866673,malformed array literal - PostgreSQL,"I want to copy an array from jsonb field to a PostgreSQL array column:
CREATE TABLE survey_results (
    id integer NOT NULL,
    areas text[],  
    raw jsonb DEFAULT '{}'::jsonb
);
INSERT INTO survey_results (id, raw)
    VALUES (1, '{""areas"": [""test"", ""test2""]}');
UPDATE survey_results SET areas = CAST(raw#&gt;&gt;'{areas}' AS text[]);
This returns me?
ERROR: malformed array literal: ""[""test"", ""test2""]"" Detail: ""["" must introduce explicitly-specified array dimensions.
How can I fix that?
http://sqlfiddle.com/#!17/d8122/2
",<sql><postgresql>,530,2,11,7462,15,68,135,69,98953,0.0,499,2,20,2018-02-19 12:52,2018-02-19 13:03,2018-02-19 13:03,0.0,0.0,Basic,2
49596061,TypeORM updating entity/table,"This is my User entity:
@PrimaryGeneratedColumn()
userId: number;
@Column({type:""varchar"", length:""300""})
userName: string;
@OneToOne(type =&gt; UserProfile, {cascadeAll:true})
@JoinColumn()
userProfile: UserProfile;
@OneToOne(type =&gt; UserCredential, {cascadeAll:true, eager:true})
@JoinColumn()
userCredential: UserCredential;
@OneToOne(type =&gt; BusinessUnit, {cascadeAll:true})
@JoinColumn()
businessUnit: BusinessUnit;
@ManyToMany(type =&gt; ProductCategory)
@JoinTable()
productCategory: ProductCategory[];
and this is my new data which i want to update:
User {
  userName: 'qweret@gmail.com',
  userProfile: 
   UserProfile {
     firstName: 'dcds',
     lastName: 'Faiz',
     mobile: '42423423',
     addressLine1: 'Delhi',
     addressLine2: 'Delhi',
     city: '-',
     country: '-',
     zipCode: '234243',
     homeTelephone: '-',
     dayOfBirth: 0,
     monthOfBirth: 0,
     yearOfBirth: 0 },
  userCredential: UserCredential { credential: 'abcd@123' } }
i'm searching user by its userId.
return await getManager()
               .createQueryBuilder(User, ""user"")
               .where(""user.userId = :id"", {id})
               .getOne();
the above query gives me result:
User {
  createdDate: 2018-03-29T06:45:16.322Z,
  updatedDate: 2018-04-01T06:28:24.171Z,
  userId: 1,
  userName: 'qweret@gmail.com' }
i want to update my user table and its related tables
manager.save(user)
will insert a new row in the table instead of updating the existing the row. Is there a way to update the whole user table and its related table without updating every column manually?
i don't want to perform this task like this:
let user = await userRepositiory.findOneById(1);
user.userName = ""Me, my friends and polar bears"";
await userRepository.save(user);
let userProfile = await userProfileRepository.findOneById(1);
 userProfile.firstName = """";
 userProfile.lastName = """";
    ....// etc
 await userRepository.save(userProfile);
 // and so on update other tables.
",<mysql><node.js><database><typeorm>,1972,0,59,211,1,2,4,39,48282,0.0,0,3,20,2018-04-01 8:02,2019-09-03 15:48,,520.0,,Basic,11
56301656,Disable Lazy Loading in Entity Framework Core,"There are plenty of posts about how to disable lazy loading in Entity Framework, but the same techniques don't work in EF Core. I found the LazyLoadingEnabled property in the change tracker, but this doesn't seem to work at all.
Everything points to this in EF:
this.Configuration.LazyLoadingEnabled = false;
But, the Configuration property is missing in EF Core.
Here is an example of what I am talking about:
public class TestContext : DbContext
{
    public DbSet&lt;Person&gt; People { get; set; }
    public DbSet&lt;Address&gt; Addresses { get; set; }
    public TestContext()
    {
        this.ChangeTracker.LazyLoadingEnabled = false;
    }
    protected override void OnConfiguring(DbContextOptionsBuilder optionsBuilder)
    {            
        var connection = new SqliteConnection($""Data Source=Test.db"");
        connection.Open();
        var command = connection.CreateCommand();
        command.CommandText = $""PRAGMA foreign_keys = ON;"";
        command.ExecuteNonQuery();
        optionsBuilder.UseSqlite(connection);
        optionsBuilder.UseLazyLoadingProxies(false);
        base.OnConfiguring(optionsBuilder);
    }
    private static void Main(string[] args)
    {
        Console.WriteLine(""Hello World!"");
        using (var context = new TestContext())
        {
            context.Database.EnsureCreated();
            var personKey = Guid.NewGuid().ToString();
            var addressKey = Guid.NewGuid().ToString();
            context.People.Add(new Entities.Person { PersonKey = personKey, BillingAddress = new Entities.Address { AddressKey = addressKey } });
            context.SaveChanges();
        }
        using (var context = new TestContext())
        {
            var people = context.People.ToList();
            foreach (var person in people)
            {
                if (person.BillingAddress == null) throw new Exception(""The billing address wasn't loaded"");
            }
        }
    }
}
The above throws an exception because BillingAddress is not getting loaded even though I turned lazy loading off.
I suspect this is a bug, but please tell me it isn't. I logged it here: https://github.com/aspnet/EntityFrameworkCore/issues/15802
You can download the sample here:
https://www.dropbox.com/s/mimvgvcmibr7em2/EFSQLiteTest.7z?dl=0
",<c#><sqlite><.net-core><entity-framework-core>,2289,4,56,7010,5,51,106,51,31973,0.0,263,1,20,2019-05-25 4:17,2019-11-27 15:12,,186.0,,Basic,11
55701029,How to insert value to identity column in PostgreSQL 11.1,"I would like to insert my own value to identity column.
Table Schema:
CREATE TABLE public.userdetail (
    userdetailid int4 NOT NULL GENERATED ALWAYS AS IDENTITY,
    username varchar(30) NOT NULL,
    ""password"" varchar(1000) NOT NULL,
    CONSTRAINT pk_userdetail PRIMARY KEY (userdetailid)
);
Insert Query:
INSERT INTO UserDetail (UserDetailId,UserName, Password) 
  VALUES(1,'admin', 'password');
Here insert query throwing below error: 
  cannot insert into column ""userdetailid""
Is there any command exists to force insert to identity column like MS SQL :
 SET IDENTITY_INSERT UserDetail ON
Let me know if you have any solution.
",<database><postgresql>,636,0,9,1089,3,12,24,68,33643,0.0,20,1,20,2019-04-16 5:20,2019-04-16 5:27,2019-04-16 5:27,0.0,0.0,Basic,10
50983177,How to connect to PostgreSQL using docker-compose?,"Want to use docker-compose to run api application and postgresql database together. 
docker-compose file:
version: '3'
volumes:
  database_data:
    driver: local
services:
  db:
    image: postgres:latest
    volumes:
      - database_data:/var/lib/postgresql/data
  api:
    build: ./api
    expose:
      - 8080
    ports:
      - 8080:8080
    volumes:
      - ./api:/usr/src/app/
    links:
      - db
    environment:
      - PGHOST=db
      - PGDATABASE=postgres
      - PGUSER=postgres
Api main.go file:
func main() {
    db, err = gorm.Open(""postgres"", ""host=db port=5432 user=postgres dbname=postgres"")
  // ...
}
When run the services, got message from log:
api_1     | [GIN] 2018/06/22 - 07:31:10 | 404 |      1.4404ms |      172.20.0.1 | GET      /posts
api_1     |
api_1     | (sql: database is closed)
api_1     | [2018-06-22 07:31:10]
api_1     |
api_1     | (sql: database is closed)
api_1     | [2018-06-22 07:31:10]
api_1     | [GIN] 2018/06/22 - 07:32:14 | 403 |        15.6µs |      172.20.0.1 | GET      /posts
db_1      | 2018-06-22 07:34:27.296 UTC [81] FATAL:  role ""root"" does not exist
db_1      | 2018-06-22 07:34:36.897 UTC [90] FATAL:  role ""root"" does not exist
Does this way not good? host=db in the connection string? Since db is the docker compose service name.
Add
It can work:
https://docs.docker.com/samples/library/postgres/#-or-via-psql
",<postgresql><docker><go><service><docker-compose>,1376,2,45,633,3,13,26,74,52641,0.0,12,1,20,2018-06-22 7:50,2018-09-27 19:19,,97.0,,Basic,10
50019457,Why does Spark Planner prefer sort merge join over shuffled hash join?,"Why does Spark Planner in Spark 2.3 prefer a sort merge join over a shuffled hash join? In other words, why is spark.sql.join.preferSortMergeJoin configuration property internal and turned on by default? What's wrong with a shuffled hash join? Is this specific to Spark that it does computations in distributed fashion or something else more inherent in the join algorithm?
You can find the property used in the JoinSelection execution planning strategy here and here that looks like:
case ... if !conf.preferSortMergeJoin &amp;&amp; ... =&gt;
  Seq(joins.ShuffledHashJoinExec(...))
",<apache-spark><join><apache-spark-sql>,583,3,4,73211,27,243,423,67,10622,0.0,5053,1,20,2018-04-25 10:04,2018-04-25 12:03,2018-04-25 12:03,0.0,0.0,Intermediate,23
48522640,Failure to connect to Docker Postgresql instance from Python,"I am using Docker to ""containerize"" a PostgreSQL deployment. I can spin up the container and connect to PostgreSQL via the command line as shown below:
minime2@CEBERUS:~/Projects/skunkworks$ docker ps
CONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS               NAMES
dc176901052a        df:pg               ""docker-entrypoint...""   About an hour ago   Up About an hour    5432/tcp            vigilant_agnesi
minime2@CEBERUS:~/Projects/skunkworks$ CONTAINER_ID=dc176901052a
minime2@CEBERUS:~/Projects/skunkworks$ IP=$(docker inspect -f '{{.NetworkSettings.Networks.bridge.IPAddress}}' $CONTAINER_ID)
minime2@CEBERUS:~/Projects/skunkworks$ echo $IP
172.17.0.2
minime2@CEBERUS:~/Projects/skunkworks$ docker exec -it vigilant_agnesi psql -U postgres -W cookiebox
Passwod for user postgres:
psql (9.6.5)
Type ""help"" for help
cookiebox#
Now attempting connection with Python:
Python 3.5.2 (default, Sep 14 2017, 22:51:06) 
[GCC 5.4.0 20160609] on linux
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
&gt;&gt;&gt; import psycopg2
&gt;&gt;&gt; conn = psycopg2.connect(""dbname='cookiebox' user='postgres' host='172.17.0.2' password='nunyabiznes'"")                                     Traceback (most recent call last):
  File ""&lt;stdin&gt;"", line 1, in &lt;module&gt;
  File ""/home/minime2/Projects/skunkworks/archivers/env/lib/python3.5/site-packages/psycopg2/__init__.py"", line 130, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: could not connect to server: Connection refused
        Is the server running on host ""172.17.0.2"" and accepting
        TCP/IP connections on port 5432?
&gt;&gt;&gt; 
Can anyone explain why I can't connect to PostgreSQL using Python - even though I'm using the same arguments/parameters that enable a successful connection at the command line (using docker exec?).
[[Additional Info]]
As suggested by @Itvhillo, I tried to use a desktop application to connect to the PG service. I run the docker service using the following command:
docker run -i -p 5432:5432 --name $CONTAINER_NAME $DOCKER_IMAGE
I am using Db Visualizer to connect to the database, and I have set the hostname to 'localhost'. I can successfully ping the port, but still get an error message when I try to connect to the database (possible permissions related error):
An error occurred while establishing the connection:
Long Message:
The connection attempt failed.
Details:
   Type: org.postgresql.util.PSQLException
   SQL State: 08001
Incidentally, this is the tail end of the output for the PG service instance:
PostgreSQL init process complete; ready for start up.
LOG:  could not bind IPv6 socket: Cannot assign requested address
HINT:  Is another postmaster already running on port 5432? If not, wait a few seconds and retry.
LOG:  database system was shut down at 2018-01-30 16:21:59 UTC
LOG:  MultiXact member wraparound protections are now enabled
LOG:  database system is ready to accept connections
LOG:  autovacuum launcher started
[[Additional Info2]]
Here is the tail end of my Dockerfile:
# modified target locations (checked by login onto Docker container)
# show hba_file;
# show config_file;
#################################################################################
# From here: https://docs.docker.com/engine/examples/postgresql_service/
# Adjust PostgreSQL configuration so that remote connections to the
# database are possible.
RUN echo ""host all  all    0.0.0.0/0  md5"" &gt;&gt; /var/lib/postgresql/data/pg_hba.conf
# And add ``listen_addresses`` to ``/var/lib/postgresql/data/postgresql.conf``
RUN echo ""listen_addresses='*'"" &gt;&gt; /var/lib/postgresql/data/postgresql.conf
#################################################################################
EXPOSE 5432
# Add VOLUMEs to allow backup of config, logs and databases
VOLUME  [""/etc/postgresql"", ""/var/log/postgresql"", ""/var/lib/postgresql"", ""/usr/lib/postgresql/""]
",<python><postgresql><docker><psycopg2>,4008,2,67,65877,82,222,348,46,13011,0.0,948,5,20,2018-01-30 13:29,2018-02-01 14:42,2018-02-06 17:45,2.0,7.0,Advanced,38
51228905,Rails error installing mysql2 (mysql2-0.3.20),"I am trying to get a rails project up and running on my local machine.  When I do bundle install 
Fetching mysql2 0.3.20
Installing mysql2 0.3.20 with native extensions
Gem::Ext::BuildError: ERROR: Failed to build gem native extension.
current directory: /Users/mac/.rvm/gems/ruby-2.3.1/gems/mysql2-
0.3.20/ext/mysql2
/Users/mac/.rvm/rubies/ruby-2.3.1/bin/ruby -r ./siteconf20180707-33936-1toblx7.rb extconf.rb
checking for ruby/thread.h... yes
checking for rb_thread_call_without_gvl() in ruby/thread.h... yes
checking for rb_thread_blocking_region()... no
checking for rb_wait_for_single_fd()... yes
checking for rb_hash_dup()... yes
checking for rb_intern3()... yes
-----
Using mysql_config at /usr/local/bin/mysql_config
-----
checking for mysql.h... yes
checking for errmsg.h... yes
checking for mysqld_error.h... yes
-----
Setting rpath to /usr/local/Cellar/mysql/8.0.11/lib
-----
creating Makefile
current directory: /Users/mac/.rvm/gems/ruby-2.3.1/gems/mysql2-0.3.20/ext/mysql2
make ""DESTDIR="" clean
current directory: /Users/mac/.rvm/gems/ruby-2.3.1/gems/mysql2-0.3.20/ext/mysql2
make ""DESTDIR=""
compiling infile.c
compiling client.c
client.c:367:33: warning: implicit conversion loses integer precision: 'long' to 'unsigned int' [-Wshorten-64-to-32]
        elapsed_time = end_time - start_time;
                     ~ ~~~~~~~~~^~~~~~~~~~~~
client.c:439:3: error: use of undeclared identifier 'my_bool'
  my_bool res = mysql_read_query_result(client);
  ^
client.c:441:19: error: use of undeclared identifier 'res'
  return (void *)(res == 0 ? Qtrue : Qfalse);
                  ^
client.c:775:3: error: use of undeclared identifier 'my_bool'
  my_bool boolval;
  ^
client.c:806:7: error: use of undeclared identifier 'boolval'
      boolval = (value == Qfalse ? 0 : 1);
      ^
client.c:807:17: error: use of undeclared identifier 'boolval'
      retval = &amp;boolval;
                ^
client.c:810:10: error: use of undeclared identifier 'MYSQL_SECURE_AUTH'; did you mean 'MYSQL_DEFAULT_AUTH'?
    case MYSQL_SECURE_AUTH:
         ^~~~~~~~~~~~~~~~~
         MYSQL_DEFAULT_AUTH
/usr/local/Cellar/mysql/8.0.11/include/mysql/mysql.h:188:3: note: 'MYSQL_DEFAULT_AUTH' declared here
  MYSQL_DEFAULT_AUTH,
  ^
client.c:811:7: error: use of undeclared identifier 'boolval'
      boolval = (value == Qfalse ? 0 : 1);
      ^
client.c:812:17: error: use of undeclared identifier 'boolval'
      retval = &amp;boolval;
                ^
client.c:843:38: error: use of undeclared identifier 'boolval'
        wrapper-&gt;reconnect_enabled = boolval;
                                     ^
client.c:1165:56: warning: implicit conversion loses integer precision: 'size_t' (aka 'unsigned long') to 'unsigned int' [-Wshorten-64-to-32]
  mysql2rb = mysql2_mysql_enc_name_to_rb(charset_name, charset_name_len);
             ~~~~~~~~~~~~~~~~~~~~~~~~~~~               ^~~~~~~~~~~~~~~~
client.c:1198:38: error: use of undeclared identifier 'MYSQL_SECURE_AUTH'; did you mean 'MYSQL_DEFAULT_AUTH'?
  return _mysql_client_options(self, MYSQL_SECURE_AUTH, value);
                                     ^~~~~~~~~~~~~~~~~
                                     MYSQL_DEFAULT_AUTH
/usr/local/Cellar/mysql/8.0.11/include/mysql/mysql.h:188:3: note: 'MYSQL_DEFAULT_AUTH' declared here
  MYSQL_DEFAULT_AUTH,
  ^
2 warnings and 10 errors generated.
make: *** [client.o] Error 1
make failed, exit code 2
Gem files will remain installed in /Users/mac/.rvm/gems/ruby-2.3.1/gems/mysql2-0.3.20 for inspection.
Results logged to /Users/mac/.rvm/gems/ruby-2.3.1/extensions/x86_64-darwin-17/2.3.0/mysql2-0.3.20/gem_make.out
An error occurred while installing mysql2 (0.3.20), and Bundler cannot continue.
Make sure that `gem install mysql2 -v '0.3.20' --source 'https://rubygems.org/'` succeeds before bundling.
In Gemfile:
  mysql2
I then follow the instructions and 
gem install mysql2 -v '0.3.20' --source 'https://rubygems.org/'
Building native extensions.  This could take a while...
ERROR:  Error installing mysql2:
    ERROR: Failed to build gem native extension.
    current directory: /Users/mac/.rvm/gems/ruby-2.3.1/gems/mysql2-0.3.20/ext/mysql2
/Users/mac/.rvm/rubies/ruby-2.3.1/bin/ruby -r ./siteconf20180707-34132-p3fohi.rb extconf.rb
checking for ruby/thread.h... yes
checking for rb_thread_call_without_gvl() in ruby/thread.h... yes
checking for rb_thread_blocking_region()... no
checking for rb_wait_for_single_fd()... yes
checking for rb_hash_dup()... yes
checking for rb_intern3()... yes
-----
Using mysql_config at /usr/local/bin/mysql_config
-----
checking for mysql.h... yes
checking for errmsg.h... yes
checking for mysqld_error.h... yes
-----
Setting rpath to /usr/local/Cellar/mysql/8.0.11/lib
-----
creating Makefile
current directory: /Users/mac/.rvm/gems/ruby-2.3.1/gems/mysql2-0.3.20/ext/mysql2
make ""DESTDIR="" clean
current directory: /Users/mac/.rvm/gems/ruby-2.3.1/gems/mysql2-0.3.20/ext/mysql2
make ""DESTDIR=""
compiling infile.c
compiling client.c
client.c:367:33: warning: implicit conversion loses integer precision: 'long' to 'unsigned int' [-Wshorten-64-to-32]
        elapsed_time = end_time - start_time;
                     ~ ~~~~~~~~~^~~~~~~~~~~~
client.c:439:3: error: use of undeclared identifier 'my_bool'
  my_bool res = mysql_read_query_result(client);
  ^
client.c:441:19: error: use of undeclared identifier 'res'
  return (void *)(res == 0 ? Qtrue : Qfalse);
                  ^
client.c:775:3: error: use of undeclared identifier 'my_bool'
  my_bool boolval;
  ^
client.c:806:7: error: use of undeclared identifier 'boolval'
      boolval = (value == Qfalse ? 0 : 1);
      ^
client.c:807:17: error: use of undeclared identifier 'boolval'
      retval = &amp;boolval;
                ^
client.c:810:10: error: use of undeclared identifier 'MYSQL_SECURE_AUTH'; did you mean 'MYSQL_DEFAULT_AUTH'?
    case MYSQL_SECURE_AUTH:
         ^~~~~~~~~~~~~~~~~
         MYSQL_DEFAULT_AUTH
/usr/local/Cellar/mysql/8.0.11/include/mysql/mysql.h:188:3: note: 'MYSQL_DEFAULT_AUTH' declared here
  MYSQL_DEFAULT_AUTH,
  ^
client.c:811:7: error: use of undeclared identifier 'boolval'
      boolval = (value == Qfalse ? 0 : 1);
      ^
client.c:812:17: error: use of undeclared identifier 'boolval'
      retval = &amp;boolval;
                ^
client.c:843:38: error: use of undeclared identifier 'boolval'
        wrapper-&gt;reconnect_enabled = boolval;
                                     ^
client.c:1165:56: warning: implicit conversion loses integer precision: 'size_t' (aka 'unsigned long') to 'unsigned int' [-Wshorten-64-to-32]
  mysql2rb = mysql2_mysql_enc_name_to_rb(charset_name, charset_name_len);
             ~~~~~~~~~~~~~~~~~~~~~~~~~~~               ^~~~~~~~~~~~~~~~
client.c:1198:38: error: use of undeclared identifier 'MYSQL_SECURE_AUTH'; did you mean 'MYSQL_DEFAULT_AUTH'?
  return _mysql_client_options(self, MYSQL_SECURE_AUTH, value);
                                     ^~~~~~~~~~~~~~~~~
                                     MYSQL_DEFAULT_AUTH
/usr/local/Cellar/mysql/8.0.11/include/mysql/mysql.h:188:3: note: 'MYSQL_DEFAULT_AUTH' declared here
  MYSQL_DEFAULT_AUTH,
  ^
2 warnings and 10 errors generated.
make: *** [client.o] Error 1
make failed, exit code 2
Gem files will remain installed in /Users/mac/.rvm/gems/ruby-2.3.1/gems/mysql2-0.3.20 for inspection.
Results logged to /Users/mac/.rvm/gems/ruby-2.3.1/extensions/x86_64-darwin-17/2.3.0/mysql2-0.3.20/gem_make.out
I have tried the solution mentioned here  
Ruby gem mysql2 install failing
brew install mysql
Warning: mysql 8.0.11 is already installed and up-to-date
To reinstall 8.0.11, run `brew reinstall mysql`
and then 
gem install mysql2
Building native extensions.  This could take a while...
Successfully installed mysql2-0.5.2
Parsing documentation for mysql2-0.5.2
Done installing documentation for mysql2 after 0 seconds
1 gem installed
but when I do bundle install again I still get all of these errors
strangely if I run
 brew reinstall mysql
==&gt; Reinstalling mysql 
==&gt; Downloading https://homebrew.bintray.com/bottles/mysql-8.0.11.high_sierra.bottle.tar.gz
Already downloaded: /Users/mac/Library/Caches/Homebrew/mysql-8.0.11.high_sierra.bottle.tar.gz
==&gt; Pouring mysql-8.0.11.high_sierra.bottle.tar.gz
==&gt; /usr/local/Cellar/mysql/8.0.11/bin/mysqld --initialize-insecure --user=mac --basedir=/usr/local/Cellar/mysql/8.0.11 --datadir=/usr/local/var/mysql --tmpdir=/tmp
Last 15 lines from /Users/mac/Library/Logs/Homebrew/mysql/post_install.01.mysqld:
2018-07-07 23:56:01 -0500
/usr/local/Cellar/mysql/8.0.11/bin/mysqld
--initialize-insecure
--user=mac
--basedir=/usr/local/Cellar/mysql/8.0.11
--datadir=/usr/local/var/mysql
--tmpdir=/tmp
2018-07-08T04:56:01.743929Z 0 [System] [MY-013169] [Server] /usr/local/Cellar/mysql/8.0.11/bin/mysqld (mysqld 8.0.11) initializing of server in progress as process 35410
2018-07-08T04:56:01.746039Z 0 [ERROR] [MY-010457] [Server] --initialize specified but the data directory has files in it. Aborting.
2018-07-08T04:56:01.746086Z 0 [ERROR] [MY-010119] [Server] Aborting
2018-07-08T04:56:01.746293Z 0 [System] [MY-010910] [Server] /usr/local/Cellar/mysql/8.0.11/bin/mysqld: Shutdown complete (mysqld 8.0.11)  Homebrew.
Warning: The post-install step did not complete successfully
You can try again using `brew postinstall mysql`
==&gt; Caveats
We've installed your MySQL database without a root password. To secure it run:
    mysql_secure_installation
MySQL is configured to only allow connections from localhost by default
To connect run:
    mysql -uroot
To have launchd start mysql now and restart at login:
  brew services start mysql
Or, if you don't want/need a background service you can just run:
  mysql.server start
==&gt; Summary
🍺  /usr/local/Cellar/mysql/8.0.11: 254 files, 232.6MB
which is confusing and truthfully I don't 100% percent understand and may very well be a root of the problem, but don't know.
I have updated to the latest version of XCode and installed the Development Tools
here is what my gemfile.lock looks like 
GEM
  remote: https://rubygems.org/
  specs:
    actionmailer (4.2.0)
      actionpack (= 4.2.0)
      actionview (= 4.2.0)
      activejob (= 4.2.0)
      mail (~&gt; 2.5, &gt;= 2.5.4)
      rails-dom-testing (~&gt; 1.0, &gt;= 1.0.5)
    actionpack (4.2.0)
      actionview (= 4.2.0)
      activesupport (= 4.2.0)
      rack (~&gt; 1.6.0)
      rack-test (~&gt; 0.6.2)
      rails-dom-testing (~&gt; 1.0, &gt;= 1.0.5)
      rails-html-sanitizer (~&gt; 1.0, &gt;= 1.0.1)
    actionview (4.2.0)
      activesupport (= 4.2.0)
      builder (~&gt; 3.1)
      erubis (~&gt; 2.7.0)
      rails-dom-testing (~&gt; 1.0, &gt;= 1.0.5)
      rails-html-sanitizer (~&gt; 1.0, &gt;= 1.0.1)
    activejob (4.2.0)
      activesupport (= 4.2.0)
      globalid (&gt;= 0.3.0)
    activemodel (4.2.0)
      activesupport (= 4.2.0)
      builder (~&gt; 3.1)
    activerecord (4.2.0)
      activemodel (= 4.2.0)
      activesupport (= 4.2.0)
      arel (~&gt; 6.0)
    activesupport (4.2.0)
      i18n (~&gt; 0.7)
      json (~&gt; 1.7, &gt;= 1.7.7)
      minitest (~&gt; 5.1)
      thread_safe (~&gt; 0.3, &gt;= 0.3.4)
      tzinfo (~&gt; 1.1)
    addressable (2.4.0)
    arel (6.0.3)
    authority (3.1.0)
      activesupport (&gt;= 3.0.0)
      rake (&gt;= 0.8.7)
    autoprefixer-rails (6.3.6.2)
      execjs
    aws_cf_signer (0.1.3)
    bcrypt (3.1.11)
    better_errors (2.1.1)
      coderay (&gt;= 1.0.0)
      erubis (&gt;= 2.6.6)
      rack (&gt;= 0.9.0)
    binding_of_caller (0.7.2)
      debug_inspector (&gt;= 0.0.1)
    bootstrap-sass (3.3.6)
      autoprefixer-rails (&gt;= 5.2.1)
      sass (&gt;= 3.3.4)
    builder (3.2.2)
    byebug (9.0.4)
    carrierwave (0.11.2)
      activemodel (&gt;= 3.2.0)
      activesupport (&gt;= 3.2.0)
      json (&gt;= 1.7)
      mime-types (&gt;= 1.16)
      mimemagic (&gt;= 0.3.0)
    celluloid (0.16.0)
      timers (~&gt; 4.0.0)
    chartkick (2.0.0)
    ckeditor (4.1.6)
      cocaine
      orm_adapter (~&gt; 0.5.0)
    climate_control (0.0.3)
      activesupport (&gt;= 3.0)
    cloudinary (1.1.7)
      aws_cf_signer
      rest-client
    cocaine (0.5.8)
      climate_control (&gt;= 0.0.3, &lt; 1.0)
    coderay (1.1.1)
    coffee-rails (4.1.1)
      coffee-script (&gt;= 2.2.0)
      railties (&gt;= 4.0.0, &lt; 5.1.x)
    coffee-script (2.4.1)
      coffee-script-source
      execjs
    coffee-script-source (1.10.0)
    concurrent-ruby (1.0.2)
    connection_pool (2.2.0)
    debug_inspector (0.0.2)
    devise (4.1.1)
      bcrypt (~&gt; 3.0)
      orm_adapter (~&gt; 0.1)
      railties (&gt;= 4.1.0, &lt; 5.1)
      responders
      warden (~&gt; 1.2.3)
    dotenv (2.1.1)
    dotenv-rails (2.1.1)
      dotenv (= 2.1.1)
      railties (&gt;= 4.0, &lt; 5.1)
    erubis (2.7.0)
    execjs (2.7.0)
    faraday (0.11.0)
      multipart-post (&gt;= 1.2, &lt; 3)
    font-awesome-rails (4.6.3.0)
      railties (&gt;= 3.2, &lt; 5.1)
    friendly_id (5.1.0)
      activerecord (&gt;= 4.0.0)
    globalid (0.3.6)
      activesupport (&gt;= 4.1.0)
    groupdate (3.0.0)
      activesupport (&gt;= 3)
    hashie (3.5.5)
    hitimes (1.2.4)
    i18n (0.7.0)
    ice_cube (0.11.1)
    jbuilder (2.4.1)
      activesupport (&gt;= 3.0.0, &lt; 5.1)
      multi_json (~&gt; 1.2)
    jquery-rails (4.1.1)
      rails-dom-testing (&gt;= 1, &lt; 3)
      railties (&gt;= 4.2.0)
      thor (&gt;= 0.14, &lt; 2.0)
    jquery-ui-rails (4.2.1)
      railties (&gt;= 3.2.16)
    json (1.8.3)
    jwt (1.5.6)
    kaminari (0.16.3)
      actionpack (&gt;= 3.0.0)
      activesupport (&gt;= 3.0.0)
    libv8 (3.16.14.15)
    loofah (2.0.3)
      nokogiri (&gt;= 1.5.9)
    mail (2.6.4)
      mime-types (&gt;= 1.16, &lt; 4)
    meta-tags (2.1.0)
      actionpack (&gt;= 3.0.0)
    mime-types (3.1)
      mime-types-data (~&gt; 3.2015)
    mime-types-data (3.2016.0521)
    mimemagic (0.3.1)
    mini_magick (4.5.1)
    mini_portile2 (2.0.0)
    minitest (5.9.0)
    multi_json (1.12.1)
    multi_xml (0.6.0)
    multipart-post (2.0.0)
    mysql2 (0.3.20)
    newrelic_rpm (3.15.2.317)
    nokogiri (1.6.7.2)
      mini_portile2 (~&gt; 2.0.0.rc2)
    oauth2 (1.3.1)
      faraday (&gt;= 0.8, &lt; 0.12)
      jwt (~&gt; 1.0)
      multi_json (~&gt; 1.3)
      multi_xml (~&gt; 0.5)
      rack (&gt;= 1.2, &lt; 3)
    omniauth (1.6.1)
      hashie (&gt;= 3.4.6, &lt; 3.6.0)
      rack (&gt;= 1.6.2, &lt; 3)
    omniauth-facebook (4.0.0)
      omniauth-oauth2 (~&gt; 1.2)
    omniauth-oauth2 (1.4.0)
      oauth2 (~&gt; 1.0)
      omniauth (~&gt; 1.2)
    orm_adapter (0.5.0)
    polyamorous (1.3.0)
      activerecord (&gt;= 3.0)
    quiet_assets (1.1.0)
      railties (&gt;= 3.1, &lt; 5.0)
    rack (1.6.5)
    rack-canonical-host (0.2.2)
      addressable (&gt; 0, &lt; 3)
      rack (&gt;= 1.0.0, &lt; 3)
    rack-protection (1.5.3)
      rack
    rack-test (0.6.3)
      rack (&gt;= 1.0)
    rails (4.2.0)
      actionmailer (= 4.2.0)
      actionpack (= 4.2.0)
      actionview (= 4.2.0)
      activejob (= 4.2.0)
      activemodel (= 4.2.0)
      activerecord (= 4.2.0)
      activesupport (= 4.2.0)
      bundler (&gt;= 1.3.0, &lt; 2.0)
      railties (= 4.2.0)
      sprockets-rails
    rails-deprecated_sanitizer (1.0.3)
      activesupport (&gt;= 4.2.0.alpha)
    rails-dom-testing (1.0.7)
      activesupport (&gt;= 4.2.0.beta, &lt; 5.0)
      nokogiri (~&gt; 1.6.0)
      rails-deprecated_sanitizer (&gt;= 1.0.1)
    rails-html-sanitizer (1.0.3)
      loofah (~&gt; 2.0)
    rails-i18n (4.0.8)
      i18n (~&gt; 0.7)
      railties (~&gt; 4.0)
    rails_12factor (0.0.3)
      rails_serve_static_assets
      rails_stdout_logging
    rails_serve_static_assets (0.0.5)
    rails_stdout_logging (0.0.5)
    railties (4.2.0)
      actionpack (= 4.2.0)
      activesupport (= 4.2.0)
      rake (&gt;= 0.8.7)
      thor (&gt;= 0.18.1, &lt; 2.0)
    rake (11.1.2)
    ranked-model (0.4.0)
      activerecord (&gt;= 3.1.12)
    ransack (1.7.0)
      actionpack (&gt;= 3.0)
      activerecord (&gt;= 3.0)
      activesupport (&gt;= 3.0)
      i18n
      polyamorous (~&gt; 1.2)
    rdoc (4.2.2)
      json (~&gt; 1.4)
    redis (3.3.0)
    redis-namespace (1.5.2)
      redis (~&gt; 3.0, &gt;= 3.0.4)
    ref (2.0.0)
    responders (2.2.0)
      railties (&gt;= 4.2.0, &lt; 5.1)
    rest-client (1.6.7)
      mime-types (&gt;= 1.16)
    sass (3.4.22)
    sass-rails (5.0.4)
      railties (&gt;= 4.0.0, &lt; 5.0)
      sass (~&gt; 3.1)
      sprockets (&gt;= 2.8, &lt; 4.0)
      sprockets-rails (&gt;= 2.0, &lt; 4.0)
      tilt (&gt;= 1.1, &lt; 3)
    sdoc (0.4.1)
      json (~&gt; 1.7, &gt;= 1.7.7)
      rdoc (~&gt; 4.0)
    sidekiq (3.4.2)
      celluloid (~&gt; 0.16.0)
      connection_pool (~&gt; 2.2, &gt;= 2.2.0)
      json (~&gt; 1.0)
      redis (~&gt; 3.2, &gt;= 3.2.1)
      redis-namespace (~&gt; 1.5, &gt;= 1.5.2)
    sidetiq (0.6.3)
      celluloid (&gt;= 0.14.1)
      ice_cube (= 0.11.1)
      sidekiq (&gt;= 3.0.0)
    sinatra (1.4.7)
      rack (~&gt; 1.5)
      rack-protection (~&gt; 1.4)
      tilt (&gt;= 1.3, &lt; 3)
    slim (3.0.7)
      temple (~&gt; 0.7.6)
      tilt (&gt;= 1.3.3, &lt; 2.1)
    slim-rails (3.0.1)
      actionmailer (&gt;= 3.1, &lt; 5.0)
      actionpack (&gt;= 3.1, &lt; 5.0)
      activesupport (&gt;= 3.1, &lt; 5.0)
      railties (&gt;= 3.1, &lt; 5.0)
      slim (~&gt; 3.0)
    spring (1.7.1)
    sprockets (3.6.0)
      concurrent-ruby (~&gt; 1.0)
      rack (&gt; 1, &lt; 3)
    sprockets-rails (3.0.4)
      actionpack (&gt;= 4.0)
      activesupport (&gt;= 4.0)
      sprockets (&gt;= 3.0.0)
    temple (0.7.7)
    therubyracer (0.12.2)
      libv8 (~&gt; 3.16.14.0)
      ref
    thor (0.19.1)
    thread_safe (0.3.5)
    tilt (2.0.4)
    timers (4.0.4)
      hitimes
    tzinfo (1.2.2)
      thread_safe (~&gt; 0.1)
    uglifier (3.0.0)
      execjs (&gt;= 0.3.0, &lt; 3)
    warden (1.2.6)
      rack (&gt;= 1.0)
    web-console (2.3.0)
      activemodel (&gt;= 4.0)
      binding_of_caller (&gt;= 0.7.2)
      railties (&gt;= 4.0)
      sprockets-rails (&gt;= 2.0, &lt; 4.0)
PLATFORMS
  ruby
DEPENDENCIES
  authority (~&gt; 3.0)
  bcrypt (~&gt; 3.1.7)
  better_errors
  bootstrap-sass (~&gt; 3.3.6)
  byebug
  carrierwave
  chartkick
  ckeditor
  cloudinary
  coffee-rails (~&gt; 4.1.0)
  devise
  dotenv-rails
  font-awesome-rails
  friendly_id
  groupdate
  jbuilder (~&gt; 2.0)
  jquery-rails
  jquery-ui-rails (~&gt; 4.2.1)
  kaminari (~&gt; 0.15)
  meta-tags
  mini_magick
  mysql2 (~&gt; 0.3.20)
  newrelic_rpm
  omniauth-facebook
  quiet_assets
  rack-canonical-host
  rails (= 4.2.0)
  rails-i18n
  rails_12factor
  ranked-model
  ransack
  sass-rails (~&gt; 5.0)
  sdoc (~&gt; 0.4.0)
  sidekiq (~&gt; 3.4.2)
  sidetiq (~&gt; 0.6)
  sinatra (&gt;= 1.3.0)
  slim-rails
  spring
  therubyracer
  uglifier (&gt;= 1.3.0)
  web-console (~&gt; 2.0)
RUBY VERSION
   ruby 2.3.1p112
BUNDLED WITH
   1.12.5
I also tried giving more specific commands like this answer recommended
https://stackoverflow.com/a/32869742/8239783
but I still get the same errors. 
gem install mysql2 -v '0.3.20' -- --with-mysql-config=/usr/local/Cellar/mysql/8.0.11/bin/mysql_config
Building native extensions with: '--with-mysql-config=/usr/local/Cellar/mysql/8.0.11/bin/mysql_config'
This could take a while...
ERROR:  Error installing mysql2:
    ERROR: Failed to build gem native extension.
    current directory: /Users/mac/.rvm/gems/ruby-2.3.1/gems/mysql2-0.3.20/ext/mysql2
/Users/mac/.rvm/rubies/ruby-2.3.1/bin/ruby -r ./siteconf20180708-38248-vd681p.rb extconf.rb --with-mysql-config=/usr/local/Cellar/mysql/8.0.11/bin/mysql_config
checking for ruby/thread.h... yes
checking for rb_thread_call_without_gvl() in ruby/thread.h... yes
checking for rb_thread_blocking_region()... no
checking for rb_wait_for_single_fd()... yes
checking for rb_hash_dup()... yes
checking for rb_intern3()... yes
-----
Using mysql_config at /usr/local/Cellar/mysql/8.0.11/bin/mysql_config
-----
checking for mysql.h... yes
checking for errmsg.h... yes
checking for mysqld_error.h... yes
-----
Setting rpath to /usr/local/Cellar/mysql/8.0.11/lib
-----
creating Makefile
current directory: /Users/mac/.rvm/gems/ruby-2.3.1/gems/mysql2-0.3.20/ext/mysql2
make ""DESTDIR="" clean
current directory: /Users/mac/.rvm/gems/ruby-2.3.1/gems/mysql2-0.3.20/ext/mysql2
make ""DESTDIR=""
compiling infile.c
compiling client.c
client.c:367:33: warning: implicit conversion loses integer precision: 'long' to 'unsigned int' [-Wshorten-64-to-32]
        elapsed_time = end_time - start_time;
                     ~ ~~~~~~~~~^~~~~~~~~~~~
client.c:439:3: error: use of undeclared identifier 'my_bool'
  my_bool res = mysql_read_query_result(client);
  ^
client.c:441:19: error: use of undeclared identifier 'res'
  return (void *)(res == 0 ? Qtrue : Qfalse);
                  ^
client.c:775:3: error: use of undeclared identifier 'my_bool'
  my_bool boolval;
  ^
client.c:806:7: error: use of undeclared identifier 'boolval'
      boolval = (value == Qfalse ? 0 : 1);
      ^
client.c:807:17: error: use of undeclared identifier 'boolval'
      retval = &amp;boolval;
                ^
client.c:810:10: error: use of undeclared identifier 'MYSQL_SECURE_AUTH'; did you mean 'MYSQL_DEFAULT_AUTH'?
    case MYSQL_SECURE_AUTH:
         ^~~~~~~~~~~~~~~~~
         MYSQL_DEFAULT_AUTH
/usr/local/Cellar/mysql/8.0.11/include/mysql/mysql.h:188:3: note: 'MYSQL_DEFAULT_AUTH' declared here
  MYSQL_DEFAULT_AUTH,
  ^
client.c:811:7: error: use of undeclared identifier 'boolval'
      boolval = (value == Qfalse ? 0 : 1);
      ^
client.c:812:17: error: use of undeclared identifier 'boolval'
      retval = &amp;boolval;
                ^
client.c:843:38: error: use of undeclared identifier 'boolval'
        wrapper-&gt;reconnect_enabled = boolval;
                                     ^
client.c:1165:56: warning: implicit conversion loses integer precision: 'size_t' (aka 'unsigned long') to 'unsigned int' [-Wshorten-64-to-32]
  mysql2rb = mysql2_mysql_enc_name_to_rb(charset_name, charset_name_len);
             ~~~~~~~~~~~~~~~~~~~~~~~~~~~               ^~~~~~~~~~~~~~~~
client.c:1198:38: error: use of undeclared identifier 'MYSQL_SECURE_AUTH'; did you mean 'MYSQL_DEFAULT_AUTH'?
  return _mysql_client_options(self, MYSQL_SECURE_AUTH, value);
                                     ^~~~~~~~~~~~~~~~~
                                     MYSQL_DEFAULT_AUTH
/usr/local/Cellar/mysql/8.0.11/include/mysql/mysql.h:188:3: note: 'MYSQL_DEFAULT_AUTH' declared here
  MYSQL_DEFAULT_AUTH,
  ^
2 warnings and 10 errors generated.
make: *** [client.o] Error 1
make failed, exit code 2
Gem files will remain installed in /Users/mac/.rvm/gems/ruby-2.3.1/gems/mysql2-0.3.20 for inspection.
Results logged to /Users/mac/.rvm/gems/ruby-2.3.1/extensions/x86_64-darwin-17/2.3.0/mysql2-0.3.20/gem_make.out
Here is the log for my mysql_config file 
mysql_config
Usage: /usr/local/bin/mysql_config [OPTIONS]
Compiler: Clang 9.1.0.9020039
Options:
        --cflags         [-I/usr/local/Cellar/mysql/8.0.11/include/mysql ]
        --cxxflags       [-I/usr/local/Cellar/mysql/8.0.11/include/mysql ]
        --include        [-I/usr/local/Cellar/mysql/8.0.11/include/mysql]
        --libs           [-L/usr/local/Cellar/mysql/8.0.11/lib -lmysqlclient -lssl -lcrypto]
        --libs_r         [-L/usr/local/Cellar/mysql/8.0.11/lib -lmysqlclient -lssl -lcrypto]
        --plugindir      [/usr/local/Cellar/mysql/8.0.11/lib/plugin]
        --socket         [/tmp/mysql.sock]
        --port           [0]
        --version        [8.0.11]
        --variable=VAR   VAR is one of:
                pkgincludedir [/usr/local/Cellar/mysql/8.0.11/include/mysql]
                pkglibdir     [/usr/local/Cellar/mysql/8.0.11/lib]
                plugindir     [/usr/local/Cellar/mysql/8.0.11/lib/plugin]
I am on a Mac High Sierra 10.13.4
I would love any advice I could get on it as it is driving me crazy.  Please let me know any other information I could provide to ask a better question.    
Thank you in advance
",<mysql><ruby-on-rails><rubygems><mysql2>,23894,6,656,281,1,3,7,57,21794,0.0,0,6,20,2018-07-08 4:46,2018-07-11 16:59,,3.0,,Basic,2
64647851,The stock item was unable to be saved. Please try again. Magento 2.4.0,"I installed magento 2.4.0 on my Linux server from godaddy. I'm unable to add the products to it. It is showing the Error is The stock item was unable to be saved. Please try again. Can any one help me from this please
",<php><mysql><linux><magento><magento2>,218,1,1,331,1,2,6,69,24333,0.0,0,9,20,2020-11-02 14:53,2020-11-04 5:14,,2.0,,Basic,14
56554159,TypeError: Object of type 'datetime' is not JSON serializable (with serialize function),"I'm  I getting this TypeError: Object of type 'datetime' is not JSON serializable error, even though I have a specific serialize function described in my model.
This is my code:
Flask route (rendered by React):
menus.py
@menus_bp.route('/menus', methods=['GET', 'POST'])
def menus():
    response_object = {
        'status': 'fail',
        'message': 'Invalid payload.'
        }
    try:
        user = User.query.filter_by(id=1).first()
        if user.menu == []:
            return edit_menu()
        else:
            template = render_template('menus.html')
            response_object = {
                'status': 'success',
                'message': 'success',
                'data': [{""restaurant"": user.restaurant,
                          ""menu"": menu,
                          ""content"": template}] # template passed to React
                }
            # db method
            Create_Menu(user=user)
        return jsonify(response_object), 200
    except (exc.IntegrityError, ValueError):
        db.session.rollback()
        return jsonify(response_object), 400
methods.py
def Create_Menu(user):
    menu = Menu(user=user)
    db.session.add(menu)
    db.session.commit()
    return {""status"": True,
            ""menu"": menu}
and finally the Menu model, which has a serialize() function:
class Menu(db.Model):
    __tablename__='menu'
    """"""
    Model for storing menus. 
    """"""   
    id = db.Column(db.Integer, primary_key=True)
    created = db.Column(db.DateTime, default=func.now(), nullable=False)       
    user_id = db.Column(db.Integer, db.ForeignKey('users.id'))
    def __init__(self, user):
        self.user = user
    def serialize(self):
       return { 'id' : self.id,
                'created': self.created,
                'coffees' : [ item.serialize() for item in self.coffees]}
But I'm getting the following traceback:
TypeError: Object of type 'datetime' is not JSON serializable
File ""/usr/lib/python3.6/site-packages/flask/app.py"", line 2309, in __call__
return self.wsgi_app(environ, start_response)
File ""/usr/lib/python3.6/site-packages/flask/app.py"", line 2295, in wsgi_app
response = self.handle_exception(e)
File ""/usr/lib/python3.6/site-packages/flask_restful/__init__.py"", line 269, in error_router
return original_handler(e)
File ""/usr/lib/python3.6/site-packages/flask_cors/extension.py"", line 161, in wrapped_function
return cors_after_request(app.make_response(f(*args, **kwargs)))
File ""/usr/lib/python3.6/site-packages/flask/app.py"", line 1741, in handle_exception
reraise(exc_type, exc_value, tb)
File ""/usr/lib/python3.6/site-packages/flask/_compat.py"", line 34, in reraise
raise value.with_traceback(tb)
File ""/usr/lib/python3.6/site-packages/flask/app.py"", line 2292, in wsgi_app
response = self.full_dispatch_request()
File ""/usr/lib/python3.6/site-packages/flask/app.py"", line 1815, in full_dispatch_request
rv = self.handle_user_exception(e)
File ""/usr/lib/python3.6/site-packages/flask_restful/__init__.py"", line 269, in error_router
return original_handler(e)
File ""/usr/lib/python3.6/site-packages/flask_cors/extension.py"", line 161, in wrapped_function
return cors_after_request(app.make_response(f(*args, **kwargs)))
File ""/usr/lib/python3.6/site-packages/flask/app.py"", line 1718, in handle_user_exception
reraise(exc_type, exc_value, tb)
File ""/usr/lib/python3.6/site-packages/flask/_compat.py"", line 34, in reraise
raise value.with_traceback(tb)
File ""/usr/lib/python3.6/site-packages/flask/app.py"", line 1813, in full_dispatch_request
rv = self.dispatch_request()
File ""/usr/lib/python3.6/site-packages/flask_debugtoolbar/__init__.py"", line 125, in dispatch_request
return view_func(**req.view_args)
File ""/usr/lib/python3.6/site-packages/flask_restful/__init__.py"", line 462, in wrapper
return self.make_response(data, code, headers=headers)
File ""/usr/lib/python3.6/site-packages/flask_restful/__init__.py"", line 491, in make_response
resp = self.representations[mediatype](data, *args, **kwargs)
File ""/usr/lib/python3.6/site-packages/flask_restful/representations/json.py"", line 21, in output_json
dumped = dumps(data, **settings) + ""\n""
File ""/usr/lib/python3.6/json/__init__.py"", line 238, in dumps
**kw).encode(obj)
File ""/usr/lib/python3.6/json/encoder.py"", line 201, in encode
chunks = list(chunks)
File ""/usr/lib/python3.6/json/encoder.py"", line 430, in _iterencode
yield from _iterencode_dict(o, _current_indent_level)
File ""/usr/lib/python3.6/json/encoder.py"", line 404, in _iterencode_dict
yield from chunks
File ""/usr/lib/python3.6/json/encoder.py"", line 404, in _iterencode_dict
yield from chunks
File ""/usr/lib/python3.6/json/encoder.py"", line 325, in _iterencode_list
yield from chunks
File ""/usr/lib/python3.6/json/encoder.py"", line 404, in _iterencode_dict
yield from chunks
File ""/usr/lib/python3.6/json/encoder.py"", line 325, in _iterencode_list
yield from chunks
File ""/usr/lib/python3.6/json/encoder.py"", line 404, in _iterencode_dict
yield from chunks
File ""/usr/lib/python3.6/json/encoder.py"", line 437, in _iterencode
o = _default(o)
File ""/usr/lib/python3.6/json/encoder.py"", line 180, in default
o.__class__.__name__)
TypeError: Object of type 'datetime' is not JSON serializable
It used to work when I was redering templates with Flask at backend, but now with frontend requets, it breaks with the erro above.
what is wrong now? why does not my serialize function work anymore? 
",<python><json><flask><serialization><sqlalchemy>,5392,0,112,9734,30,103,203,52,30001,0.0,1849,3,20,2019-06-12 3:08,2019-06-12 12:45,2019-06-12 12:45,0.0,0.0,Intermediate,15
50172067,SqlConnection Error if EXE is executed from network path,"
  First of all: everything you will read in this post happens only if Windows 10 April 2018 update is installed. No problem before installation and after update uninstallation.
After installing Windows 10 1803 update, all my VB program (VB6, .NET and WPF) running from network mapped drive or UNC path can't connect to SQL server, no problem if the same executable is placed and executed from local drive (tested on 2 pc in the same network):
Remote SQL server, exe on local drive: OK
Same remote SQL server, same exe on mapped network drive (with full read/write access): ERROR
This is the error (maybe not significat to solve this problem):
  A network-related or instance-specific error occurred while establishing a connection to SQL Server. The server was not found or was not accessible. Verify that the instance name is correct and that SQL Server is configured to allow remote connections. (provider: SQL Network Interfaces, error: 26 - Error Locating Server/Instance Specified).
Simple VB.NET code to reproduce the problem (place the code in a simple form with a button in the button_click event, set values to connect to the SQL server, compile, save the exe file on a network path and execute it):
Dim myConnectionString As String
Dim mySqlConnectionStringBuilder As New SqlConnectionStringBuilder()
mySqlConnectionStringBuilder.DataSource = myServer
mySqlConnectionStringBuilder.InitialCatalog = myDatabase
mySqlConnectionStringBuilder.UserID = myUtente
mySqlConnectionStringBuilder.Password = myPassword
myConnectionString = mySqlConnectionStringBuilder.ConnectionString
Dim mySqlConnection As New SqlConnection(myConnectionString)
mySqlConnection.Open()  &lt;- error
Exception:
System.Data.SqlClient.SqlException (0x80131904): Si è verificato un errore di rete o specifico dell'istanza mentre si cercava di stabilire una connessione con SQL Server. Il server non è stato trovato o non è accessibile. Verificare che il nome dell'istanza sia corretto e che SQL Server sia configurato in modo da consentire connessioni remote. (provider: SQL Network Interfaces, error: 26 - Errore nell'individuazione del server/dell'istanza specificata)
   in System.Data.SqlClient.SqlInternalConnectionTds..ctor(DbConnectionPoolIdentity identity, SqlConnectionString connectionOptions, SqlCredential credential, Object providerInfo, String newPassword, SecureString newSecurePassword, Boolean redirectedUserInstance, SqlConnectionString userConnectionOptions, SessionData reconnectSessionData, DbConnectionPool pool, String accessToken, Boolean applyTransientFaultHandling, SqlAuthenticationProviderManager sqlAuthProviderManager)
   in System.Data.SqlClient.SqlConnectionFactory.CreateConnection(DbConnectionOptions options, DbConnectionPoolKey poolKey, Object poolGroupProviderInfo, DbConnectionPool pool, DbConnection owningConnection, DbConnectionOptions userOptions)
   in System.Data.ProviderBase.DbConnectionFactory.CreatePooledConnection(DbConnectionPool pool, DbConnection owningObject, DbConnectionOptions options, DbConnectionPoolKey poolKey, DbConnectionOptions userOptions)
   in System.Data.ProviderBase.DbConnectionPool.CreateObject(DbConnection owningObject, DbConnectionOptions userOptions, DbConnectionInternal oldConnection)
   in System.Data.ProviderBase.DbConnectionPool.UserCreateRequest(DbConnection owningObject, DbConnectionOptions userOptions, DbConnectionInternal oldConnection)
   in System.Data.ProviderBase.DbConnectionPool.TryGetConnection(DbConnection owningObject, UInt32 waitForMultipleObjectsTimeout, Boolean allowCreate, Boolean onlyOneCheckConnection, DbConnectionOptions userOptions, DbConnectionInternal&amp; connection)
   in System.Data.ProviderBase.DbConnectionPool.TryGetConnection(DbConnection owningObject, TaskCompletionSource`1 retry, DbConnectionOptions userOptions, DbConnectionInternal&amp; connection)
   in System.Data.ProviderBase.DbConnectionFactory.TryGetConnection(DbConnection owningConnection, TaskCompletionSource`1 retry, DbConnectionOptions userOptions, DbConnectionInternal oldConnection, DbConnectionInternal&amp; connection)
   in System.Data.ProviderBase.DbConnectionInternal.TryOpenConnectionInternal(DbConnection outerConnection, DbConnectionFactory connectionFactory, TaskCompletionSource`1 retry, DbConnectionOptions userOptions)
   in System.Data.ProviderBase.DbConnectionClosed.TryOpenConnection(DbConnection outerConnection, DbConnectionFactory connectionFactory, TaskCompletionSource`1 retry, DbConnectionOptions userOptions)
   in System.Data.SqlClient.SqlConnection.TryOpenInner(TaskCompletionSource`1 retry)
   in System.Data.SqlClient.SqlConnection.TryOpen(TaskCompletionSource`1 retry)
   in System.Data.SqlClient.SqlConnection.Open()
   in RiepilogoOreTimer.RiepilogoOreTimerWindow.ConnessioneOK()
ClientConnectionId:00000000-0000-0000-0000-000000000000
Error Number:-1,State:0,Class:20
Any ideas?
Update:
If I uninstall the April 2018 update the issue go away and the program works fine even if executed on a network drive, but this can't be the solution...
Update 08/05/2018:
I noticed that April 2018 update brought some changes in security:
  Windows 10, version 1803 provides additional protections:
  New Attack surface reduction rules 
  Controlled folder access can now block disk sectors
Could it be the cause of the issue?
I'm not a security manager so I can't say if this can cause my problem
Update 09/05/2018: I found this information in this post:
  Windows 10 update 1803 does not open network connections on
  executables files on SMBv1 share (as Windows Server 2003)
but I don't know what SMBv1 is... somebody can help me?
",<sql-server><vb.net><windows-10>,5616,2,27,372,0,2,13,65,4324,0.0,1,4,20,2018-05-04 9:49,2018-05-08 21:08,2018-05-09 10:47,4.0,5.0,Advanced,37
49323419,manually create replication slot for publication in PostgreSQL 10,"I am trying to get a stream of updates for certain tables from my PostgreSQL database. The regular way of getting all updates looks like this:
You create a logical replication slot
pg_create_logical_replication_slot('my_slot', 'wal2json');
And either connect to it using pg_recvlogical or making special SQL queries. This allows you to get all the actions from the database in json (if you used wal2json plugin or similar) and then do whatever you want with that data.
But in PostgreSQL 10 we have Publication/Subscription mechanism which allows us to replicate selected tables only. This is very handy because a lot of useless data is not being sent. The process looks like this:
First, you create a publication
CREATE PUBLICATION foo FOR TABLE herp, derp;
Then you subscribe to that publication from another database
CREATE SUBSCRIPTION mysub CONNECTION &lt;connection stuff&gt; PUBLICATION foo;
This creates a replication slot on a master database under the hood and starts listening to updates and commit them to the same tables on a second database. This is fine if your job was to replicate some tables, but want to get a raw stream for my stuff.
As I mentioned, the CREATE SUBSCRIPTION query is creating a replication slot on the master database under the hood, but how can I create one manually without the subscription and a second database? Here the docs say:
  To make this work, create the replication slot separately (using the function pg_create_logical_replication_slot with the plugin name pgoutput)
According to the docs, this is possible, but pg_create_logical_replication_slot only creates a regular replication slot. Is the pgoutput plugin responsible for all the magic? If yes, then it becomes impossible to use other plugins like wal2json with publications.
What am I missing here?
",<postgresql><replication><postgresql-10>,1804,2,8,988,2,10,25,66,18753,0.0,164,2,20,2018-03-16 14:42,2019-06-21 12:00,,462.0,,Advanced,39
54598531,What determines if rails includes id: :serial in a table definition?,"I'm working with an existing rails app, using postgresql. Its schema.rb file has id: :serial for many, but not all, tables:
create_table ""foos"", id: :serial, force: :cascade do |t|
When I run rails db:migrate:reset, id: :serial is removed. We are all on the same version of postgres, but different OSes. I haven't exhaustively tested the behavior between machines, but I think there is a difference between machines.
The rails version is the same as it was when the project started.
The project did start with sqlite3. When I switch to that and regenerate the file, same behavior.
What could cause this option to be removed in my environment?
here's some code that is probably relevant:
https://github.com/rails/rails/blob/b2eb1d1c55a59fee1e6c4cba7030d8ceb524267c/activerecord/lib/active_record/connection_adapters/postgresql/column.rb#L15-L21
https://github.com/rails/rails/blob/b2eb1d1c55a59fee1e6c4cba7030d8ceb524267c/activerecord/lib/active_record/connection_adapters/postgresql/schema_dumper.rb#L26-L42
update
I just tried rails db:migrate:reset on colleague's machines, and I was wrong! their environments also remove id: :serial.
I looked closer at recent migrations from a colleague, and the most recent one did not create id: :serial in schema.rb either.
",<ruby-on-rails><postgresql><rails-migrations>,1264,4,7,22715,29,156,228,62,8117,0.0,1154,2,20,2019-02-08 18:48,2019-02-14 4:56,2019-02-14 16:24,6.0,6.0,Basic,8
56742757,Why is Azure SQL database so expensive?,"For a small personal coding project I recently created a SQL database in Azure. For the past weeks I have been hardly using the database, out of 2 GB available space I have been using only 13 MB.
However, the database costs me 6,70 EUR per day and I don't understand why this is the case. Read a few topics/posts stating that the costs with similar use should be around 5-7 EUR per month, not per day.
This is the configuration for the database:
No elastic pool
General purpose, Gen5, 2 vCores
West Europe
Does anyone have an idea about what could be causing the costs per month to be so high? 
",<sql><azure><azure-sql-database>,595,0,0,1033,2,12,21,47,13493,0.0,132,7,20,2019-06-24 19:24,2019-06-24 19:33,2019-06-25 2:32,0.0,1.0,Advanced,39
49387428,Which MySQL connector do I use: mysql-connector-java-5.1.46.jar or mysql-connector-java-5.1.46-bin.jar What is the difference?,"I am preparing to use jdbc for the first time and am in the process of installing the jdbc driver for MySQL.
However, it is unclear to me which of these files to move to the WEB_INF/lib folder in Eclipse.  They both seem to contain the same content and are included together in the downloaded zip file for the MySQL connector.
I have searched everywhere but have been unable to find any documentation to explain which of these files to use.
",<java><mysql><jdbc><mysql-connector>,441,0,0,2364,1,19,24,51,8481,0.0,108,1,20,2018-03-20 14:52,2018-03-20 15:38,2018-03-20 15:38,0.0,0.0,Intermediate,19
56808425,SQLAlchemy (psycopg2.ProgrammingError) can't adapt type 'dict',"Couldn't find a solution on the web for my problem.
I am trying to insert this pandas df to a Postgresql table using SQLAlchemy 
Pandas 0.24.2 
sqlalchemy 1.3.3
python 3.7
Relevant part of my code is below:
engine = create_engine('postgresql://user:pass@host:5432/db')
file = open('GameRoundMessageBlackjackSample.json', 'r', encoding='utf-8')
json_dict = json.load(file)
df = json_normalize(json_dict, record_path='cards', meta=['bet', 'dealerId', 'dealerName', 'gameOutcome', 'gameRoundDuration', 'gameRoundId', 'gameType', 'tableId', 'win'])
df = df[['win', 'betAmount', 'bets']]
df.to_sql('test_netent_data', engine, if_exists='append')
When I try to load this table to sql without the column 'bets' everyting works as expected. But when I include it i get the following error:
sqlalchemy.exc.ProgrammingError: (psycopg2.ProgrammingError) can't adapt 
type 'dict'
[SQL: INSERT INTO test_netent_data (index, win, ""betAmount"", bets) VALUES (%(index)s, %(win)s, %(betAmount)s, %(bets)s)]
[parameters: ({'index': 0, 'win': '2000.00', 'betAmount': '1212112', 'bets': [{'name': '1', 'amount': '1212112'}]}, {'index': 1, 'win': '2000.00', 'betAmount': '1212000', 'bets': [{'name': '1', 'amount': '1212000'}]}, {'index': 2, 'win': '2000.00', 'betAmount': '1212112', 'bets': [{'name': '1', 'amount': '1212112'}]}, {'index': 3, 'win': '2000.00', 'betAmount': '1212000', 'bets': [{'name': '1', 'amount': '1212000'}]}, {'index': 4, 'win': '2000.00', 'betAmount': '1212112', 'bets': [{'name': '1', 'amount': '1212112'}]}, {'index': 5, 'win': '2000.00', 'betAmount': '1212000', 'bets': [{'name': '1', 'amount': '1212000'}]}, {'index': 6, 'win': '2000.00', 'betAmount': '1212112', 'bets': [{'name': '1', 'amount': '1212112'}]}, {'index': 7, 'win': '2000.00', 'betAmount': '1212000', 'bets': [{'name': '1', 'amount': '1212000'}]})]
(Background on this error at: http://sqlalche.me/e/f405)
I have checked the type of this column but it is (type object) no different from other columns. Ive also tried to convert it to string and got a bunch of other errors.
I believe there should be a simple solution which I can't get my head around.
",<json><python-3.x><pandas><postgresql><sqlalchemy>,2123,2,13,269,1,2,11,74,50387,0.0,13,4,20,2019-06-28 14:04,2019-06-28 14:55,2019-06-28 14:55,0.0,0.0,Advanced,33
50711207,How to set sql dialect in IntelliJ,"I'm working with IntelliJ 2017. I want to set the SQL dialect for an sql file. After I created the file, there is a message at the top saying the SQL dialect for the file is not set. When I click on the ""Change Dialect to.."" link, it opens an SQL Dialects menu. On the right, there is a pulldown link to select the dialect, but the pull down menu is empty. I went into Preferences > Languages and Frameworks > SQL Dialects to try to add some, but that menu is also empty and I can't seem to modify any of the fields. 
How do I add SQL dialects to IntelliJ, so I can select one for this file? Below is a photo of the menu I get when I select ""Change Dialect to..."" in the sql file 
Below is a photo of the menu I get from Perferences > Languages and Frameworks > SQL Dialects. I can't edit any of the fields.
",<sql><intellij-idea>,808,2,0,267,1,5,13,68,23063,0.0,0,1,20,2018-06-06 1:53,2018-06-06 5:11,,0.0,,Intermediate,20
49291428,Error: could not determine PostgreSQL version from '10.3' - Django on Heroku,"I tried to push from local env to Heroku master. No new requirements from the previous commit. However, I received an Error which saying the system could not determine PostgreSQL version from ""10.3"".
Here is my requirements list:
amqp==1.4.9
anyjson==0.3.3
appdirs==1.4.3
awscli==1.11.89
billiard==3.3.0.23
boto==2.46.1
botocore==1.5.52
celery==3.1.25
Collectfast==0.5.2
colorama==0.3.7
dj-database-url==0.4.2
Django==1.11.1
django-celery==3.2.1
django-recaptcha==1.3.0
django-redis-cache==1.7.1
django-storages==1.5.2
django-storages-redux==1.3.2
docutils==0.13.1
gunicorn==19.7.0
honcho==0.5.0
jmespath==0.9.2
kombu==3.0.37
olefile==0.44
packaging==16.8
Pillow==4.3.0
psycopg2==2.6.2
pyasn1==0.2.3
pyparsing==2.2.0
python-dateutil==2.6.0
pytz==2018.3
PyYAML==3.12
redis==2.10.5
reportlab==3.4.0
rsa==3.4.2
s3transfer==0.1.10
selenium==3.4.0
six==1.10.0
vine==1.1.4
virtualenv==15.1.0
virtualenvwrapper-win==1.2.1
whitenoise==3.3.0
and below is the error in the build log.
Collecting amqp==1.4.9 (from -r /tmp/build_28bcf3a327daae7657433628289c1501/requirements.txt (line 1))
         Downloading amqp-1.4.9-py2.py3-none-any.whl (51kB)
       Collecting anyjson==0.3.3 (from -r /tmp/build_28bcf3a327daae7657433628289c1501/requirements.txt (line 2))
         Downloading anyjson-0.3.3.tar.gz
       Collecting appdirs==1.4.3 (from -r /tmp/build_28bcf3a327daae7657433628289c1501/requirements.txt (line 3))
         Downloading appdirs-1.4.3-py2.py3-none-any.whl
       Collecting awscli==1.11.89 (from -r /tmp/build_28bcf3a327daae7657433628289c1501/requirements.txt (line 4))
         Downloading awscli-1.11.89-py2.py3-none-any.whl (1.2MB)
       Collecting billiard==3.3.0.23 (from -r /tmp/build_28bcf3a327daae7657433628289c1501/requirements.txt (line 5))
         Downloading billiard-3.3.0.23.tar.gz (151kB)
       Collecting boto==2.46.1 (from -r /tmp/build_28bcf3a327daae7657433628289c1501/requirements.txt (line 6))
         Downloading boto-2.46.1-py2.py3-none-any.whl (1.4MB)
       Collecting botocore==1.5.52 (from -r /tmp/build_28bcf3a327daae7657433628289c1501/requirements.txt (line 7))
         Downloading botocore-1.5.52-py2.py3-none-any.whl (3.5MB)
       Collecting celery==3.1.25 (from -r /tmp/build_28bcf3a327daae7657433628289c1501/requirements.txt (line 8))
         Downloading celery-3.1.25-py2.py3-none-any.whl (526kB)
       Collecting Collectfast==0.5.2 (from -r /tmp/build_28bcf3a327daae7657433628289c1501/requirements.txt (line 9))
         Downloading Collectfast-0.5.2-py3-none-any.whl
       Collecting colorama==0.3.7 (from -r /tmp/build_28bcf3a327daae7657433628289c1501/requirements.txt (line 10))
         Downloading colorama-0.3.7-py2.py3-none-any.whl
       Collecting dj-database-url==0.4.2 (from -r /tmp/build_28bcf3a327daae7657433628289c1501/requirements.txt (line 11))
         Downloading dj_database_url-0.4.2-py2.py3-none-any.whl
       Collecting Django==1.11.1 (from -r /tmp/build_28bcf3a327daae7657433628289c1501/requirements.txt (line 12))
         Downloading Django-1.11.1-py2.py3-none-any.whl (6.9MB)
       Collecting django-celery==3.2.1 (from -r /tmp/build_28bcf3a327daae7657433628289c1501/requirements.txt (line 13))
         Downloading django-celery-3.2.1.tar.gz (91kB)
       Collecting django-recaptcha==1.3.0 (from -r /tmp/build_28bcf3a327daae7657433628289c1501/requirements.txt (line 14))
         Downloading django-recaptcha-1.3.0.tar.gz
       Collecting django-redis-cache==1.7.1 (from -r /tmp/build_28bcf3a327daae7657433628289c1501/requirements.txt (line 15))
         Downloading django-redis-cache-1.7.1.tar.gz
       Collecting django-storages==1.5.2 (from -r /tmp/build_28bcf3a327daae7657433628289c1501/requirements.txt (line 16))
         Downloading django_storages-1.5.2-py2.py3-none-any.whl (51kB)
       Collecting django-storages-redux==1.3.2 (from -r /tmp/build_28bcf3a327daae7657433628289c1501/requirements.txt (line 17))
         Downloading django_storages_redux-1.3.2-py2.py3-none-any.whl (41kB)
       Collecting docutils==0.13.1 (from -r /tmp/build_28bcf3a327daae7657433628289c1501/requirements.txt (line 18))
         Downloading docutils-0.13.1-py3-none-any.whl (536kB)
       Collecting gunicorn==19.7.0 (from -r /tmp/build_28bcf3a327daae7657433628289c1501/requirements.txt (line 19))
         Downloading gunicorn-19.7.0-py2.py3-none-any.whl (112kB)
       Collecting honcho==0.5.0 (from -r /tmp/build_28bcf3a327daae7657433628289c1501/requirements.txt (line 20))
         Downloading honcho-0.5.0.tar.gz
       Collecting jmespath==0.9.2 (from -r /tmp/build_28bcf3a327daae7657433628289c1501/requirements.txt (line 21))
         Downloading jmespath-0.9.2-py2.py3-none-any.whl
       Collecting kombu==3.0.37 (from -r /tmp/build_28bcf3a327daae7657433628289c1501/requirements.txt (line 22))
         Downloading kombu-3.0.37-py2.py3-none-any.whl (240kB)
       Collecting olefile==0.44 (from -r /tmp/build_28bcf3a327daae7657433628289c1501/requirements.txt (line 23))
         Downloading olefile-0.44.zip (74kB)
       Collecting packaging==16.8 (from -r /tmp/build_28bcf3a327daae7657433628289c1501/requirements.txt (line 24))
         Downloading packaging-16.8-py2.py3-none-any.whl
       Collecting Pillow==4.3.0 (from -r /tmp/build_28bcf3a327daae7657433628289c1501/requirements.txt (line 25))
         Downloading Pillow-4.3.0-cp35-cp35m-manylinux1_x86_64.whl (5.8MB)
       Collecting psycopg2==2.6.2 (from -r /tmp/build_28bcf3a327daae7657433628289c1501/requirements.txt (line 26))
         Downloading psycopg2-2.6.2.tar.gz (376kB)
           Complete output from command python setup.py egg_info:
           running egg_info
           creating pip-egg-info/psycopg2.egg-info
           writing pip-egg-info/psycopg2.egg-info/PKG-INFO
           writing top-level names to pip-egg-info/psycopg2.egg-info/top_level.txt
           writing dependency_links to pip-egg-info/psycopg2.egg-info/dependency_links.txt
           writing manifest file 'pip-egg-info/psycopg2.egg-info/SOURCES.txt'
           Error: could not determine PostgreSQL version from '10.3'
           ----------------------------------------
       Command ""python setup.py egg_info"" failed with error code 1 in /tmp/pip-build-24iic71n/psycopg2/
 !     Push rejected, failed to compile Python app.
 !     Push failed
Has anyone ever get through this?
",<django><git><postgresql><heroku><psycopg2>,6308,0,106,253,1,2,9,52,20608,0.0,43,1,20,2018-03-15 4:08,2018-03-15 5:38,2018-03-15 5:38,0.0,0.0,Intermediate,17
61981787,"Is there a rule that forbids to name its entity class ""User"" when working with PostgreSQL and Spring Boot?","guys. I'm having a problem with a Spring boot 2.3.0  and PostgreSQL 12 project. I have an entity class I called User whose code is as follows:
@Entity
@NoArgsConstructor
@Data
@AllArgsConstructor
@Builder
public class User {
    @Id @GeneratedValue(strategy = GenerationType.IDENTITY)
    private Long id;
    private String username;
    private String email;
    private String firstName;
    private String lastName;
    private int age;
}
And my application.properties file looks like this:
spring.jpa.hibernate.ddl-auto=create-drop
spring.jpa.hibernate.show-sql=true
spring.datasource.url=jdbc:postgresql://localhost:5432/dbname
spring.datasource.username=postgres
spring.datasource.password=*********
The concern is that when I execute my project I get a mistake like this:
org.hibernate.tool.schema.spi.CommandAcceptanceException: Error executing DDL ""drop table if exists user cascade"" via JDBC Statement
    at org.hibernate.tool.schema.internal.exec.GenerationTargetToDatabase.accept(GenerationTargetToDatabase.java:67) ~[hibernate-core-5.4.15.Final.jar:5.4.15.Final]
    at org.hibernate.tool.schema.internal.SchemaDropperImpl.applySqlString(SchemaDropperImpl.java:375) [hibernate-core-5.4.15.Final.jar:5.4.15.Final]
    at org.hibernate.tool.schema.internal.SchemaDropperImpl.applySqlStrings(SchemaDropperImpl.java:359) [hibernate-core-5.4.15.Final.jar:5.4.15.Final]
    at org.hibernate.tool.schema.internal.SchemaDropperImpl.dropFromMetadata(SchemaDropperImpl.java:241) [hibernate-core-5.4.15.Final.jar:5.4.15.Final]
    at org.hibernate.tool.schema.internal.SchemaDropperImpl.performDrop(SchemaDropperImpl.java:154) [hibernate-core-5.4.15.Final.jar:5.4.15.Final]
    at org.hibernate.tool.schema.internal.SchemaDropperImpl.doDrop(SchemaDropperImpl.java:126) [hibernate-core-5.4.15.Final.jar:5.4.15.Final]
    at org.hibernate.tool.schema.internal.SchemaDropperImpl.doDrop(SchemaDropperImpl.java:112) [hibernate-core-5.4.15.Final.jar:5.4.15.Final]
    at org.hibernate.tool.schema.spi.SchemaManagementToolCoordinator.performDatabaseAction(SchemaManagementToolCoordinator.java:145) [hibernate-core-5.4.15.Final.jar:5.4.15.Final]
    at org.hibernate.tool.schema.spi.SchemaManagementToolCoordinator.process(SchemaManagementToolCoordinator.java:73) [hibernate-core-5.4.15.Final.jar:5.4.15.Final]
    at org.hibernate.internal.SessionFactoryImpl.&lt;init&gt;(SessionFactoryImpl.java:314) [hibernate-core-5.4.15.Final.jar:5.4.15.Final]
    at org.hibernate.boot.internal.SessionFactoryBuilderImpl.build(SessionFactoryBuilderImpl.java:468) [hibernate-core-5.4.15.Final.jar:5.4.15.Final]
    at org.hibernate.jpa.boot.internal.EntityManagerFactoryBuilderImpl.build(EntityManagerFactoryBuilderImpl.java:1249) [hibernate-core-5.4.15.Final.jar:5.4.15.Final]
    at org.springframework.orm.jpa.vendor.SpringHibernateJpaPersistenceProvider.createContainerEntityManagerFactory(SpringHibernateJpaPersistenceProvider.java:58) [spring-orm-5.2.6.RELEASE.jar:5.2.6.RELEASE]
    at org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean.createNativeEntityManagerFactory(LocalContainerEntityManagerFactoryBean.java:365) [spring-orm-5.2.6.RELEASE.jar:5.2.6.RELEASE]
    at org.springframework.orm.jpa.AbstractEntityManagerFactoryBean.buildNativeEntityManagerFactory(AbstractEntityManagerFactoryBean.java:391) [spring-orm-5.2.6.RELEASE.jar:5.2.6.RELEASE]
    at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[na:1.8.0_252]
    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[na:1.8.0_252]
    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[na:1.8.0_252]
    at java.lang.Thread.run(Thread.java:748) ~[na:1.8.0_252]
Caused by: org.postgresql.util.PSQLException: ERREUR: erreur de syntaxe sur ou près de « user »
  Position : 22
    at org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2533) ~[postgresql-42.2.12.jar:42.2.12]
    at org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2268) ~[postgresql-42.2.12.jar:42.2.12]
    at org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:313) ~[postgresql-42.2.12.jar:42.2.12]
    at org.postgresql.jdbc.PgStatement.executeInternal(PgStatement.java:448) ~[postgresql-42.2.12.jar:42.2.12]
    at org.postgresql.jdbc.PgStatement.execute(PgStatement.java:369) ~[postgresql-42.2.12.jar:42.2.12]
    at org.postgresql.jdbc.PgStatement.executeWithFlags(PgStatement.java:310) ~[postgresql-42.2.12.jar:42.2.12]
    at org.postgresql.jdbc.PgStatement.executeCachedSql(PgStatement.java:296) ~[postgresql-42.2.12.jar:42.2.12]
    at org.postgresql.jdbc.PgStatement.executeWithFlags(PgStatement.java:273) ~[postgresql-42.2.12.jar:42.2.12]
    at org.postgresql.jdbc.PgStatement.execute(PgStatement.java:268) ~[postgresql-42.2.12.jar:42.2.12]
    at com.zaxxer.hikari.pool.ProxyStatement.execute(ProxyStatement.java:95) ~[HikariCP-3.4.5.jar:na]
    at com.zaxxer.hikari.pool.HikariProxyStatement.execute(HikariProxyStatement.java) ~[HikariCP-3.4.5.jar:na]
    at org.hibernate.tool.schema.internal.exec.GenerationTargetToDatabase.accept(GenerationTargetToDatabase.java:54) ~[hibernate-core-5.4.15.Final.jar:5.4.15.Final]
    ... 18 common frames omitted
2020-05-24 06:16:33.429  WARN 13636 --- [         task-1] o.h.t.s.i.ExceptionHandlerLoggedImpl     : GenerationTarget encountered exception accepting command : Error executing DDL ""create table user (id int8 generated by default as identity, age int4 not null, email varchar(255), first_name varchar(255), last_name varchar(255), username varchar(255), primary key (id))"" via JDBC Statement
org.hibernate.tool.schema.spi.CommandAcceptanceException: Error executing DDL ""create table user (id int8 generated by default as identity, age int4 not null, email varchar(255), first_name varchar(255), last_name varchar(255), username varchar(255), primary key (id))"" via JDBC Statement
    at org.hibernate.tool.schema.internal.exec.GenerationTargetToDatabase.accept(GenerationTargetToDatabase.java:67) ~[hibernate-core-5.4.15.Final.jar:5.4.15.Final]
    at org.hibernate.tool.schema.internal.SchemaCreatorImpl.applySqlString(SchemaCreatorImpl.java:439) [hibernate-core-5.4.15.Final.jar:5.4.15.Final]
    at org.hibernate.tool.schema.internal.SchemaCreatorImpl.applySqlStrings(SchemaCreatorImpl.java:423) [hibernate-core-5.4.15.Final.jar:5.4.15.Final]
    at org.hibernate.tool.schema.internal.SchemaCreatorImpl.createFromMetadata(SchemaCreatorImpl.java:314) [hibernate-core-5.4.15.Final.jar:5.4.15.Final]
    at org.hibernate.tool.schema.internal.SchemaCreatorImpl.performCreation(SchemaCreatorImpl.java:166) [hibernate-core-5.4.15.Final.jar:5.4.15.Final]
    at org.hibernate.tool.schema.internal.SchemaCreatorImpl.doCreation(SchemaCreatorImpl.java:135) [hibernate-core-5.4.15.Final.jar:5.4.15.Final]
    at org.hibernate.tool.schema.internal.SchemaCreatorImpl.doCreation(SchemaCreatorImpl.java:121) [hibernate-core-5.4.15.Final.jar:5.4.15.Final]
    at org.hibernate.tool.schema.spi.SchemaManagementToolCoordinator.performDatabaseAction(SchemaManagementToolCoordinator.java:156) [hibernate-core-5.4.15.Final.jar:5.4.15.Final]
    at org.hibernate.tool.schema.spi.SchemaManagementToolCoordinator.process(SchemaManagementToolCoordinator.java:73) [hibernate-core-5.4.15.Final.jar:5.4.15.Final]
    at org.hibernate.internal.SessionFactoryImpl.&lt;init&gt;(SessionFactoryImpl.java:314) [hibernate-core-5.4.15.Final.jar:5.4.15.Final]
    at org.hibernate.boot.internal.SessionFactoryBuilderImpl.build(SessionFactoryBuilderImpl.java:468) [hibernate-core-5.4.15.Final.jar:5.4.15.Final]
    at org.hibernate.jpa.boot.internal.EntityManagerFactoryBuilderImpl.build(EntityManagerFactoryBuilderImpl.java:1249) [hibernate-core-5.4.15.Final.jar:5.4.15.Final]
    at org.springframework.orm.jpa.vendor.SpringHibernateJpaPersistenceProvider.createContainerEntityManagerFactory(SpringHibernateJpaPersistenceProvider.java:58) [spring-orm-5.2.6.RELEASE.jar:5.2.6.RELEASE]
    at org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean.createNativeEntityManagerFactory(LocalContainerEntityManagerFactoryBean.java:365) [spring-orm-5.2.6.RELEASE.jar:5.2.6.RELEASE]
    at org.springframework.orm.jpa.AbstractEntityManagerFactoryBean.buildNativeEntityManagerFactory(AbstractEntityManagerFactoryBean.java:391) [spring-orm-5.2.6.RELEASE.jar:5.2.6.RELEASE]
    at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[na:1.8.0_252]
    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[na:1.8.0_252]
    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[na:1.8.0_252]
    at java.lang.Thread.run(Thread.java:748) ~[na:1.8.0_252]
Caused by: org.postgresql.util.PSQLException: ERREUR: erreur de syntaxe sur ou près de « user »
  Position : 14
    at org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2533) ~[postgresql-42.2.12.jar:42.2.12]
    at org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2268) ~[postgresql-42.2.12.jar:42.2.12]
    at org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:313) ~[postgresql-42.2.12.jar:42.2.12]
    at org.postgresql.jdbc.PgStatement.executeInternal(PgStatement.java:448) ~[postgresql-42.2.12.jar:42.2.12]
    at org.postgresql.jdbc.PgStatement.execute(PgStatement.java:369) ~[postgresql-42.2.12.jar:42.2.12]
    at org.postgresql.jdbc.PgStatement.executeWithFlags(PgStatement.java:310) ~[postgresql-42.2.12.jar:42.2.12]
    at org.postgresql.jdbc.PgStatement.executeCachedSql(PgStatement.java:296) ~[postgresql-42.2.12.jar:42.2.12]
    at org.postgresql.jdbc.PgStatement.executeWithFlags(PgStatement.java:273) ~[postgresql-42.2.12.jar:42.2.12]
    at org.postgresql.jdbc.PgStatement.execute(PgStatement.java:268) ~[postgresql-42.2.12.jar:42.2.12]
    at com.zaxxer.hikari.pool.ProxyStatement.execute(ProxyStatement.java:95) ~[HikariCP-3.4.5.jar:na]
    at com.zaxxer.hikari.pool.HikariProxyStatement.execute(HikariProxyStatement.java) ~[HikariCP-3.4.5.jar:na]
    at org.hibernate.tool.schema.internal.exec.GenerationTargetToDatabase.accept(GenerationTargetToDatabase.java:54) ~[hibernate-core-5.4.15.Final.jar:5.4.15.Final]
    ... 18 common frames omitted
However when I change the name of my class e.g. to Person 
@Entity
@NoArgsConstructor
@Data
@AllArgsConstructor
@Builder
public class Person {
    @Id @GeneratedValue(strategy = GenerationType.IDENTITY)
    private Long id;
    private String username;
    private String email;
    private String firstName;
    private String lastName;
    private int age;
}
I don't get any errors. Could someone help me with this in the following way or at least explain me what is wrong with the entity class User.
I would also like to add that when in doubt I tested this code with MySQL as an alternative to PostgreSQL and got no errors.
",<java><postgresql><hibernate><spring-boot><jpa>,10925,0,106,193,1,1,4,50,12911,0.0,0,3,19,2020-05-24 4:52,2020-05-24 5:07,2020-05-24 5:07,0.0,0.0,Intermediate,19
