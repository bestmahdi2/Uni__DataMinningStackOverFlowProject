QuestionId,QuestionTitle,QuestionBody,QuestionTags,QuestionBodyLength,URLImageCount,LOC,UserReputation,UserGoldBadges,UserSilverBadges,UserBronzeBadges,QuestionAcceptRate,QuestionViewCount,QuestionFavoriteCount,UserUpVoteCount,QuestionAnswersCount,QuestionScore,QuestionCreationDate,FirstAnswerCreationDate,AcceptedAnswerCreationDate,FirstAnswerIntervalDays,AcceptedAnswerIntervalDays,QuestionLabel,QuestionLabelDefinition,MergedText,ProcessedText
53641403,Search in Json column with Laravel,"In my emails table, I have a column named To with column-type Json. This is how values are stored:
[
    {
        ""emailAddress"": {
            ""name"": ""Test"", 
            ""address"": ""test@example.com""
        }
    }, 
    {
        ""emailAddress"": {
            ""name"": ""Test 2"", 
            ""address"": ""test2@example.com""
        }
    }
]
Now I want a collection of all emails sent to ""test@example.com"". I tried:
DB::table('emails')-&gt;whereJsonContains('to-&gt;emailAddress-&gt;address', 'test@example.com')-&gt;get();
(see https://laravel.com/docs/5.7/queries#json-where-clauses)
but I do not get a match. Is there a better way to search using Laravel (Eloquent)?
In the debugbar, I can see that this query is ""translated"" as:
select * from `emails` where json_contains(`to`-&gt;'$.""emailAddress"".""address""', '\""test@example.com\""'))
",<php><mysql><json><laravel><laravel-5>,845,2,18,1571,3,21,43,44,49425,0.0,176,7,21,2018-12-05 21:59,2018-12-06 7:43,2018-12-06 15:27,1.0,1.0,Basic,7,"<php><mysql><json><laravel><laravel-5>, Search in Json column with Laravel, In my emails table, I have a column named To with column-type Json. This is how values are stored:
[
    {
        ""emailAddress"": {
            ""name"": ""Test"", 
            ""address"": ""test@example.com""
        }
    }, 
    {
        ""emailAddress"": {
            ""name"": ""Test 2"", 
            ""address"": ""test2@example.com""
        }
    }
]
Now I want a collection of all emails sent to ""test@example.com"". I tried:
DB::table('emails')-&gt;whereJsonContains('to-&gt;emailAddress-&gt;address', 'test@example.com')-&gt;get();
(see https://laravel.com/docs/5.7/queries#json-where-clauses)
but I do not get a match. Is there a better way to search using Laravel (Eloquent)?
In the debugbar, I can see that this query is ""translated"" as:
select * from `emails` where json_contains(`to`-&gt;'$.""emailAddress"".""address""', '\""test@example.com\""'))
","<pp><myself><son><travel><travel-5>, search son column travel, email table, column name column-type son. value stored: [ { ""emailaddress"": { ""name"": ""test"", ""address"": ""test@example.com"" } }, { ""emailaddress"": { ""name"": ""test 2"", ""address"": ""test@example.com"" } } ] want collect email sent ""test@example.com"". tried: do::table('email')-&it;wherejsoncontains('to-&it;emailaddress-&it;address', 'test@example.com')-&it;get(); (see http://travel.com/docs/5.7/queried#son-where-clauses) get match. better way search use travel (eloquent)? debugbar, see query ""translated"" as: select * `email` json_contains(`to`-&it;'$.""emailaddress"".""address""', '\""test@example.com\""'))"
52088355,FluentMySQL connection using Unix Socket,"I'm following the Getting started section for the MySQL package on the Vapor Documentation, which I'm able to follow step by step and, as a result, I have successfully established a connection to the MySQL database, using custom database credentials like this:
/// Register providers first
try services.register(FluentMySQLProvider())
// MySQL database
let mySQLConfig = MySQLDatabaseConfig(hostname: ""localhost"",
                                      port: 3306,
                                      username: ""root"",
                                      password: ""thisismyrootpassword"",
                                      database: ""lol_database"",
                                      capabilities: .default,
                                      characterSet: MySQLCharacterSet.utf8_general_ci,
                                      transport: MySQLTransportConfig.cleartext)
services.register(mySQLConfig)
Based on the MySQLDatabaseConfig object's documentation I'm unable to find if it is possible to connect to a MySQL database based on a Unix Socket configuration.
What I'll be able to provide to the application under the production environment it's just the database name, the username, password and the Socket path, which will be in the form /cloudsql/project1:us-central1:instance1
For more reference, what I'm trying to do is connect from a Google Cloud App Engine flexible environment to a SQL database based on this tutorial: https://cloud.google.com/appengine/docs/flexible/nodejs/using-cloud-sql#setting_up_your_local_environment The environment of course will be Vapor still that's the only way for a database client to establish connection to the database server.
Thank you for your help.
",<mysql><swift><vapor>,1714,4,16,1509,2,19,27,38,335,0.0,821,1,21,2018-08-30 2:17,2021-07-09 0:32,2021-07-09 0:32,1044.0,1044.0,Basic,3,"<mysql><swift><vapor>, FluentMySQL connection using Unix Socket, I'm following the Getting started section for the MySQL package on the Vapor Documentation, which I'm able to follow step by step and, as a result, I have successfully established a connection to the MySQL database, using custom database credentials like this:
/// Register providers first
try services.register(FluentMySQLProvider())
// MySQL database
let mySQLConfig = MySQLDatabaseConfig(hostname: ""localhost"",
                                      port: 3306,
                                      username: ""root"",
                                      password: ""thisismyrootpassword"",
                                      database: ""lol_database"",
                                      capabilities: .default,
                                      characterSet: MySQLCharacterSet.utf8_general_ci,
                                      transport: MySQLTransportConfig.cleartext)
services.register(mySQLConfig)
Based on the MySQLDatabaseConfig object's documentation I'm unable to find if it is possible to connect to a MySQL database based on a Unix Socket configuration.
What I'll be able to provide to the application under the production environment it's just the database name, the username, password and the Socket path, which will be in the form /cloudsql/project1:us-central1:instance1
For more reference, what I'm trying to do is connect from a Google Cloud App Engine flexible environment to a SQL database based on this tutorial: https://cloud.google.com/appengine/docs/flexible/nodejs/using-cloud-sql#setting_up_your_local_environment The environment of course will be Vapor still that's the only way for a database client to establish connection to the database server.
Thank you for your help.
","<myself><swift><vapor>, fluentmysql connect use unit socket, i'm follow get start section myself package vapor documentation, i'm all follow step step and, result, success establish connect myself database, use custom database credenti like this: /// resist proved first try services.register(fluentmysqlprovider()) // myself database let mysqlconfig = mysqldatabaseconfig(hostage: ""localhost"", port: 3306, surname: ""root"", password: ""thisismyrootpassword"", database: ""lol_database"", capabilities: .default, characters: mysqlcharacterset.utf8_general_ci, transport: mysqltransportconfig.clearest) services.register(mysqlconfig) base mysqldatabaseconfig object' document i'm unable find possible connect myself database base unit socket configuration. i'll all proved applied product environs database name, surname, password socket path, form /clouds/project:us-central:instance reference, i'm try connect good cloud pp engine flexible environs sal database base tutoring: http://cloud.goose.com/appengine/docs/flexible/nodes/using-cloud-sal#setting_up_your_local_environ environs course vapor still that' way database client establish connect database server. thank help."
58233866,SQLSTATE[HY000] [1045] Access denied for user 'root'@'localhost' (using password: NO) . DB_HOST set to localhost,"I moved the Laravel project from localhost to server. Which I have done every step on the server.
I am able to view the login page on my server. The problem is I am not able to connect with my MySQL server.
My .env file:
APP_NAME=Transport
APP_ENV=local
APP_KEY=base64:mrakeyidharhaikonsdf
APP_DEBUG=true
APP_URL=http://localhost
LOG_CHANNEL=stack
DB_CONNECTION=mysql
DB_HOST=localhost
DB_PORT=3306
DB_DATABASE=transport_db
DB_USERNAME=root
DB_PASSWORD=mypass
I tried to change the host to 127.0.0.1 and also tried to put my server's IP address. It didn't helped me. Am I missing something?
My error:
SQLSTATE[HY000] [1045] Access denied for user 'root'@'localhost' (using password: NO) (SQL: select count(*) as aggregate from users where email = user.email@gmail.com)
I know this question may have answers already on Stack Overflow. But I have different issue here.
",<php><mysql><laravel><laravel-6>,867,1,18,1603,2,17,34,45,170223,0.0,650,16,21,2019-10-04 9:46,2019-10-04 10:16,2019-10-04 10:17,0.0,0.0,Basic,6,"<php><mysql><laravel><laravel-6>, SQLSTATE[HY000] [1045] Access denied for user 'root'@'localhost' (using password: NO) . DB_HOST set to localhost, I moved the Laravel project from localhost to server. Which I have done every step on the server.
I am able to view the login page on my server. The problem is I am not able to connect with my MySQL server.
My .env file:
APP_NAME=Transport
APP_ENV=local
APP_KEY=base64:mrakeyidharhaikonsdf
APP_DEBUG=true
APP_URL=http://localhost
LOG_CHANNEL=stack
DB_CONNECTION=mysql
DB_HOST=localhost
DB_PORT=3306
DB_DATABASE=transport_db
DB_USERNAME=root
DB_PASSWORD=mypass
I tried to change the host to 127.0.0.1 and also tried to put my server's IP address. It didn't helped me. Am I missing something?
My error:
SQLSTATE[HY000] [1045] Access denied for user 'root'@'localhost' (using password: NO) (SQL: select count(*) as aggregate from users where email = user.email@gmail.com)
I know this question may have answers already on Stack Overflow. But I have different issue here.
","<pp><myself><travel><travel-6>, sqlstate[hy000] [1045] access den user 'root'@'localhost' (use password: no) . db_host set localhost, move travel project localhost server. done every step server. all view login page server. problem all connect myself server. .end file: app_name=transport app_env=low app_key=based:mrakeyidharhaikonsdf app_debug=true app_url=http://localhost log_channel=stick db_connection=myself db_host=localhost duport=3306 db_database=transported db_username=root db_password=pass try change host 127.0.0.1 also try put server' in address. help me. miss something? error: sqlstate[hy000] [1045] access den user 'root'@'localhost' (use password: no) (sal: select count(*) agree user email = user.email@email.com) know question may answer already stick overflow. differ issue here."
48053955,Alembic Migrations on Multiple Models,"I am attempting to create a revision with --autogenerate using Alembic for two Models, but am receiving a duplicate table keys error. Does, a schema need to be specified?  If so, how can it be set?  The documentation I've read says to use __table_args__ = {'schema': 'somename'}, but that hasn't helped.  Any tips or suggestions are greatly appreciated.
My current setup is:
base.py
from sqlalchemy.ext.declarative import declarative_base
Base = declarative_base()
workspace.py
from sqlalchemy import Column, Integer, String
from base import Base
class WorkspaceModel(Base):
    __tablename__ = 'workspaces'
    id = Column(Integer, primary_key=True)
    name = Column(String)
host.py
from sqlalchemy import Column, Integer, String
from base import Base
class HostModel(Base):
    __tablename__ = 'hosts'
    id = Column(Integer, primary_key=true)
    ip = Column(String)
alembic/env.py
from host import HostModel
from workspace import WorkspaceModel
target_metadata = [HostModel.metadata, WorkspaceModel.metadata]
Error
ValueError: Duplicate table keys across multiple MetaData objects: ""hosts"", ""workspaces""
",<python><sqlalchemy><alembic>,1110,0,26,4468,2,29,39,66,10030,0.0,136,3,21,2018-01-01 22:59,2020-02-25 6:14,2020-07-15 23:34,785.0,926.0,Basic,6,"<python><sqlalchemy><alembic>, Alembic Migrations on Multiple Models, I am attempting to create a revision with --autogenerate using Alembic for two Models, but am receiving a duplicate table keys error. Does, a schema need to be specified?  If so, how can it be set?  The documentation I've read says to use __table_args__ = {'schema': 'somename'}, but that hasn't helped.  Any tips or suggestions are greatly appreciated.
My current setup is:
base.py
from sqlalchemy.ext.declarative import declarative_base
Base = declarative_base()
workspace.py
from sqlalchemy import Column, Integer, String
from base import Base
class WorkspaceModel(Base):
    __tablename__ = 'workspaces'
    id = Column(Integer, primary_key=True)
    name = Column(String)
host.py
from sqlalchemy import Column, Integer, String
from base import Base
class HostModel(Base):
    __tablename__ = 'hosts'
    id = Column(Integer, primary_key=true)
    ip = Column(String)
alembic/env.py
from host import HostModel
from workspace import WorkspaceModel
target_metadata = [HostModel.metadata, WorkspaceModel.metadata]
Error
ValueError: Duplicate table keys across multiple MetaData objects: ""hosts"", ""workspaces""
","<patron><sqlalchemy><alembic>, limb migrate multiple models, attempt great revise --autogener use limb two models, receive public table key error. does, scheme need specified? so, set? document i'v read say use __table_args__ = {'scheme': 'sometime'}, helped. tip suggest greatly appreciated. current set is: base.i sqlalchemy.ext.declare import declarative_bas base = declarative_base() workplace.i sqlalchemi import column, inter, string base import base class workspacemodel(base): __tablename__ = 'workspaces' id = column(inter, primary_key=true) name = column(string) host.i sqlalchemi import column, inter, string base import base class hostmodel(base): __tablename__ = 'hosts' id = column(inter, primary_key=true) in = column(string) alembic/end.i host import hostmodel workspac import workspacemodel target_metadata = [hostmodel.metadata, workspacemodel.metadata] error valueerror: public table key across multiple metadata objects: ""hosts"", ""workspaces"""
59582390,Confusion Around Creating a VPC Access Connector,"I am trying to set up Serverless VPC access
  Serverless VPC Access enables you to connect from your Cloud Functions directly to Compute Engine VM instances, Memorystore instances, Cloud SQL instances,
Sounds great. But the documentation is not super friendly to a beginner. Step 2 is to create a connector, about which I have a couple of questions:
  In the Network field, select the VPC network to connect to.
My dropdown here contains only ""Default"". Is this normal? What should IO expect to see here?
  In the IP range field, enter an unused CIDR /28 IP range. Addresses in this range are used as source addresses for traffic sent through the connector. This IP range must not overlap with any existing IP address reservations in your VPC network.
I don't know what to do here. I tried using the information in the linked document to first) enter an IP from the region I had selected, and, second) enter an IP from outside that region. Both resulted in connectors that were created with the error. ""Connector is in a bad state, manual deletion is recommended""
The documentation continues with a couple of troubleshooting steps if the creation fails:
  Specify an IP range that does not overlap with any existing IP address reservations in the VPC network.
I don't know what this means. Maybe like, if I have other connectors I should be sure the IP range for the new one doesn't overlap with those. That's just a guess, but anyway I have none.
  Grant your project permission to use Compute Engine VM images from the project with ID serverless-vpc-access-images. See Setting image access constraints for information on how to update your organization policy accordingly.
This leads me to another document about updating my organization's ""Image Policy"". This one has me so out of my depth, I don't even think I should be here.
This has all started with just wanting to connect to a SQL Server instance from Firebase. Creating the VPC connector seems like a good step, but I've just fallen at every hurdle. Can a cloud-dweller please help me with a few of these points of confusion? 
",<google-cloud-platform><cloud><google-cloud-sql><vpc>,2087,4,1,14803,32,109,235,56,12457,0.0,2623,3,21,2020-01-03 16:56,2020-01-04 4:10,,1.0,,Basic,3,"<google-cloud-platform><cloud><google-cloud-sql><vpc>, Confusion Around Creating a VPC Access Connector, I am trying to set up Serverless VPC access
  Serverless VPC Access enables you to connect from your Cloud Functions directly to Compute Engine VM instances, Memorystore instances, Cloud SQL instances,
Sounds great. But the documentation is not super friendly to a beginner. Step 2 is to create a connector, about which I have a couple of questions:
  In the Network field, select the VPC network to connect to.
My dropdown here contains only ""Default"". Is this normal? What should IO expect to see here?
  In the IP range field, enter an unused CIDR /28 IP range. Addresses in this range are used as source addresses for traffic sent through the connector. This IP range must not overlap with any existing IP address reservations in your VPC network.
I don't know what to do here. I tried using the information in the linked document to first) enter an IP from the region I had selected, and, second) enter an IP from outside that region. Both resulted in connectors that were created with the error. ""Connector is in a bad state, manual deletion is recommended""
The documentation continues with a couple of troubleshooting steps if the creation fails:
  Specify an IP range that does not overlap with any existing IP address reservations in the VPC network.
I don't know what this means. Maybe like, if I have other connectors I should be sure the IP range for the new one doesn't overlap with those. That's just a guess, but anyway I have none.
  Grant your project permission to use Compute Engine VM images from the project with ID serverless-vpc-access-images. See Setting image access constraints for information on how to update your organization policy accordingly.
This leads me to another document about updating my organization's ""Image Policy"". This one has me so out of my depth, I don't even think I should be here.
This has all started with just wanting to connect to a SQL Server instance from Firebase. Creating the VPC connector seems like a good step, but I've just fallen at every hurdle. Can a cloud-dweller please help me with a few of these points of confusion? 
","<goose-cloud-platform><cloud><goose-cloud-sal><up>, confuse around great up access connection, try set serverless up access serverless up access enable connect cloud function directly compute engine am instances, memorystor instances, cloud sal instances, sound great. document super friendly beginner. step 2 great connection, couple questions: network field, select up network connect to. dropdown contain ""default"". normal? to expect see here? in rang field, enter anus cider /28 in range. address rang use source address traffic sent connection. in rang must overlap exist in address reserve up network. know here. try use inform link document first) enter in region selected, and, second) enter in outside region. result connection great error. ""connection bad state, manual delete recommended"" document continue couple troubleshoot step creation fails: specific in rang overlap exist in address reserve up network. know means. may like, connection sure in rang new one overlap those. that' guess, anyway none. grant project permits use compute engine am image project id serverless-up-access-images. see set image access constraint inform update organ policy accordingly. lead not document update organization' ""image policy"". one depth, even think here. start want connect sal server instant firebase. great up connection seem like good step, i'v fallen every hardly. cloud-duel pleas help point confusion?"
58676909,How to speed up spark df.write jdbc to postgres database?,"I am new to spark and am attempting to speed up appending the contents of a dataframe, (that can have between 200k and 2M rows) to a postgres database using df.write:
df.write.format('jdbc').options(
      url=psql_url_spark,
      driver=spark_env['PSQL_DRIVER'],
      dbtable=""{schema}.{table}"".format(schema=schema, table=table),
      user=spark_env['PSQL_USER'],
      password=spark_env['PSQL_PASS'],
      batchsize=2000000,
      queryTimeout=690
      ).mode(mode).save()
I tried increasing the batchsize but that didn't help, as completing this task still took ~4hours. I've also included some snapshots below from aws emr showing more details about how the job ran. The task to save the dataframe to the postgres table was only assigned to one executor (which I found strange), would speeding this up involve dividing this task between executors?
Also, I have read spark's performance tuning docs but increasing the batchsize, and queryTimeout have not seemed to improve performance. (I tried calling df.cache() in my script before df.write, but runtime for the script was still 4hrs)
Additionally, my aws emr hardware setup and spark-submit are:
Master Node (1): m4.xlarge
Core Nodes (2): m5.xlarge
spark-submit --deploy-mode client --executor-cores 4 --num-executors 4 ...
",<postgresql><apache-spark><pyspark><apache-spark-sql>,1287,3,15,1040,1,15,44,41,19782,0.0,57,4,21,2019-11-03 2:15,2020-04-25 22:10,2020-04-26 8:59,174.0,175.0,Intermediate,23,"<postgresql><apache-spark><pyspark><apache-spark-sql>, How to speed up spark df.write jdbc to postgres database?, I am new to spark and am attempting to speed up appending the contents of a dataframe, (that can have between 200k and 2M rows) to a postgres database using df.write:
df.write.format('jdbc').options(
      url=psql_url_spark,
      driver=spark_env['PSQL_DRIVER'],
      dbtable=""{schema}.{table}"".format(schema=schema, table=table),
      user=spark_env['PSQL_USER'],
      password=spark_env['PSQL_PASS'],
      batchsize=2000000,
      queryTimeout=690
      ).mode(mode).save()
I tried increasing the batchsize but that didn't help, as completing this task still took ~4hours. I've also included some snapshots below from aws emr showing more details about how the job ran. The task to save the dataframe to the postgres table was only assigned to one executor (which I found strange), would speeding this up involve dividing this task between executors?
Also, I have read spark's performance tuning docs but increasing the batchsize, and queryTimeout have not seemed to improve performance. (I tried calling df.cache() in my script before df.write, but runtime for the script was still 4hrs)
Additionally, my aws emr hardware setup and spark-submit are:
Master Node (1): m4.xlarge
Core Nodes (2): m5.xlarge
spark-submit --deploy-mode client --executor-cores 4 --num-executors 4 ...
","<postgresql><apache-spark><spark><apache-spark-sal>, speed spark of.write job poster database?, new spark attempt speed happened content dataframe, (that 200k am rows) poster database use of.write: of.write.format('job').option( curl=psql_url_spark, driver=spark_env['psql_driver'], table=""{scheme}.{table}"".format(scheme=scheme, table=table), user=spark_env['psql_user'], password=spark_env['psql_pass'], batchsize=2000000, querytimeout=690 ).mode(mode).save() try increase batchsiz help, complete task still took ~hours. i'v also include snapshot a mr show detail job ran. task save datafram poster table assign one executor (which found strange), would speed involve livid task executor? also, read spark' perform tune do increase batchsize, querytimeout seem improve performance. (i try call of.ache() script of.write, until script still his) additional, a mr hardware set spark-submit are: master node (1): my.large core node (2): my.large spark-submit --deploy-god client --executor-cor 4 --sum-executor 4 ..."
50945477,Count rows in partition with Order By,"I was trying to understand PARTITION BY in postgres by writing a few sample queries. I have a test table on which I run my query.
id integer | num integer
___________|_____________
1          | 4 
2          | 4
3          | 5
4          | 6
When I run the following query, I get the output as I expected.
SELECT id, COUNT(id) OVER(PARTITION BY num) from test;
id         | count
___________|_____________
1          | 2 
2          | 2
3          | 1
4          | 1
But, when I add ORDER BY to the partition,
SELECT id, COUNT(id) OVER(PARTITION BY num ORDER BY id) from test;
id         | count
___________|_____________
1          | 1 
2          | 2
3          | 1
4          | 1
My understanding is that COUNT is computed across all rows that fall into a partition. Here, I have partitioned the rows by num. The number of rows in the partition is the same, with or without an ORDER BY clause. Why is there a difference in the outputs?
",<sql><postgresql><window-functions>,939,0,22,612,3,7,13,80,54789,0.0,352,3,21,2018-06-20 10:00,2018-06-20 10:18,2018-06-20 10:18,0.0,0.0,Basic,3,"<sql><postgresql><window-functions>, Count rows in partition with Order By, I was trying to understand PARTITION BY in postgres by writing a few sample queries. I have a test table on which I run my query.
id integer | num integer
___________|_____________
1          | 4 
2          | 4
3          | 5
4          | 6
When I run the following query, I get the output as I expected.
SELECT id, COUNT(id) OVER(PARTITION BY num) from test;
id         | count
___________|_____________
1          | 2 
2          | 2
3          | 1
4          | 1
But, when I add ORDER BY to the partition,
SELECT id, COUNT(id) OVER(PARTITION BY num ORDER BY id) from test;
id         | count
___________|_____________
1          | 1 
2          | 2
3          | 1
4          | 1
My understanding is that COUNT is computed across all rows that fall into a partition. Here, I have partitioned the rows by num. The number of rows in the partition is the same, with or without an ORDER BY clause. Why is there a difference in the outputs?
","<sal><postgresql><window-functions>, count row partite order by, try understand partite poster write sample queried. test table run query. id inter | sum inter ___________|_____________ 1 | 4 2 | 4 3 | 5 4 | 6 run follow query, get output expected. select id, count(id) over(partite sum) test; id | count ___________|_____________ 1 | 2 2 | 2 3 | 1 4 | 1 but, add order partition, select id, count(id) over(partite sum order id) test; id | count ___________|_____________ 1 | 1 2 | 2 3 | 1 4 | 1 understand count compute across row fall partition. here, partite row sum. number row partite same, without order clause. differ output?"
52355143,Is it possible to delete old records from clickhouse table?,"As far as I know, clickhouse allows only inserting new data. But is it possible to delete block older then some period to avoid overflow of HDD?
",<sql><clickhouse>,145,0,0,8840,28,117,207,76,39391,0.0,2932,3,21,2018-09-16 14:36,2018-10-05 14:27,2018-10-23 9:05,19.0,37.0,Basic,3,"<sql><clickhouse>, Is it possible to delete old records from clickhouse table?, As far as I know, clickhouse allows only inserting new data. But is it possible to delete block older then some period to avoid overflow of HDD?
","<sal><clickhouse>, possible delete old record clickhous table?, far know, clickhous allow insert new data. possible delete block older period avoid overflow had?"
63997315,UNION types text and bigint cannot be matched,"I'm running a complex stored procedure and I'm getting an error when I have 3 unions, but with 2 unions no error. If I remove either of the top two unions it runs fine. If I make one of the NULLs a 0, it runs fine. The error is &quot;UNION types text and bigint cannot be matched&quot;
```lang-sql
SELECT NULL AS total_time_spent 
FROM tbl1
GROUP BY student_id 
UNION ALL 
SELECT NULL AS total_time_spent
FROM tbl2
GROUP BY student_id 
UNION ALL 
SELECT sum(cast((&quot;value&quot; -&gt;&gt; 'seconds') AS integer)) AS total_time_spent 
FROM tbl3 
GROUP BY student_id
```
I've tried all kinds of casting on the sum result or the sum input. The json that I'm pulling from is either NULL, [] or something like this:
[{&quot;date&quot;: &quot;2020-09-17&quot;, &quot;seconds&quot;: 458}]
",<postgresql><union-all>,785,0,14,1643,5,21,41,54,43648,0.0,73,1,21,2020-09-21 17:34,2020-09-22 2:21,2020-09-22 2:21,1.0,1.0,Basic,2,"<postgresql><union-all>, UNION types text and bigint cannot be matched, I'm running a complex stored procedure and I'm getting an error when I have 3 unions, but with 2 unions no error. If I remove either of the top two unions it runs fine. If I make one of the NULLs a 0, it runs fine. The error is &quot;UNION types text and bigint cannot be matched&quot;
```lang-sql
SELECT NULL AS total_time_spent 
FROM tbl1
GROUP BY student_id 
UNION ALL 
SELECT NULL AS total_time_spent
FROM tbl2
GROUP BY student_id 
UNION ALL 
SELECT sum(cast((&quot;value&quot; -&gt;&gt; 'seconds') AS integer)) AS total_time_spent 
FROM tbl3 
GROUP BY student_id
```
I've tried all kinds of casting on the sum result or the sum input. The json that I'm pulling from is either NULL, [] or something like this:
[{&quot;date&quot;: &quot;2020-09-17&quot;, &quot;seconds&quot;: 458}]
","<postgresql><union-all>, union type text begin cannot matched, i'm run complex store procedure i'm get error 3 unions, 2 union error. remove either top two union run fine. make one null 0, run fine. error &quit;union type text begin cannot matched&quit; ```long-sal select null total_time_sp tell group student_id union select null total_time_sp tell group student_id union select sum(cast((&quit;value&quit; -&it;&it; 'seconds') inter)) total_time_sp tell group student_id ``` i'v try kind cast sum result sum input. son i'm pull either null, [] cometh like this: [{&quit;date&quit;: &quit;2020-09-17&quit;, &quit;seconds&quit;: 458}]"
55825283,How to convert array to string in laravel?,"I am getting input from checkbox values in array using bootstrap form.
I am using array for storing checkbox values. How i convert this array to string . Because database only take string values.
Here is my code
&lt;div class=""form-group col-md-12""&gt;
    &lt;div class=""custom-control custom-checkbox custom-control-inline""&gt;
        &lt;input type=""checkbox"" id=""eduPrimary"" name=""education[]"" 
        class=""custom-control-input"" value=""primary"" /&gt;
        &lt;label class=""custom-control-label"" for=""eduPrimary""&gt;primary&lt;/label&gt;
    &lt;/div&gt;
&lt;/div&gt;
&lt;div class=""form-group col-md-12""&gt;
    &lt;div class=""custom-control custom-checkbox custom-control-inline""&gt;
        &lt;input type=""checkbox"" id=""eduSecondary"" name=""education[]"" 
        class=""custom-control-input"" value=""secondary"" /&gt;
        &lt;label class=""custom-control-label"" for=""eduSecondary""&gt;secondary&lt;/label&gt;
    &lt;/div&gt;
&lt;/div&gt;
&lt;div class=""form-group col-md-12""&gt;
    &lt;div class=""custom-control custom-checkbox custom-control-inline""&gt;
        &lt;input type=""checkbox"" id=""eduUniversity"" name=""education[]"" 
        class=""custom-control-input"" value=""university"" /&gt;
        &lt;label class=""custom-control-label""for=""eduUniversity""&gt;university&lt;/label&gt;
    &lt;/div&gt;
&lt;/div&gt;
In backend i am using laravel to store values to database But it run error that storing array to string in mysql.
public function store(Request $request,AdProfile $adprofile)
{
    $adprofile-&gt;education = $request-&gt;education[];
    $adprofile-&gt;save();
    return redirect()-&gt;route('adprofile.profilecomplete');
}
",<php><mysql><laravel>,1654,0,27,792,1,6,17,78,99378,0.0,128,8,21,2019-04-24 8:11,2019-04-24 8:17,2019-04-24 9:59,0.0,0.0,Basic,2,"<php><mysql><laravel>, How to convert array to string in laravel?, I am getting input from checkbox values in array using bootstrap form.
I am using array for storing checkbox values. How i convert this array to string . Because database only take string values.
Here is my code
&lt;div class=""form-group col-md-12""&gt;
    &lt;div class=""custom-control custom-checkbox custom-control-inline""&gt;
        &lt;input type=""checkbox"" id=""eduPrimary"" name=""education[]"" 
        class=""custom-control-input"" value=""primary"" /&gt;
        &lt;label class=""custom-control-label"" for=""eduPrimary""&gt;primary&lt;/label&gt;
    &lt;/div&gt;
&lt;/div&gt;
&lt;div class=""form-group col-md-12""&gt;
    &lt;div class=""custom-control custom-checkbox custom-control-inline""&gt;
        &lt;input type=""checkbox"" id=""eduSecondary"" name=""education[]"" 
        class=""custom-control-input"" value=""secondary"" /&gt;
        &lt;label class=""custom-control-label"" for=""eduSecondary""&gt;secondary&lt;/label&gt;
    &lt;/div&gt;
&lt;/div&gt;
&lt;div class=""form-group col-md-12""&gt;
    &lt;div class=""custom-control custom-checkbox custom-control-inline""&gt;
        &lt;input type=""checkbox"" id=""eduUniversity"" name=""education[]"" 
        class=""custom-control-input"" value=""university"" /&gt;
        &lt;label class=""custom-control-label""for=""eduUniversity""&gt;university&lt;/label&gt;
    &lt;/div&gt;
&lt;/div&gt;
In backend i am using laravel to store values to database But it run error that storing array to string in mysql.
public function store(Request $request,AdProfile $adprofile)
{
    $adprofile-&gt;education = $request-&gt;education[];
    $adprofile-&gt;save();
    return redirect()-&gt;route('adprofile.profilecomplete');
}
","<pp><myself><travel>, convert array string travel?, get input checkbox value array use bootstrap form. use array store checkbox values. convert array string . database take string values. code &it;did class=""form-group col-md-12""&it; &it;did class=""custom-control custom-checkbox custom-control-online""&it; &it;input type=""checkbox"" id=""eduprimary"" name=""education[]"" class=""custom-control-input"" value=""primary"" /&it; &it;label class=""custom-control-label"" for=""eduprimary""&it;primary&it;/label&it; &it;/did&it; &it;/did&it; &it;did class=""form-group col-md-12""&it; &it;did class=""custom-control custom-checkbox custom-control-online""&it; &it;input type=""checkbox"" id=""edusecondary"" name=""education[]"" class=""custom-control-input"" value=""secondary"" /&it; &it;label class=""custom-control-label"" for=""edusecondary""&it;secondary&it;/label&it; &it;/did&it; &it;/did&it; &it;did class=""form-group col-md-12""&it; &it;did class=""custom-control custom-checkbox custom-control-online""&it; &it;input type=""checkbox"" id=""eduuniversity"" name=""education[]"" class=""custom-control-input"" value=""university"" /&it; &it;label class=""custom-control-label""for=""eduuniversity""&it;university&it;/label&it; &it;/did&it; &it;/did&it; backed use travel store value database run error store array string myself. public function store(request $request,adprofil $profile) { $profile-&it;duc = $request-&it;education[]; $profile-&it;save(); return direct()-&it;route('profile.profilecomplete'); }"
61148791,PostgreSQL on Elastic Beanstalk (Amazon Linux 2),"With former generation of Amazon Linux, all I needed to do is add the following in .ebextensions in order to use PostgreSQL:
packages:
    yum:
        postgresql93-devel: []
Now when I deploy on EB with the following platform:
Python 3.7 running on 64bit Amazon Linux 2/3.0.0
I get the following error on deployment:
[ERROR] Error occurred during build: Yum does not have postgresql93-devel available for installation
Therefore it is impossible to deploy as I need to connect to a PostgreSQL database in RDS.
What config in .ebextensions do I need to do?
",<linux><postgresql><amazon-web-services><amazon-elastic-beanstalk><yum>,556,0,4,916,0,10,19,64,7173,0.0,73,4,21,2020-04-10 21:14,2020-04-10 21:22,2020-08-01 10:59,0.0,113.0,Basic,14,"<linux><postgresql><amazon-web-services><amazon-elastic-beanstalk><yum>, PostgreSQL on Elastic Beanstalk (Amazon Linux 2), With former generation of Amazon Linux, all I needed to do is add the following in .ebextensions in order to use PostgreSQL:
packages:
    yum:
        postgresql93-devel: []
Now when I deploy on EB with the following platform:
Python 3.7 running on 64bit Amazon Linux 2/3.0.0
I get the following error on deployment:
[ERROR] Error occurred during build: Yum does not have postgresql93-devel available for installation
Therefore it is impossible to deploy as I need to connect to a PostgreSQL database in RDS.
What config in .ebextensions do I need to do?
","<line><postgresql><amazon-web-services><amazon-elastic-beanstalk><sum>, postgresql last beanstalk (amazon line 2), former genet amazon line, need add follow .ebextens order use postgresql: packages: sum: postgresql93-devil: [] deploy be follow platform: patron 3.7 run bit amazon line 2/3.0.0 get follow error employment: [error] error occur build: sum postgresql93-devil avail instal therefore impose deploy need connect postgresql database rd. confirm .ebextens need do?"
56022874,"BigQuery replaced most of my Spark jobs, am I missing something?","I've been developing Spark jobs for some years using on-premise clusters and our team recently moved to the Google Cloud Platform allowing us to leverage the power of BigQuery and such.
The thing is, I now often find myself writing processing steps in SQL more than in PySpark since it is : 
easier to reason about (less verbose)
easier to maintain (SQL vs scala/python code)
you can run it easily on the GUI if needed
fast without having to really reason about partitioning, caching and so on...
In the end, I only use Spark when I've got something to do that I can't express using SQL. 
To be clear, my workflow is often like : 
preprocessing (previously in Spark, now in SQL)
feature engineering (previously in Spark, now mainly in SQL)
machine learning model and predictions (Spark ML)
Am I missing something ?
Is there any con in using BigQuery this way instead of Spark ?
Thanks
",<sql><apache-spark><apache-spark-sql><google-bigquery><bigdata>,885,0,0,667,0,5,16,60,5633,0.0,1,2,20,2019-05-07 12:41,2019-07-31 23:26,,85.0,,Intermediate,20,"<sql><apache-spark><apache-spark-sql><google-bigquery><bigdata>, BigQuery replaced most of my Spark jobs, am I missing something?, I've been developing Spark jobs for some years using on-premise clusters and our team recently moved to the Google Cloud Platform allowing us to leverage the power of BigQuery and such.
The thing is, I now often find myself writing processing steps in SQL more than in PySpark since it is : 
easier to reason about (less verbose)
easier to maintain (SQL vs scala/python code)
you can run it easily on the GUI if needed
fast without having to really reason about partitioning, caching and so on...
In the end, I only use Spark when I've got something to do that I can't express using SQL. 
To be clear, my workflow is often like : 
preprocessing (previously in Spark, now in SQL)
feature engineering (previously in Spark, now mainly in SQL)
machine learning model and predictions (Spark ML)
Am I missing something ?
Is there any con in using BigQuery this way instead of Spark ?
Thanks
","<sal><apache-spark><apache-spark-sal><goose-bigquery><bigdata>, bigqueri replace spark jobs, miss something?, i'v develop spark job year use on-premise cluster team recent move good cloud platform allow us several power bigqueri such. thing is, often find write process step sal spark since : easier reason (less verse) easier maintain (sal vs scala/patron code) run vasili gun need fast without really reason petitioning, each on... end, use spark i'v got cometh can't express use sal. clear, workflow often like : preprocess (previous spark, sal) feature engine (previous spark, mainly sal) machine learn model predict (spark my) miss cometh ? con use bigqueri way instead spark ? thank"
50907968,Server is not configured for RPC,"Looking for my job history I foudn the error below:
06/18/2018 00:00:01,MBS_Lojas_ExportaMR_OutrasLojas,Error,1,WIN-VRT-01\SQL2008,MBS_Lojas_ExportaMR_OutrasLojas,Passo1,,Executed as user: WIN-VRT-01\integracao. Server 'x.y.z' is not configured for RPC. [SQLSTATE 42000] (Error 7411).  The step failed.,01:11:15,16,7411,,,,0
I have this linked server with the option RPC and RPC Out with the values assigned to true.
In the job I have this
EXEC master.dbo.sp_serveroption @server=N'x.y.z', @optname=N'rpc', @optvalue=N'true'
EXEC master.dbo.sp_serveroption @server=N'x.y.z', @optname=N'rpc out', @optvalue=N'true'
I can't find out why is this happening and none of the solutions posted for this error could help me to debug this issue.
",<sql-server>,736,0,3,840,2,8,27,41,47285,0.0,8,3,20,2018-06-18 10:59,2019-04-22 16:54,,308.0,,Basic,13,"<sql-server>, Server is not configured for RPC, Looking for my job history I foudn the error below:
06/18/2018 00:00:01,MBS_Lojas_ExportaMR_OutrasLojas,Error,1,WIN-VRT-01\SQL2008,MBS_Lojas_ExportaMR_OutrasLojas,Passo1,,Executed as user: WIN-VRT-01\integracao. Server 'x.y.z' is not configured for RPC. [SQLSTATE 42000] (Error 7411).  The step failed.,01:11:15,16,7411,,,,0
I have this linked server with the option RPC and RPC Out with the values assigned to true.
In the job I have this
EXEC master.dbo.sp_serveroption @server=N'x.y.z', @optname=N'rpc', @optvalue=N'true'
EXEC master.dbo.sp_serveroption @server=N'x.y.z', @optname=N'rpc out', @optvalue=N'true'
I can't find out why is this happening and none of the solutions posted for this error could help me to debug this issue.
","<sal-server>, server configur rec, look job history found error below: 06/18/2018 00:00:01,mbs_lojas_exportamr_outraslojas,error,1,win-art-01\sql2008,mbs_lojas_exportamr_outraslojas,passed,,execute user: win-art-01\integracao. server 'x.y.z' configur rec. [sqlstate 42000] (error 7411). step failed.,01:11:15,16,7411,,,,0 link server option rec rec value assign true. job even master.do.sp_serveropt @server=n'x.y.z', @optname=n'rec', @optvalue=n'true' even master.do.sp_serveropt @server=n'x.y.z', @optname=n'rec out', @optvalue=n'true' can't find happen none slut post error could help debut issue."
56503583,Error while installing SQL Server 2017 Express showing sqlncli.msi is missing in some path,"I am trying to install SQL Server 2017 Express, but it is throwing this error:
sqlncli.msi is not found in the path
Screenshot illustrating the sqlncli.msi error:
",<sql-server-2017-express>,163,1,0,265,1,3,12,45,18529,0.0,0,3,20,2019-06-08 5:01,2019-06-12 13:40,,4.0,,Basic,14,"<sql-server-2017-express>, Error while installing SQL Server 2017 Express showing sqlncli.msi is missing in some path, I am trying to install SQL Server 2017 Express, but it is throwing this error:
sqlncli.msi is not found in the path
Screenshot illustrating the sqlncli.msi error:
","<sal-server-2017-express>, error instal sal server 2017 express show sqlncli.si miss path, try instal sal server 2017 express, throw error: sqlncli.si found path screenshot illusory sqlncli.si error:"
51893065,"PostgreSQL & BDR: Is BDR truly multi-master, is it Open Source and EOL for 1.x in 2019?","I am confused regarding PostgreSQL BDR and I have several questions:
Question 1: Is BDR truly multi-master for PostgreSQL?
According to the docs here, it says that:
  The BDR (Bi-Directional Replication) project adds multi-master
  replication to PostgreSQL 9.4
but if I read on 2ndQuadrant, I read the following:
If I read that part, they don't mention multi-master much at all; just that a ""second master, working in passive"", which indicates its not a real master?
Question 2: Is BDR open-source?
I read here that it is, at least that it was:
  BDR is the first open source multi-master replication system for PostgreSQL
Is it still? Because when I look, I am often directed to 2ndQuadrants webpage, and that gives me the impression that its not open-source, when they say that:
  How can you get Postgres-BDR?
  Just fill out the contact form below and a PostgreSQL expert will be in touch shortly!
Sounds like selling to me =)
Question 3: What version is what?
I read that 2ndQuadrant released version 1.0.5 in March this year. I also read on 2ndQuadrants webpage that
  In the complex environment of replication, the 3rd generation of BDR achieves...
The 3rd gen? Is version 1.0.5 that same 3rd gen, or is it something else?
Also, the same page says that:
  Note for current Postgres-BDR users: BDR 1.x  will reach EOL in December 2019. Our team of PostgreSQL experts can help plan and execute your upgrade with minimal impact and almost zero downtime. Contact us today and a member of our professional services team will be in touch with you as soon as possible.
So, 1.0.5 was released in March, but has EOL in December 2019? Is 2.x not open-source, so some license cost associated with it, and 1.x is EOL 2019?
",<postgresql><postgresql-bdr><postgres-bdr>,1719,4,0,19797,35,97,156,76,11323,0.0,615,3,20,2018-08-17 10:08,2018-08-24 10:50,2018-11-13 1:41,7.0,88.0,Intermediate,19,"<postgresql><postgresql-bdr><postgres-bdr>, PostgreSQL & BDR: Is BDR truly multi-master, is it Open Source and EOL for 1.x in 2019?, I am confused regarding PostgreSQL BDR and I have several questions:
Question 1: Is BDR truly multi-master for PostgreSQL?
According to the docs here, it says that:
  The BDR (Bi-Directional Replication) project adds multi-master
  replication to PostgreSQL 9.4
but if I read on 2ndQuadrant, I read the following:
If I read that part, they don't mention multi-master much at all; just that a ""second master, working in passive"", which indicates its not a real master?
Question 2: Is BDR open-source?
I read here that it is, at least that it was:
  BDR is the first open source multi-master replication system for PostgreSQL
Is it still? Because when I look, I am often directed to 2ndQuadrants webpage, and that gives me the impression that its not open-source, when they say that:
  How can you get Postgres-BDR?
  Just fill out the contact form below and a PostgreSQL expert will be in touch shortly!
Sounds like selling to me =)
Question 3: What version is what?
I read that 2ndQuadrant released version 1.0.5 in March this year. I also read on 2ndQuadrants webpage that
  In the complex environment of replication, the 3rd generation of BDR achieves...
The 3rd gen? Is version 1.0.5 that same 3rd gen, or is it something else?
Also, the same page says that:
  Note for current Postgres-BDR users: BDR 1.x  will reach EOL in December 2019. Our team of PostgreSQL experts can help plan and execute your upgrade with minimal impact and almost zero downtime. Contact us today and a member of our professional services team will be in touch with you as soon as possible.
So, 1.0.5 was released in March, but has EOL in December 2019? Is 2.x not open-source, so some license cost associated with it, and 1.x is EOL 2019?
","<postgresql><postgresql-dr><postures-dr>, postgresql & dr: dr truly multi-master, open source vol 1.x 2019?, confuse regard postgresql dr never questions: question 1: dr truly multi-mast postgresql? accord do here, say that: dr (i-direct application) project add multi-mast relic postgresql 9.4 read 2ndquadrant, read following: read part, mention multi-mast much all; ""second master, work passive"", india real master? question 2: dr open-source? read is, least was: dr first open source multi-mast relic system postgresql still? look, often direct 2ndquadrant webpage, give impress open-source, say that: get postures-dr? fill contact form postgresql expert touch shortly! sound like sell =) question 3: version what? read 2ndquadrant release version 1.0.5 march year. also read 2ndquadrant webpag complex environs application, rd genet dr achieved... rd gen? version 1.0.5 rd gen, cometh else? also, page say that: note current postures-dr users: dr 1.x reach vol december 2019. team postgresql expert help plan execute upgrade minims impact almost zero downtime. contact us today member profession service team touch soon possible. so, 1.0.5 release march, vol december 2019? 2.x open-source, license cost cassock it, 1.x vol 2019?"
50828041,How to open database sqlite file on iPhone real device?,"I'm debbuging a app in my real device by cable. I've a iPhone 6. I want check my database and operate with sqlite3 to query my results. The other questions and tutorials explain to do this only in simulator but I'm using a real iPhone.
In AppDelegate, I prints the path of database:
print(NSSearchPathForDirectoriesInDomains(.documentDirectory, .userDomainMask, true).last! as String)
/Users/myname/Library/Developer/CoreSimulator/Devices/DAE93E57-7004-45F6-9B93-E79CA1AEEEFA/data/Containers/Data/Application/D7A4F27E-6F11-4941-A1B0-0337ABF788AB/Documents
So, I take the path and access from terminal and access my database with sqlite3 DatabaseFile
But when I debugging in my device, the path that's printed not works. I tried use the printed path
cd /var/mobile/Containers/Data/Application/3257D423-C198-41A5-B29D-B31E99F84F34/Documents
/usr/bin/CD: line 4: cd: /var/mobile/Containers/Data/Application/3257D423-C198-41A5-B29D-B31E99F84F34/Documents: No such file or directory
This error happens because this is of iOS system, I think.
",<ios><swift><xcode><sqlite>,1037,0,5,3905,9,45,100,55,14829,0.0,529,5,20,2018-06-13 1:45,2018-06-13 5:49,,0.0,,Basic,9,"<ios><swift><xcode><sqlite>, How to open database sqlite file on iPhone real device?, I'm debbuging a app in my real device by cable. I've a iPhone 6. I want check my database and operate with sqlite3 to query my results. The other questions and tutorials explain to do this only in simulator but I'm using a real iPhone.
In AppDelegate, I prints the path of database:
print(NSSearchPathForDirectoriesInDomains(.documentDirectory, .userDomainMask, true).last! as String)
/Users/myname/Library/Developer/CoreSimulator/Devices/DAE93E57-7004-45F6-9B93-E79CA1AEEEFA/data/Containers/Data/Application/D7A4F27E-6F11-4941-A1B0-0337ABF788AB/Documents
So, I take the path and access from terminal and access my database with sqlite3 DatabaseFile
But when I debugging in my device, the path that's printed not works. I tried use the printed path
cd /var/mobile/Containers/Data/Application/3257D423-C198-41A5-B29D-B31E99F84F34/Documents
/usr/bin/CD: line 4: cd: /var/mobile/Containers/Data/Application/3257D423-C198-41A5-B29D-B31E99F84F34/Documents: No such file or directory
This error happens because this is of iOS system, I think.
","<is><swift><code><quite>, open database quite file upon real device?, i'm debut pp real devil cable. i'v upon 6. want check database over sqlite3 query results. question tutor explain soul i'm use real phone. appdelegate, print path database: print(nssearchpathfordirectoriesindomains(.documentdirectory, .userdomainmask, true).last! string) /users/name/library/developer/coresimulator/devices/dae93e57-7004-45f6-9b93-e79ca1aeeefa/data/container/data/application/d7a4f27e-6f11-4941-abbe-0337abf788ab/dock so, take path access german access database sqlite3 databasefil debut device, path that' print works. try use print path d /war/mobile/container/data/application/3257d423-c198-41a5-bed-b31e99f84f34/dock /us/bin/d: line 4: d: /war/mobile/container/data/application/3257d423-c198-41a5-bed-b31e99f84f34/documents: file director error happen to system, think."
52000903,How to start flyway after database initialization in Docker,"I have following docker compose file(docker-compose-dev.yml):
version: '3'
services:
  my_sql_db:
    image: percona:latest
    container_name: my_sql_db
    environment:
      MYSQL_ROOT_PASSWORD: password
      MYSQL_DATABASE: abhs
    ports:
    - ""3306:3306""
  migration:
    image: boxfuse/flyway:latest
    container_name: flyway_migration
    volumes:
      - ./flyway_scripts/src/main/resources/db/migration:/flyway/sql
    command: -url=jdbc:mysql://my_sql_db:3306/abhs?useUnicode=true&amp;characterEncoding=utf8&amp;useSSL=false -user=root -password=password migrate
    depends_on:
    - my_sql_db
and following docker-compose.yml:
version: '3'
services:
  migration:
    image: boxfuse/flyway:latest
    container_name: flyway_migration
    volumes:
     - ./flyway_scripts/src/main/resources/db/migration:/flyway/sql
Then I execute following command:
docker-compose -f docker-compose.yml -f docker-compose-dev.yml up
And It lead to error:
In logs I see following:
my_sql_db    | Initializing database
flyway_migration  | Flyway Community Edition 5.1.4 by Boxfuse
flyway_migration  |
my_sql_db    | 2018-08-24T08:47:41.616694Z 0 [Warning] 'NO_ZERO_DATE', 'NO_ZERO_IN_DATE' and 'ERROR_FOR_DIVISION_BY_ZERO' sql modes should be used with strict mode. They will be merged with strict mode in a future release.
my_sql_db    | 2018-08-24T08:47:41.616747Z 0 [Warning] 'NO_AUTO_CREATE_USER' sql mode was not set.
flyway_migration  | ERROR:
flyway_migration  | Unable to obtain connection from database (jdbc:mysql://my_sql_db:3306/abhs?useUnicode=true&amp;characterEncoding=utf8&amp;useSSL=false) for user 'root': Could not connect to address=(host=my_sql_db)(port=3306)(type=master) : Connection refused (Connection refused)
flyway_migration  | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
flyway_migration  | SQL State  : 08
flyway_migration  | Error Code : -1
flyway_migration  | Message    : Could not connect to address=(host=my_sql_db)(port=3306)(type=master) : Connection refused (Connection refused)
my_sql_db    | 2018-08-24T08:47:43.024690Z 0 [Warning] InnoDB: New log files created, LSN=45790
flyway_migration  |
my_sql_db    | 2018-08-24T08:47:43.443625Z 0 [Warning] InnoDB: Creating foreign key constraint system tables.
my_sql_db    | 2018-08-24T08:47:43.588008Z 0 [Warning] No existing UUID has been found, so we assume that this is the first time that this server has been started. Generating a new UUID: 5dc59a4f-a77a-11e8-b6cb-0242ac130002.
my_sql_db    | 2018-08-24T08:47:43.760654Z 0 [Warning] Gtid table is not ready to be used. Table 'mysql.gtid_executed' cannot be opened.
my_sql_db    | 2018-08-24T08:47:44.518107Z 0 [Warning] CA certificate ca.pem is self signed.
my_sql_db    | 2018-08-24T08:47:44.925466Z 1 [Warning] root@localhost is created with an empty password ! Please consider switching off the --initialize-insecure option.
my_sql_db    | 2018-08-24T08:47:54.762213Z 1 [Warning] 'user' entry 'root@localhost' ignored in --skip-name-resolve mode.
my_sql_db    | 2018-08-24T08:47:54.762517Z 1 [Warning] 'user' entry 'mysql.session@localhost' ignored in --skip-name-resolve mode.
my_sql_db    | 2018-08-24T08:47:54.762889Z 1 [Warning] 'user' entry 'mysql.sys@localhost' ignored in --skip-name-resolve mode.
my_sql_db    | 2018-08-24T08:47:54.763244Z 1 [Warning] 'db' entry 'performance_schema mysql.session@localhost' ignored in --skip-name-resolve mode.
my_sql_db    | 2018-08-24T08:47:54.763472Z 1 [Warning] 'db' entry 'sys mysql.sys@localhost' ignored in --skip-name-resolve mode.
my_sql_db    | 2018-08-24T08:47:54.763788Z 1 [Warning] 'proxies_priv' entry '@ root@localhost' ignored in --skip-name-resolve mode.
my_sql_db    | 2018-08-24T08:47:54.763928Z 1 [Warning] 'tables_priv' entry 'user mysql.session@localhost' ignored in --skip-name-resolve mode.
my_sql_db    | 2018-08-24T08:47:54.764128Z 1 [Warning] 'tables_priv' entry 'sys_config mysql.sys@localhost' ignored in --skip-name-resolve mode.
my_sql_db    | Database initialized
my_sql_db    | MySQL init process in progress...
my_sql_db    | 2018-08-24T08:47:58.970290Z 0 [Warning] 'NO_ZERO_DATE', 'NO_ZERO_IN_DATE' and 'ERROR_FOR_DIVISION_BY_ZERO' sql modes should be used with strict mode. They will be merged with strict mode in a future release.
my_sql_db    | 2018-08-24T08:47:58.970345Z 0 [Warning] 'NO_AUTO_CREATE_USER' sql mode was not set.
my_sql_db    | 2018-08-24T08:47:58.974061Z 0 [Note] mysqld (mysqld 5.7.22-22) starting as process 58 ...
my_sql_db    | 2018-08-24T08:47:58.999651Z 0 [Note] InnoDB: PUNCH HOLE support available
my_sql_db    | 2018-08-24T08:47:58.999685Z 0 [Note] InnoDB: Mutexes and rw_locks use GCC atomic builtins
my_sql_db    | 2018-08-24T08:47:58.999689Z 0 [Note] InnoDB: Uses event mutexes
my_sql_db    | 2018-08-24T08:47:58.999692Z 0 [Note] InnoDB: GCC builtin __atomic_thread_fence() is used for memory barrier
my_sql_db    | 2018-08-24T08:47:58.999695Z 0 [Note] InnoDB: Compressed tables use zlib 1.2.8
my_sql_db    | 2018-08-24T08:47:58.999698Z 0 [Note] InnoDB: Using Linux native AIO
my_sql_db    | 2018-08-24T08:47:59.000153Z 0 [Note] InnoDB: Number of pools: 1
my_sql_db    | 2018-08-24T08:47:59.000426Z 0 [Note] InnoDB: Using CPU crc32 instructions
my_sql_db    | 2018-08-24T08:47:59.002306Z 0 [Note] InnoDB: Initializing buffer pool, total size = 128M, instances = 1, chunk size = 128M
my_sql_db    | 2018-08-24T08:47:59.006893Z 0 [Note] InnoDB: Completed initialization of buffer pool
my_sql_db    | 2018-08-24T08:47:59.013219Z 0 [Note] InnoDB: If the mysqld execution user is authorized, page cleaner thread priority can be changed. See the man page of setpriority().
my_sql_db    | 2018-08-24T08:47:59.024242Z 0 [Note] InnoDB: Crash recovery did not find the parallel doublewrite buffer at /var/lib/mysql/xb_doublewrite
my_sql_db    | 2018-08-24T08:47:59.026263Z 0 [Note] InnoDB: Highest supported file format is Barracuda.
my_sql_db    | 2018-08-24T08:47:59.066469Z 0 [Note] InnoDB: Created parallel doublewrite buffer at /var/lib/mysql/xb_doublewrite, size 3932160 bytes
my_sql_db    | 2018-08-24T08:47:59.071752Z 0 [Note] InnoDB: Creating shared tablespace for temporary tables
my_sql_db    | 2018-08-24T08:47:59.072052Z 0 [Note] InnoDB: Setting file './ibtmp1' size to 12 MB. Physically writing the file full; Please wait ...
my_sql_db    | 2018-08-24T08:47:59.422155Z 0 [Note] InnoDB: File './ibtmp1' size is now 12 MB.
my_sql_db    | 2018-08-24T08:47:59.423325Z 0 [Note] InnoDB: 96 redo rollback segment(s) found. 96 redo rollback segment(s) are active.
my_sql_db    | 2018-08-24T08:47:59.423376Z 0 [Note] InnoDB: 32 non-redo rollback segment(s) are active.
my_sql_db    | 2018-08-24T08:47:59.423900Z 0 [Note] InnoDB: Waiting for purge to start
my_sql_db    | 2018-08-24T08:47:59.474066Z 0 [Note] InnoDB: Percona XtraDB (http://www.percona.com) 5.7.22-22 started; log sequence number 2595255
my_sql_db    | 2018-08-24T08:47:59.474647Z 0 [Note] Plugin 'FEDERATED' is disabled.
my_sql_db    | 2018-08-24T08:47:59.499970Z 0 [Note] Found ca.pem, server-cert.pem and server-key.pem in data directory. Trying to enable SSL support using them.
my_sql_db    | 2018-08-24T08:47:59.500004Z 0 [Note] Skipping generation of SSL certificates as certificate files are present in data directory.
my_sql_db    | 2018-08-24T08:47:59.500382Z 0 [Note] InnoDB: Loading buffer pool(s) from /var/lib/mysql/ib_buffer_pool
my_sql_db    | 2018-08-24T08:47:59.501263Z 0 [Warning] CA certificate ca.pem is self signed.
my_sql_db    | 2018-08-24T08:47:59.522151Z 0 [Note] Skipping generation of RSA key pair as key files are present in data directory.
my_sql_db    | 2018-08-24T08:47:59.531657Z 0 [Note] InnoDB: Buffer pool(s) load completed at 180824  8:47:59
Looks like flyway starts before database initialization and hence could not connect to database and I see the error below.
How can I fix that problem?
P.S.
I googled similar questions and I found the following piece of advice: https://github.com/vishnubob/wait-for-it but I am novice in docker  and I don't understand how to put it into my docker compose file
P.S.2
I tried to put file wait-fot-it.sh near the compose file and execute:
command: [""./wait-for-it.sh"", ""mysql:3306"", ""--"", ""-url=jdbc:mysql://my_sql_db:3306/abhs?useUnicode=true&amp;characterEncoding=utf8&amp;useSSL=false -user=root -password=password migrate""]
But I returns ERROR: Invalid argument: ./wait-for-it.sh
P.S.3
I tried approach from ""Duplicated"" topic:
version: '3'
services:
  my_sql_db:
    image: percona:latest
    container_name: my_sql_db
    environment:
      MYSQL_ROOT_PASSWORD: password
      MYSQL_DATABASE: abhs
    ports:
    - ""3306:3306""
    healthcheck:
      test: [""CMD"", ""mysqladmin"" ,""ping"", ""-h"", ""localhost""]
      timeout: 20s
      retries: 10
  migration:
    image: boxfuse/flyway:latest
    container_name: flyway_migration
    volumes:
      - ./flyway_scripts/src/main/resources/db/migration:/flyway/sql
    command: -url=jdbc:mysql://my_sql_db:3306/abhs?useUnicode=true&amp;characterEncoding=utf8&amp;useSSL=false -user=root -password=password migrate
    depends_on:
      my_sql_db:
        condition: service_healthy
but I see following error:
$ docker-compose -f docker-compose.yml -f docker-compose-dev.yml up
The Compose file '.\docker-compose-dev.yml' is invalid because:
services.migration.depends_on contains an invalid type, it should be an array
P.S.4
for that approach I see following error:
version: '3'
services:
  my_sql_db:
    image: percona:latest
    container_name: my_sql_db
    environment:
      MYSQL_ROOT_PASSWORD: password
      MYSQL_DATABASE: abhs
    ports:
    - ""3306:3306""
    healthcheck:
      test: [""CMD"", ""mysqladmin"" ,""ping"", ""-h"", ""localhost""]
      timeout: 20s
      retries: 10
  migration:
    image: boxfuse/flyway:latest
    container_name: flyway_migration
    volumes:
      - ./flyway_scripts/src/main/resources/db/migration:/flyway/sql
    command: dockerize wait jdbc:mysql://my_sql_db:3306 -url=jdbc:mysql://my_sql_db:3306/abhs?useUnicode=true&amp;characterEncoding=utf8&amp;useSSL=false -user=root -password=password migrate
    depends_on:
      - my_sql_db
I see following error:
flyway_migration  | ERROR: Invalid argument: dockerize
UPDATE_1
wait-for-it.sh content:
#!/usr/bin/env bash
#   Use this script to test if a given TCP host/port are available
cmdname=$(basename $0)
echoerr() { if [[ $QUIET -ne 1 ]]; then echo ""$@"" 1&gt;&amp;2; fi }
usage()
{
    cat &lt;&lt; USAGE &gt;&amp;2
Usage:
    $cmdname host:port [-s] [-t timeout] [-- command args]
    -h HOST | --host=HOST       Host or IP under test
    -p PORT | --port=PORT       TCP port under test
                                Alternatively, you specify the host and port as host:port
    -s | --strict               Only execute subcommand if the test succeeds
    -q | --quiet                Don't output any status messages
    -t TIMEOUT | --timeout=TIMEOUT
                                Timeout in seconds, zero for no timeout
    -- COMMAND ARGS             Execute command with args after the test finishes
USAGE
    exit 1
}
wait_for()
{
    if [[ $TIMEOUT -gt 0 ]]; then
        echoerr ""$cmdname: waiting $TIMEOUT seconds for $HOST:$PORT""
    else
        echoerr ""$cmdname: waiting for $HOST:$PORT without a timeout""
    fi
    start_ts=$(date +%s)
    while :
    do
        if [[ $ISBUSY -eq 1 ]]; then
            nc -z $HOST $PORT
            result=$?
        else
            (echo &gt; /dev/tcp/$HOST/$PORT) &gt;/dev/null 2&gt;&amp;1
            result=$?
        fi
        if [[ $result -eq 0 ]]; then
            end_ts=$(date +%s)
            echoerr ""$cmdname: $HOST:$PORT is available after $((end_ts - start_ts)) seconds""
            break
        fi
        sleep 1
    done
    return $result
}
wait_for_wrapper()
{
    # In order to support SIGINT during timeout: http://unix.stackexchange.com/a/57692
    if [[ $QUIET -eq 1 ]]; then
        timeout $BUSYTIMEFLAG $TIMEOUT $0 --quiet --child --host=$HOST --port=$PORT --timeout=$TIMEOUT &amp;
    else
        timeout $BUSYTIMEFLAG $TIMEOUT $0 --child --host=$HOST --port=$PORT --timeout=$TIMEOUT &amp;
    fi
    PID=$!
    trap ""kill -INT -$PID"" INT
    wait $PID
    RESULT=$?
    if [[ $RESULT -ne 0 ]]; then
        echoerr ""$cmdname: timeout occurred after waiting $TIMEOUT seconds for $HOST:$PORT""
    fi
    return $RESULT
}
# process arguments
while [[ $# -gt 0 ]]
do
    case ""$1"" in
        *:* )
        hostport=(${1//:/ })
        HOST=${hostport[0]}
        PORT=${hostport[1]}
        shift 1
        ;;
        --child)
        CHILD=1
        shift 1
        ;;
        -q | --quiet)
        QUIET=1
        shift 1
        ;;
        -s | --strict)
        STRICT=1
        shift 1
        ;;
        -h)
        HOST=""$2""
        if [[ $HOST == """" ]]; then break; fi
        shift 2
        ;;
        --host=*)
        HOST=""${1#*=}""
        shift 1
        ;;
        -p)
        PORT=""$2""
        if [[ $PORT == """" ]]; then break; fi
        shift 2
        ;;
        --port=*)
        PORT=""${1#*=}""
        shift 1
        ;;
        -t)
        TIMEOUT=""$2""
        if [[ $TIMEOUT == """" ]]; then break; fi
        shift 2
        ;;
        --timeout=*)
        TIMEOUT=""${1#*=}""
        shift 1
        ;;
        --)
        shift
        CLI=(""$@"")
        break
        ;;
        --help)
        usage
        ;;
        *)
        echoerr ""Unknown argument: $1""
        usage
        ;;
    esac
done
if [[ ""$HOST"" == """" || ""$PORT"" == """" ]]; then
    echoerr ""Error: you need to provide a host and port to test.""
    usage
fi
TIMEOUT=${TIMEOUT:-15}
STRICT=${STRICT:-0}
CHILD=${CHILD:-0}
QUIET=${QUIET:-0}
# check to see if timeout is from busybox?
# check to see if timeout is from busybox?
TIMEOUT_PATH=$(realpath $(which timeout))
if [[ $TIMEOUT_PATH =~ ""busybox"" ]]; then
        ISBUSY=1
        BUSYTIMEFLAG=""-t""
else
        ISBUSY=0
        BUSYTIMEFLAG=""""
fi
if [[ $CHILD -gt 0 ]]; then
    wait_for
    RESULT=$?
    exit $RESULT
else
    if [[ $TIMEOUT -gt 0 ]]; then
        wait_for_wrapper
        RESULT=$?
    else
        wait_for
        RESULT=$?
    fi
fi
if [[ $CLI != """" ]]; then
    if [[ $RESULT -ne 0 &amp;&amp; $STRICT -eq 1 ]]; then
        echoerr ""$cmdname: strict mode, refusing to execute subprocess""
        exit $RESULT
    fi
    exec ""${CLI[@]}""
else
    exit $RESULT
fi
P.S.5
Also I tried this:
version: '3'
services:
  my_sql_db:
    image: percona:latest
    container_name: my_sql_db
    environment:
      MYSQL_ROOT_PASSWORD: password
      MYSQL_DATABASE: abhs
    ports:
    - ""3306:3306""
    healthcheck:
      test: [""CMD"", ""mysqladmin"" ,""ping"", ""-h"", ""localhost""]
      timeout: 20s
      retries: 10
  migration:
    image: boxfuse/flyway:latest
    container_name: flyway_migration
    volumes:
     - ./flyway_scripts/src/main/resources/db/migration:/flyway/sql
    entrypoint: [""wait-for-it.sh"", ""mysql:3306"", ""--"", ""docker-entrypoint.sh""]      
    command: -url=jdbc:mysql://my_sql_db:3306/abhs?useUnicode=true&amp;characterEncoding=utf8&amp;useSSL=false -user=root -password=password migrate
    depends_on:
      - my_sql_db
It leads to error:
Creating flyway_migration ... error
ERROR: for flyway_migration  Cannot start service migration: OCI runtime create failed: container_linux.go:348: starting container process caused ""exec: \""wait-for-it.sh\"": executable file not found in $PATH"": unknown
ERROR: for migration  Cannot start service migration: OCI runtime create failed: container_linux.go:348: starting container process caused ""exec: \""wait-for-it.sh\"": executable file not found in $PATH"": unknown
Encountered errors while bringing up the project.
",<java><mysql><docker><flyway><depends>,15862,4,344,36992,119,374,727,63,20204,0.0,3581,3,20,2018-08-24 8:59,2018-08-27 12:12,,3.0,,Advanced,32,"<java><mysql><docker><flyway><depends>, How to start flyway after database initialization in Docker, I have following docker compose file(docker-compose-dev.yml):
version: '3'
services:
  my_sql_db:
    image: percona:latest
    container_name: my_sql_db
    environment:
      MYSQL_ROOT_PASSWORD: password
      MYSQL_DATABASE: abhs
    ports:
    - ""3306:3306""
  migration:
    image: boxfuse/flyway:latest
    container_name: flyway_migration
    volumes:
      - ./flyway_scripts/src/main/resources/db/migration:/flyway/sql
    command: -url=jdbc:mysql://my_sql_db:3306/abhs?useUnicode=true&amp;characterEncoding=utf8&amp;useSSL=false -user=root -password=password migrate
    depends_on:
    - my_sql_db
and following docker-compose.yml:
version: '3'
services:
  migration:
    image: boxfuse/flyway:latest
    container_name: flyway_migration
    volumes:
     - ./flyway_scripts/src/main/resources/db/migration:/flyway/sql
Then I execute following command:
docker-compose -f docker-compose.yml -f docker-compose-dev.yml up
And It lead to error:
In logs I see following:
my_sql_db    | Initializing database
flyway_migration  | Flyway Community Edition 5.1.4 by Boxfuse
flyway_migration  |
my_sql_db    | 2018-08-24T08:47:41.616694Z 0 [Warning] 'NO_ZERO_DATE', 'NO_ZERO_IN_DATE' and 'ERROR_FOR_DIVISION_BY_ZERO' sql modes should be used with strict mode. They will be merged with strict mode in a future release.
my_sql_db    | 2018-08-24T08:47:41.616747Z 0 [Warning] 'NO_AUTO_CREATE_USER' sql mode was not set.
flyway_migration  | ERROR:
flyway_migration  | Unable to obtain connection from database (jdbc:mysql://my_sql_db:3306/abhs?useUnicode=true&amp;characterEncoding=utf8&amp;useSSL=false) for user 'root': Could not connect to address=(host=my_sql_db)(port=3306)(type=master) : Connection refused (Connection refused)
flyway_migration  | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
flyway_migration  | SQL State  : 08
flyway_migration  | Error Code : -1
flyway_migration  | Message    : Could not connect to address=(host=my_sql_db)(port=3306)(type=master) : Connection refused (Connection refused)
my_sql_db    | 2018-08-24T08:47:43.024690Z 0 [Warning] InnoDB: New log files created, LSN=45790
flyway_migration  |
my_sql_db    | 2018-08-24T08:47:43.443625Z 0 [Warning] InnoDB: Creating foreign key constraint system tables.
my_sql_db    | 2018-08-24T08:47:43.588008Z 0 [Warning] No existing UUID has been found, so we assume that this is the first time that this server has been started. Generating a new UUID: 5dc59a4f-a77a-11e8-b6cb-0242ac130002.
my_sql_db    | 2018-08-24T08:47:43.760654Z 0 [Warning] Gtid table is not ready to be used. Table 'mysql.gtid_executed' cannot be opened.
my_sql_db    | 2018-08-24T08:47:44.518107Z 0 [Warning] CA certificate ca.pem is self signed.
my_sql_db    | 2018-08-24T08:47:44.925466Z 1 [Warning] root@localhost is created with an empty password ! Please consider switching off the --initialize-insecure option.
my_sql_db    | 2018-08-24T08:47:54.762213Z 1 [Warning] 'user' entry 'root@localhost' ignored in --skip-name-resolve mode.
my_sql_db    | 2018-08-24T08:47:54.762517Z 1 [Warning] 'user' entry 'mysql.session@localhost' ignored in --skip-name-resolve mode.
my_sql_db    | 2018-08-24T08:47:54.762889Z 1 [Warning] 'user' entry 'mysql.sys@localhost' ignored in --skip-name-resolve mode.
my_sql_db    | 2018-08-24T08:47:54.763244Z 1 [Warning] 'db' entry 'performance_schema mysql.session@localhost' ignored in --skip-name-resolve mode.
my_sql_db    | 2018-08-24T08:47:54.763472Z 1 [Warning] 'db' entry 'sys mysql.sys@localhost' ignored in --skip-name-resolve mode.
my_sql_db    | 2018-08-24T08:47:54.763788Z 1 [Warning] 'proxies_priv' entry '@ root@localhost' ignored in --skip-name-resolve mode.
my_sql_db    | 2018-08-24T08:47:54.763928Z 1 [Warning] 'tables_priv' entry 'user mysql.session@localhost' ignored in --skip-name-resolve mode.
my_sql_db    | 2018-08-24T08:47:54.764128Z 1 [Warning] 'tables_priv' entry 'sys_config mysql.sys@localhost' ignored in --skip-name-resolve mode.
my_sql_db    | Database initialized
my_sql_db    | MySQL init process in progress...
my_sql_db    | 2018-08-24T08:47:58.970290Z 0 [Warning] 'NO_ZERO_DATE', 'NO_ZERO_IN_DATE' and 'ERROR_FOR_DIVISION_BY_ZERO' sql modes should be used with strict mode. They will be merged with strict mode in a future release.
my_sql_db    | 2018-08-24T08:47:58.970345Z 0 [Warning] 'NO_AUTO_CREATE_USER' sql mode was not set.
my_sql_db    | 2018-08-24T08:47:58.974061Z 0 [Note] mysqld (mysqld 5.7.22-22) starting as process 58 ...
my_sql_db    | 2018-08-24T08:47:58.999651Z 0 [Note] InnoDB: PUNCH HOLE support available
my_sql_db    | 2018-08-24T08:47:58.999685Z 0 [Note] InnoDB: Mutexes and rw_locks use GCC atomic builtins
my_sql_db    | 2018-08-24T08:47:58.999689Z 0 [Note] InnoDB: Uses event mutexes
my_sql_db    | 2018-08-24T08:47:58.999692Z 0 [Note] InnoDB: GCC builtin __atomic_thread_fence() is used for memory barrier
my_sql_db    | 2018-08-24T08:47:58.999695Z 0 [Note] InnoDB: Compressed tables use zlib 1.2.8
my_sql_db    | 2018-08-24T08:47:58.999698Z 0 [Note] InnoDB: Using Linux native AIO
my_sql_db    | 2018-08-24T08:47:59.000153Z 0 [Note] InnoDB: Number of pools: 1
my_sql_db    | 2018-08-24T08:47:59.000426Z 0 [Note] InnoDB: Using CPU crc32 instructions
my_sql_db    | 2018-08-24T08:47:59.002306Z 0 [Note] InnoDB: Initializing buffer pool, total size = 128M, instances = 1, chunk size = 128M
my_sql_db    | 2018-08-24T08:47:59.006893Z 0 [Note] InnoDB: Completed initialization of buffer pool
my_sql_db    | 2018-08-24T08:47:59.013219Z 0 [Note] InnoDB: If the mysqld execution user is authorized, page cleaner thread priority can be changed. See the man page of setpriority().
my_sql_db    | 2018-08-24T08:47:59.024242Z 0 [Note] InnoDB: Crash recovery did not find the parallel doublewrite buffer at /var/lib/mysql/xb_doublewrite
my_sql_db    | 2018-08-24T08:47:59.026263Z 0 [Note] InnoDB: Highest supported file format is Barracuda.
my_sql_db    | 2018-08-24T08:47:59.066469Z 0 [Note] InnoDB: Created parallel doublewrite buffer at /var/lib/mysql/xb_doublewrite, size 3932160 bytes
my_sql_db    | 2018-08-24T08:47:59.071752Z 0 [Note] InnoDB: Creating shared tablespace for temporary tables
my_sql_db    | 2018-08-24T08:47:59.072052Z 0 [Note] InnoDB: Setting file './ibtmp1' size to 12 MB. Physically writing the file full; Please wait ...
my_sql_db    | 2018-08-24T08:47:59.422155Z 0 [Note] InnoDB: File './ibtmp1' size is now 12 MB.
my_sql_db    | 2018-08-24T08:47:59.423325Z 0 [Note] InnoDB: 96 redo rollback segment(s) found. 96 redo rollback segment(s) are active.
my_sql_db    | 2018-08-24T08:47:59.423376Z 0 [Note] InnoDB: 32 non-redo rollback segment(s) are active.
my_sql_db    | 2018-08-24T08:47:59.423900Z 0 [Note] InnoDB: Waiting for purge to start
my_sql_db    | 2018-08-24T08:47:59.474066Z 0 [Note] InnoDB: Percona XtraDB (http://www.percona.com) 5.7.22-22 started; log sequence number 2595255
my_sql_db    | 2018-08-24T08:47:59.474647Z 0 [Note] Plugin 'FEDERATED' is disabled.
my_sql_db    | 2018-08-24T08:47:59.499970Z 0 [Note] Found ca.pem, server-cert.pem and server-key.pem in data directory. Trying to enable SSL support using them.
my_sql_db    | 2018-08-24T08:47:59.500004Z 0 [Note] Skipping generation of SSL certificates as certificate files are present in data directory.
my_sql_db    | 2018-08-24T08:47:59.500382Z 0 [Note] InnoDB: Loading buffer pool(s) from /var/lib/mysql/ib_buffer_pool
my_sql_db    | 2018-08-24T08:47:59.501263Z 0 [Warning] CA certificate ca.pem is self signed.
my_sql_db    | 2018-08-24T08:47:59.522151Z 0 [Note] Skipping generation of RSA key pair as key files are present in data directory.
my_sql_db    | 2018-08-24T08:47:59.531657Z 0 [Note] InnoDB: Buffer pool(s) load completed at 180824  8:47:59
Looks like flyway starts before database initialization and hence could not connect to database and I see the error below.
How can I fix that problem?
P.S.
I googled similar questions and I found the following piece of advice: https://github.com/vishnubob/wait-for-it but I am novice in docker  and I don't understand how to put it into my docker compose file
P.S.2
I tried to put file wait-fot-it.sh near the compose file and execute:
command: [""./wait-for-it.sh"", ""mysql:3306"", ""--"", ""-url=jdbc:mysql://my_sql_db:3306/abhs?useUnicode=true&amp;characterEncoding=utf8&amp;useSSL=false -user=root -password=password migrate""]
But I returns ERROR: Invalid argument: ./wait-for-it.sh
P.S.3
I tried approach from ""Duplicated"" topic:
version: '3'
services:
  my_sql_db:
    image: percona:latest
    container_name: my_sql_db
    environment:
      MYSQL_ROOT_PASSWORD: password
      MYSQL_DATABASE: abhs
    ports:
    - ""3306:3306""
    healthcheck:
      test: [""CMD"", ""mysqladmin"" ,""ping"", ""-h"", ""localhost""]
      timeout: 20s
      retries: 10
  migration:
    image: boxfuse/flyway:latest
    container_name: flyway_migration
    volumes:
      - ./flyway_scripts/src/main/resources/db/migration:/flyway/sql
    command: -url=jdbc:mysql://my_sql_db:3306/abhs?useUnicode=true&amp;characterEncoding=utf8&amp;useSSL=false -user=root -password=password migrate
    depends_on:
      my_sql_db:
        condition: service_healthy
but I see following error:
$ docker-compose -f docker-compose.yml -f docker-compose-dev.yml up
The Compose file '.\docker-compose-dev.yml' is invalid because:
services.migration.depends_on contains an invalid type, it should be an array
P.S.4
for that approach I see following error:
version: '3'
services:
  my_sql_db:
    image: percona:latest
    container_name: my_sql_db
    environment:
      MYSQL_ROOT_PASSWORD: password
      MYSQL_DATABASE: abhs
    ports:
    - ""3306:3306""
    healthcheck:
      test: [""CMD"", ""mysqladmin"" ,""ping"", ""-h"", ""localhost""]
      timeout: 20s
      retries: 10
  migration:
    image: boxfuse/flyway:latest
    container_name: flyway_migration
    volumes:
      - ./flyway_scripts/src/main/resources/db/migration:/flyway/sql
    command: dockerize wait jdbc:mysql://my_sql_db:3306 -url=jdbc:mysql://my_sql_db:3306/abhs?useUnicode=true&amp;characterEncoding=utf8&amp;useSSL=false -user=root -password=password migrate
    depends_on:
      - my_sql_db
I see following error:
flyway_migration  | ERROR: Invalid argument: dockerize
UPDATE_1
wait-for-it.sh content:
#!/usr/bin/env bash
#   Use this script to test if a given TCP host/port are available
cmdname=$(basename $0)
echoerr() { if [[ $QUIET -ne 1 ]]; then echo ""$@"" 1&gt;&amp;2; fi }
usage()
{
    cat &lt;&lt; USAGE &gt;&amp;2
Usage:
    $cmdname host:port [-s] [-t timeout] [-- command args]
    -h HOST | --host=HOST       Host or IP under test
    -p PORT | --port=PORT       TCP port under test
                                Alternatively, you specify the host and port as host:port
    -s | --strict               Only execute subcommand if the test succeeds
    -q | --quiet                Don't output any status messages
    -t TIMEOUT | --timeout=TIMEOUT
                                Timeout in seconds, zero for no timeout
    -- COMMAND ARGS             Execute command with args after the test finishes
USAGE
    exit 1
}
wait_for()
{
    if [[ $TIMEOUT -gt 0 ]]; then
        echoerr ""$cmdname: waiting $TIMEOUT seconds for $HOST:$PORT""
    else
        echoerr ""$cmdname: waiting for $HOST:$PORT without a timeout""
    fi
    start_ts=$(date +%s)
    while :
    do
        if [[ $ISBUSY -eq 1 ]]; then
            nc -z $HOST $PORT
            result=$?
        else
            (echo &gt; /dev/tcp/$HOST/$PORT) &gt;/dev/null 2&gt;&amp;1
            result=$?
        fi
        if [[ $result -eq 0 ]]; then
            end_ts=$(date +%s)
            echoerr ""$cmdname: $HOST:$PORT is available after $((end_ts - start_ts)) seconds""
            break
        fi
        sleep 1
    done
    return $result
}
wait_for_wrapper()
{
    # In order to support SIGINT during timeout: http://unix.stackexchange.com/a/57692
    if [[ $QUIET -eq 1 ]]; then
        timeout $BUSYTIMEFLAG $TIMEOUT $0 --quiet --child --host=$HOST --port=$PORT --timeout=$TIMEOUT &amp;
    else
        timeout $BUSYTIMEFLAG $TIMEOUT $0 --child --host=$HOST --port=$PORT --timeout=$TIMEOUT &amp;
    fi
    PID=$!
    trap ""kill -INT -$PID"" INT
    wait $PID
    RESULT=$?
    if [[ $RESULT -ne 0 ]]; then
        echoerr ""$cmdname: timeout occurred after waiting $TIMEOUT seconds for $HOST:$PORT""
    fi
    return $RESULT
}
# process arguments
while [[ $# -gt 0 ]]
do
    case ""$1"" in
        *:* )
        hostport=(${1//:/ })
        HOST=${hostport[0]}
        PORT=${hostport[1]}
        shift 1
        ;;
        --child)
        CHILD=1
        shift 1
        ;;
        -q | --quiet)
        QUIET=1
        shift 1
        ;;
        -s | --strict)
        STRICT=1
        shift 1
        ;;
        -h)
        HOST=""$2""
        if [[ $HOST == """" ]]; then break; fi
        shift 2
        ;;
        --host=*)
        HOST=""${1#*=}""
        shift 1
        ;;
        -p)
        PORT=""$2""
        if [[ $PORT == """" ]]; then break; fi
        shift 2
        ;;
        --port=*)
        PORT=""${1#*=}""
        shift 1
        ;;
        -t)
        TIMEOUT=""$2""
        if [[ $TIMEOUT == """" ]]; then break; fi
        shift 2
        ;;
        --timeout=*)
        TIMEOUT=""${1#*=}""
        shift 1
        ;;
        --)
        shift
        CLI=(""$@"")
        break
        ;;
        --help)
        usage
        ;;
        *)
        echoerr ""Unknown argument: $1""
        usage
        ;;
    esac
done
if [[ ""$HOST"" == """" || ""$PORT"" == """" ]]; then
    echoerr ""Error: you need to provide a host and port to test.""
    usage
fi
TIMEOUT=${TIMEOUT:-15}
STRICT=${STRICT:-0}
CHILD=${CHILD:-0}
QUIET=${QUIET:-0}
# check to see if timeout is from busybox?
# check to see if timeout is from busybox?
TIMEOUT_PATH=$(realpath $(which timeout))
if [[ $TIMEOUT_PATH =~ ""busybox"" ]]; then
        ISBUSY=1
        BUSYTIMEFLAG=""-t""
else
        ISBUSY=0
        BUSYTIMEFLAG=""""
fi
if [[ $CHILD -gt 0 ]]; then
    wait_for
    RESULT=$?
    exit $RESULT
else
    if [[ $TIMEOUT -gt 0 ]]; then
        wait_for_wrapper
        RESULT=$?
    else
        wait_for
        RESULT=$?
    fi
fi
if [[ $CLI != """" ]]; then
    if [[ $RESULT -ne 0 &amp;&amp; $STRICT -eq 1 ]]; then
        echoerr ""$cmdname: strict mode, refusing to execute subprocess""
        exit $RESULT
    fi
    exec ""${CLI[@]}""
else
    exit $RESULT
fi
P.S.5
Also I tried this:
version: '3'
services:
  my_sql_db:
    image: percona:latest
    container_name: my_sql_db
    environment:
      MYSQL_ROOT_PASSWORD: password
      MYSQL_DATABASE: abhs
    ports:
    - ""3306:3306""
    healthcheck:
      test: [""CMD"", ""mysqladmin"" ,""ping"", ""-h"", ""localhost""]
      timeout: 20s
      retries: 10
  migration:
    image: boxfuse/flyway:latest
    container_name: flyway_migration
    volumes:
     - ./flyway_scripts/src/main/resources/db/migration:/flyway/sql
    entrypoint: [""wait-for-it.sh"", ""mysql:3306"", ""--"", ""docker-entrypoint.sh""]      
    command: -url=jdbc:mysql://my_sql_db:3306/abhs?useUnicode=true&amp;characterEncoding=utf8&amp;useSSL=false -user=root -password=password migrate
    depends_on:
      - my_sql_db
It leads to error:
Creating flyway_migration ... error
ERROR: for flyway_migration  Cannot start service migration: OCI runtime create failed: container_linux.go:348: starting container process caused ""exec: \""wait-for-it.sh\"": executable file not found in $PATH"": unknown
ERROR: for migration  Cannot start service migration: OCI runtime create failed: container_linux.go:348: starting container process caused ""exec: \""wait-for-it.sh\"": executable file not found in $PATH"": unknown
Encountered errors while bringing up the project.
","<cava><myself><doctor><anyway><depends>, start anyway database into doctor, follow doctor compose file(doctor-compose-de.you): version: '3' services: my_sql_db: image: person:latest container_name: my_sql_db environment: mysql_root_password: password mysql_database: ah ports: - ""3306:3306"" migration: image: confuse/anyway:latest container_name: flyway_migr volumes: - ./flyway_scripts/sac/main/resources/do/migration:/anyway/sal command: -curl=job:myself://my_sql_db:3306/as?useunicode=true&amp;characterencoding=utf&amp;useful=fall -user=root -password=password migrate depends_on: - my_sql_db follow doctor-compose.you: version: '3' services: migration: image: confuse/anyway:latest container_name: flyway_migr volumes: - ./flyway_scripts/sac/main/resources/do/migration:/anyway/sal execute follow command: doctor-compose -f doctor-compose.you -f doctor-compose-de.you lead error: log see following: my_sql_db | into database flyway_migr | anyway common edit 5.1.4 boxes flyway_migr | my_sql_db | 2018-08-24t08:47:41.616694z 0 [warning] 'no_zero_date', 'no_zero_in_date' 'error_for_division_by_zero' sal mode use strict mode. berg strict mode future release. my_sql_db | 2018-08-24t08:47:41.616747z 0 [warning] 'no_auto_create_user' sal mode set. flyway_migr | error: flyway_migr | unable obtain connect database (job:myself://my_sql_db:3306/as?useunicode=true&amp;characterencoding=utf&amp;useful=false) user 'root': could connect address=(host=my_sql_db)(port=3306)(type=master) : connect refuse (connect refused) flyway_migr | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- flyway_migr | sal state : 08 flyway_migr | error code : -1 flyway_migr | message : could connect address=(host=my_sql_db)(port=3306)(type=master) : connect refuse (connect refused) my_sql_db | 2018-08-24t08:47:43.024690z 0 [warning] innodb: new log file created, isn=45790 flyway_migr | my_sql_db | 2018-08-24t08:47:43.443625z 0 [warning] innodb: great foreign key constraint system tables. my_sql_db | 2018-08-24t08:47:43.588008z 0 [warning] exist quid found, assume first time server started. genet new quid: 5dc59a4f-anna-11e8-back-0242ac130002. my_sql_db | 2018-08-24t08:47:43.760654z 0 [warning] grid table ready used. table 'myself.gtid_executed' cannot opened. my_sql_db | 2018-08-24t08:47:44.518107z 0 [warning] ca certify ca.per self signed. my_sql_db | 2018-08-24t08:47:44.925466z 1 [warning] root@localhost great empty password ! pleas consider switch --initiative-insecure option. my_sql_db | 2018-08-24t08:47:54.762213z 1 [warning] 'user' entry 'root@localhost' ignore --skin-name-resolve mode. my_sql_db | 2018-08-24t08:47:54.762517z 1 [warning] 'user' entry 'myself.session@localhost' ignore --skin-name-resolve mode. my_sql_db | 2018-08-24t08:47:54.762889z 1 [warning] 'user' entry 'myself.says@localhost' ignore --skin-name-resolve mode. my_sql_db | 2018-08-24t08:47:54.763244z 1 [warning] 'do' entry 'performance_schema myself.session@localhost' ignore --skin-name-resolve mode. my_sql_db | 2018-08-24t08:47:54.763472z 1 [warning] 'do' entry 'si myself.says@localhost' ignore --skin-name-resolve mode. my_sql_db | 2018-08-24t08:47:54.763788z 1 [warning] 'proxies_priv' entry '@ root@localhost' ignore --skin-name-resolve mode. my_sql_db | 2018-08-24t08:47:54.763928z 1 [warning] 'tables_priv' entry 'user myself.session@localhost' ignore --skin-name-resolve mode. my_sql_db | 2018-08-24t08:47:54.764128z 1 [warning] 'tables_priv' entry 'sys_config myself.says@localhost' ignore --skin-name-resolve mode. my_sql_db | database into my_sql_db | myself knit process progress... my_sql_db | 2018-08-24t08:47:58.970290z 0 [warning] 'no_zero_date', 'no_zero_in_date' 'error_for_division_by_zero' sal mode use strict mode. berg strict mode future release. my_sql_db | 2018-08-24t08:47:58.970345z 0 [warning] 'no_auto_create_user' sal mode set. my_sql_db | 2018-08-24t08:47:58.974061z 0 [note] myself (myself 5.7.22-22) start process 58 ... my_sql_db | 2018-08-24t08:47:58.999651z 0 [note] innodb: punch hole support avail my_sql_db | 2018-08-24t08:47:58.999685z 0 [note] innodb: mute rw_lock use go atom built my_sql_db | 2018-08-24t08:47:58.999689z 0 [note] innodb: use event mute my_sql_db | 2018-08-24t08:47:58.999692z 0 [note] innodb: go built __atomic_thread_fence() use memory barrier my_sql_db | 2018-08-24t08:47:58.999695z 0 [note] innodb: compress table use limb 1.2.8 my_sql_db | 2018-08-24t08:47:58.999698z 0 [note] innodb: use line native air my_sql_db | 2018-08-24t08:47:59.000153z 0 [note] innodb: number pools: 1 my_sql_db | 2018-08-24t08:47:59.000426z 0 [note] innodb: use cup crc32 instruct my_sql_db | 2018-08-24t08:47:59.002306z 0 [note] innodb: into suffer pool, total size = 128m, instant = 1, chink size = 128m my_sql_db | 2018-08-24t08:47:59.006893z 0 [note] innodb: complete into suffer pool my_sql_db | 2018-08-24t08:47:59.013219z 0 [note] innodb: myself execute user authorized, page cleaner thread priority changed. see man page setpriority(). my_sql_db | 2018-08-24t08:47:59.024242z 0 [note] innodb: crash recovery find parallel doublewrit suffer /war/limb/myself/xb_doublewrit my_sql_db | 2018-08-24t08:47:59.026263z 0 [note] innodb: highest support file format barracuda. my_sql_db | 2018-08-24t08:47:59.066469z 0 [note] innodb: great parallel doublewrit suffer /war/limb/myself/xb_doublewrite, size 3932160 bite my_sql_db | 2018-08-24t08:47:59.071752z 0 [note] innodb: great share tablespac temporary table my_sql_db | 2018-08-24t08:47:59.072052z 0 [note] innodb: set file './ibtmp1' size 12 mb. physics write file full; pleas wait ... my_sql_db | 2018-08-24t08:47:59.422155z 0 [note] innodb: file './ibtmp1' size 12 mb. my_sql_db | 2018-08-24t08:47:59.423325z 0 [note] innodb: 96 red rollback segment(s) found. 96 red rollback segment(s) active. my_sql_db | 2018-08-24t08:47:59.423376z 0 [note] innodb: 32 non-red rollback segment(s) active. my_sql_db | 2018-08-24t08:47:59.423900z 0 [note] innodb: wait pure start my_sql_db | 2018-08-24t08:47:59.474066z 0 [note] innodb: person trade (http://www.person.com) 5.7.22-22 started; log sequence number 2595255 my_sql_db | 2018-08-24t08:47:59.474647z 0 [note] plain 'federated' disabled. my_sql_db | 2018-08-24t08:47:59.499970z 0 [note] found ca.per, server-cent.per server-key.per data directory. try enable sal support use them. my_sql_db | 2018-08-24t08:47:59.500004z 0 [note] skin genet sal certify certify file present data directory. my_sql_db | 2018-08-24t08:47:59.500382z 0 [note] innodb: load suffer pool(s) /war/limb/myself/ib_buffer_pool my_sql_db | 2018-08-24t08:47:59.501263z 0 [warning] ca certify ca.per self signed. my_sql_db | 2018-08-24t08:47:59.522151z 0 [note] skin genet sa key pair key file present data directory. my_sql_db | 2018-08-24t08:47:59.531657z 0 [note] innodb: suffer pool(s) load complete 180824 8:47:59 look like anyway start database into hence could connect database see error below. fix problem? p.s. good similar question found follow piece advice: http://github.com/vishnubob/wait-for-it novice doctor understand put doctor compose file p.s.2 try put file wait-for-it.s near compose file execute: command: [""./wait-for-it.s"", ""myself:3306"", ""--"", ""-curl=job:myself://my_sql_db:3306/as?useunicode=true&amp;characterencoding=utf&amp;useful=fall -user=root -password=password migrate""] return error: invalid argument: ./wait-for-it.s p.s.3 try approach ""duplicates"" topic: version: '3' services: my_sql_db: image: person:latest container_name: my_sql_db environment: mysql_root_password: password mysql_database: ah ports: - ""3306:3306"" healthcheck: test: [""cod"", ""mysqladmin"" ,""king"", ""-h"", ""localhost""] timeout: 20 retires: 10 migration: image: confuse/anyway:latest container_name: flyway_migr volumes: - ./flyway_scripts/sac/main/resources/do/migration:/anyway/sal command: -curl=job:myself://my_sql_db:3306/as?useunicode=true&amp;characterencoding=utf&amp;useful=fall -user=root -password=password migrate depends_on: my_sql_db: condition: service_healthi see follow error: $ doctor-compose -f doctor-compose.you -f doctor-compose-de.you compose file '.\doctor-compose-de.you' invalid because: services.migration.depends_on contain invalid type, array p.s.4 approach see follow error: version: '3' services: my_sql_db: image: person:latest container_name: my_sql_db environment: mysql_root_password: password mysql_database: ah ports: - ""3306:3306"" healthcheck: test: [""cod"", ""mysqladmin"" ,""king"", ""-h"", ""localhost""] timeout: 20 retires: 10 migration: image: confuse/anyway:latest container_name: flyway_migr volumes: - ./flyway_scripts/sac/main/resources/do/migration:/anyway/sal command: doctor wait job:myself://my_sql_db:3306 -curl=job:myself://my_sql_db:3306/as?useunicode=true&amp;characterencoding=utf&amp;useful=fall -user=root -password=password migrate depends_on: - my_sql_db see follow error: flyway_migr | error: invalid argument: doctor updated wait-for-it.s content: #!/us/bin/end base # use script test given top host/port avail cmdname=$(basenam $0) echoed() { [[ $quiet -ne 1 ]]; echo ""$@"" 1&it;&amp;2; i } usage() { cat &it;&it; usage &it;&amp;2 usage: $cmdname host:port [-s] [-t timeout] [-- command arms] -h host | --host=host host in test -p port | --port=port top port test alternatively, specific host port host:port -s | --strict execute subcommand test such -q | --quiet output state message -t timeout | --timeout=timeout timeout seconds, zero timeout -- command are execute command are test finish usage exit 1 } wait_for() { [[ $timeout -it 0 ]]; echoed ""$cmdname: wait $timeout second $host:$port"" else echoed ""$cmdname: wait $host:$port without timeout"" i starts=$(dat +%s) : [[ $isbusi -e 1 ]]; no -z $host $port result=$? else (echo &it; /de/top/$host/$port) &it;/de/null 2&it;&amp;1 result=$? i [[ $result -e 0 ]]; ends=$(dat +%s) echoed ""$cmdname: $host:$port avail $((end - starts)) seconds"" break i sleep 1 done return $result } wait_for_wrapper() { # order support silent timeout: http://unit.stackexchange.com/a/57692 [[ $quiet -e 1 ]]; timeout $busytimeflag $timeout $0 --quiet --child --host=$host --port=$port --timeout=$timeout &amp; else timeout $busytimeflag $timeout $0 --child --host=$host --port=$port --timeout=$timeout &amp; i did=$! trap ""kill -in -$did"" in wait $did result=$? [[ $result -ne 0 ]]; echoed ""$cmdname: timeout occur wait $timeout second $host:$port"" i return $result } # process argument [[ $# -it 0 ]] case ""$1"" *:* ) hostport=(${1//:/ }) host=${hostport[0]} port=${hostport[1]} shift 1 ;; --child) child=1 shift 1 ;; -q | --quiet) quiet=1 shift 1 ;; -s | --strict) strict=1 shift 1 ;; -h) host=""$2"" [[ $host == """" ]]; break; i shift 2 ;; --host=*) host=""${1#*=}"" shift 1 ;; -p) port=""$2"" [[ $port == """" ]]; break; i shift 2 ;; --port=*) port=""${1#*=}"" shift 1 ;; -t) timeout=""$2"" [[ $timeout == """" ]]; break; i shift 2 ;; --timeout=*) timeout=""${1#*=}"" shift 1 ;; --) shift coli=(""$@"") break ;; --help) usage ;; *) echoed ""unknown argument: $1"" usage ;; sac done [[ ""$host"" == """" || ""$port"" == """" ]]; echoed ""error: need proved host port test."" usage i timeout=${timeout:-15} strict=${strict:-0} child=${child:-0} quiet=${quiet:-0} # check see timeout busybody? # check see timeout busybody? timeout_path=$(realpath $(which timeout)) [[ $timeout_path =~ ""busybody"" ]]; busy=1 busytimeflag=""-t"" else busy=0 busytimeflag="""" i [[ $child -it 0 ]]; wait_for result=$? exit $result else [[ $timeout -it 0 ]]; wait_for_wrapp result=$? else wait_for result=$? i i [[ $coli != """" ]]; [[ $result -ne 0 &amp;&amp; $strict -e 1 ]]; echoed ""$cmdname: strict mode, refuse execute subprocess"" exit $result i even ""${coli[@]}"" else exit $result i p.s.5 also try this: version: '3' services: my_sql_db: image: person:latest container_name: my_sql_db environment: mysql_root_password: password mysql_database: ah ports: - ""3306:3306"" healthcheck: test: [""cod"", ""mysqladmin"" ,""king"", ""-h"", ""localhost""] timeout: 20 retires: 10 migration: image: confuse/anyway:latest container_name: flyway_migr volumes: - ./flyway_scripts/sac/main/resources/do/migration:/anyway/sal entrypoint: [""wait-for-it.s"", ""myself:3306"", ""--"", ""doctor-entrypoint.s""] command: -curl=job:myself://my_sql_db:3306/as?useunicode=true&amp;characterencoding=utf&amp;useful=fall -user=root -password=password migrate depends_on: - my_sql_db lead error: great flyway_migr ... error error: flyway_migr cannot start service migration: foci until great failed: container_linux.go:348: start contain process cause ""even: \""wait-for-it.s\"": execute file found $path"": unknown error: migrate cannot start service migration: foci until great failed: container_linux.go:348: start contain process cause ""even: \""wait-for-it.s\"": execute file found $path"": unknown count error bring project."
60014874,How to use TypeScript with Sequelize,"I already have my server application written in Node, PostgreSQL, Sequelize using Fastify.
Now I would like to use TypeScript. Can anyone tell me how to begin rewriting my Server application using TypeScript.
",<node.js><postgresql><typescript><sequelize.js><fastify>,209,0,0,499,1,3,13,48,43713,0.0,61,3,20,2020-02-01 7:20,2020-02-02 2:08,2020-02-24 3:31,1.0,23.0,Intermediate,20,"<node.js><postgresql><typescript><sequelize.js><fastify>, How to use TypeScript with Sequelize, I already have my server application written in Node, PostgreSQL, Sequelize using Fastify.
Now I would like to use TypeScript. Can anyone tell me how to begin rewriting my Server application using TypeScript.
","<node.is><postgresql><typescript><sequelae.is><hastily>, use typescript sequelae, already server applied written node, postgresql, sequel use hastily. would like use typescript. anyone tell begin regret server applied use typescript."
59563423,"Cannot drop a database in Azure Data Studio, because it's currently in use","I cannot drop custom databases in Azure Data Studio, because they are currently in use.
I've been looking for various ways to close the zap database, but I cannot find any in the UI. 
Only by restarting Azure Data Studio, is the zap database in an ""Auto Closed"" state, which lets me drop it using:
drop database zap;
How do I close a connection to a database without restarting Azure Data Studio?
Open:
Auto-closed:
",<sql><sql-server><windows>,416,2,3,11770,22,94,194,48,23330,0.0,364,2,20,2020-01-02 12:33,2020-01-02 12:35,2020-01-02 12:36,0.0,0.0,Intermediate,15,"<sql><sql-server><windows>, Cannot drop a database in Azure Data Studio, because it's currently in use, I cannot drop custom databases in Azure Data Studio, because they are currently in use.
I've been looking for various ways to close the zap database, but I cannot find any in the UI. 
Only by restarting Azure Data Studio, is the zap database in an ""Auto Closed"" state, which lets me drop it using:
drop database zap;
How do I close a connection to a database without restarting Azure Data Studio?
Open:
Auto-closed:
","<sal><sal-server><windows>, cannot drop database azur data studio, current use, cannot drop custom database azur data studio, current use. i'v look various way close cap database, cannot find i. start azur data studio, cap database ""auto closed"" state, let drop using: drop database cap; close connect database without start azur data studio? open: auto-closed:"
52719378,Failed to find valid data directory. MySQL generic binary installion,"Im going to install mysql to linux server. But I dont have root access to that server. So I created two folders called mysql and mysqldata. mysql folder holds binary files. mysqldata folder holds data and the logs.
my.cnf
[mysqld]
user                    = mysql
port                    = 3306
bind-address            = localhost
basedir                 = /home/nwn/mysql/mysql-8.0
socket                  = /home/nwn/mysqldata/instA/socket/mysql.sock
datadir                 = /home/nwn/mysqldata/instA/data
tmpdir                  = /home/nwn/mysqldata/instA/tmp
secure_file_priv        = /home/nwn/mysqldata/instA/mysql-files
max_connections         = 150
# Logging
log-bin                 = /home/nwn/mysqldata/instA/logs/instA-binlog
log-error               = /home/nwn/mysqldata/instA/logs/instA-errorlog.err
slow_query_log          = 1
slow_query_log_file     = /home/nwn/mysqldata/instA/logs/instA-slowquery.log
long_query_time         = 0.5
# InnoDB
innodb_data_home_dir    = /home/nwn/mysqldata/instA/innodb/data
innodb_data_file_path   = ibdata1:50M;ibdata2:12M:autoextend:max:500M
innodb_log_group_home_dir = /home/nwn/mysqldata/instA/innodb/log
innodb_buffer_pool_size = 32M
# MyISAM
key_buffer_size         = 16M
server_id                = 1
I did all the other configurations.
when I run following command 
mysql-8.0]$ bin/mysqld --defaults-file=~/mysqldata/instA/my.cnf --initialize-insercure
I have following logs in the error_log
 cat ~/mysqldata/instA/logs/instA-errorlog.err
2018-10-09T10:39:51.127424Z 0 [Warning] [MY-010139] [Server] Changed limits: max_open_files: 1024 (requested 8160)
2018-10-09T10:39:51.127523Z 0 [Warning] [MY-010142] [Server] Changed limits: table_open_cache: 432 (requested 4000)
2018-10-09T10:39:51.383986Z 0 [Warning] [MY-010101] [Server] Insecure configuration for --secure-file-priv: Location is accessible to all OS users. Consider choosing a different directory.
2018-10-09T10:39:51.384043Z 0 [System] [MY-010116] [Server] /home/nwn/mysql/mysql-8.0/bin/mysqld (mysqld 8.0.12) starting as process 32654
2018-10-09T10:39:51.386625Z 0 [Warning] [MY-010122] [Server] One can only use the --user switch if running as root
2018-10-09T10:39:51.394675Z 1 [ERROR] [MY-011011] [Server] Failed to find valid data directory.
2018-10-09T10:39:51.394817Z 0 [ERROR] [MY-010020] [Server] Data Dictionary initialization failed.
2018-10-09T10:39:51.394831Z 0 [ERROR] [MY-010119] [Server] Aborting
2018-10-09T10:39:51.395363Z 0 [System] [MY-010910] [Server] /home/nwn/mysql/mysql-8.0/bin/mysqld: Shutdown complete (mysqld 8.0.12)  MySQL Community Server - GPL.
",<mysql><mysqladministrator>,2594,0,39,267,1,3,10,72,65137,0.0,1,6,20,2018-10-09 10:57,2020-05-25 13:45,,594.0,,Basic,14,"<mysql><mysqladministrator>, Failed to find valid data directory. MySQL generic binary installion, Im going to install mysql to linux server. But I dont have root access to that server. So I created two folders called mysql and mysqldata. mysql folder holds binary files. mysqldata folder holds data and the logs.
my.cnf
[mysqld]
user                    = mysql
port                    = 3306
bind-address            = localhost
basedir                 = /home/nwn/mysql/mysql-8.0
socket                  = /home/nwn/mysqldata/instA/socket/mysql.sock
datadir                 = /home/nwn/mysqldata/instA/data
tmpdir                  = /home/nwn/mysqldata/instA/tmp
secure_file_priv        = /home/nwn/mysqldata/instA/mysql-files
max_connections         = 150
# Logging
log-bin                 = /home/nwn/mysqldata/instA/logs/instA-binlog
log-error               = /home/nwn/mysqldata/instA/logs/instA-errorlog.err
slow_query_log          = 1
slow_query_log_file     = /home/nwn/mysqldata/instA/logs/instA-slowquery.log
long_query_time         = 0.5
# InnoDB
innodb_data_home_dir    = /home/nwn/mysqldata/instA/innodb/data
innodb_data_file_path   = ibdata1:50M;ibdata2:12M:autoextend:max:500M
innodb_log_group_home_dir = /home/nwn/mysqldata/instA/innodb/log
innodb_buffer_pool_size = 32M
# MyISAM
key_buffer_size         = 16M
server_id                = 1
I did all the other configurations.
when I run following command 
mysql-8.0]$ bin/mysqld --defaults-file=~/mysqldata/instA/my.cnf --initialize-insercure
I have following logs in the error_log
 cat ~/mysqldata/instA/logs/instA-errorlog.err
2018-10-09T10:39:51.127424Z 0 [Warning] [MY-010139] [Server] Changed limits: max_open_files: 1024 (requested 8160)
2018-10-09T10:39:51.127523Z 0 [Warning] [MY-010142] [Server] Changed limits: table_open_cache: 432 (requested 4000)
2018-10-09T10:39:51.383986Z 0 [Warning] [MY-010101] [Server] Insecure configuration for --secure-file-priv: Location is accessible to all OS users. Consider choosing a different directory.
2018-10-09T10:39:51.384043Z 0 [System] [MY-010116] [Server] /home/nwn/mysql/mysql-8.0/bin/mysqld (mysqld 8.0.12) starting as process 32654
2018-10-09T10:39:51.386625Z 0 [Warning] [MY-010122] [Server] One can only use the --user switch if running as root
2018-10-09T10:39:51.394675Z 1 [ERROR] [MY-011011] [Server] Failed to find valid data directory.
2018-10-09T10:39:51.394817Z 0 [ERROR] [MY-010020] [Server] Data Dictionary initialization failed.
2018-10-09T10:39:51.394831Z 0 [ERROR] [MY-010119] [Server] Aborting
2018-10-09T10:39:51.395363Z 0 [System] [MY-010910] [Server] /home/nwn/mysql/mysql-8.0/bin/mysqld: Shutdown complete (mysqld 8.0.12)  MySQL Community Server - GPL.
","<myself><mysqladministrator>, fail find valid data directory. myself genet binary stallion, in go instal myself line server. dont root access server. great two older call myself mysqldata. myself older hold binary files. mysqldata older hold data logs. my.cf [myself] user = myself port = 3306 bind-address = localhost based = /home/own/myself/myself-8.0 socket = /home/own/mysqldata/inst/socket/myself.sock datadir = /home/own/mysqldata/inst/data impair = /home/own/mysqldata/inst/tm secure_file_priv = /home/own/mysqldata/inst/myself-fig max_connect = 150 # log log-bin = /home/own/mysqldata/inst/logs/inst-billon log-error = /home/own/mysqldata/inst/logs/inst-errorlog.err slow_query_log = 1 slow_query_log_fil = /home/own/mysqldata/inst/logs/inst-slowquery.log long_query_tim = 0.5 # innodb innodb_data_home_dir = /home/own/mysqldata/inst/innodb/data innodb_data_file_path = ibdata1:him;ibdata2:him:autoextend:max:500m innodb_log_group_home_dir = /home/own/mysqldata/inst/innodb/log innodb_buffer_pool_s = him # myisam key_buffer_s = him server_id = 1 configuration. run follow command myself-8.0]$ bin/myself --default-file=~/mysqldata/inst/my.cf --initiative-insecure follow log error_log cat ~/mysqldata/inst/logs/inst-errorlog.err 2018-10-09t10:39:51.127424z 0 [warning] [my-010139] [server] change limits: max_open_files: 1024 (request 8160) 2018-10-09t10:39:51.127523z 0 [warning] [my-010142] [server] change limits: table_open_cache: 432 (request 4000) 2018-10-09t10:39:51.383986z 0 [warning] [my-010101] [server] insecure configur --secure-file-prim: local access os users. consider choose differ directory. 2018-10-09t10:39:51.384043z 0 [system] [my-010116] [server] /home/own/myself/myself-8.0/bin/myself (myself 8.0.12) start process 32654 2018-10-09t10:39:51.386625z 0 [warning] [my-010122] [server] one use --user switch run root 2018-10-09t10:39:51.394675z 1 [error] [my-011011] [server] fail find valid data directory. 2018-10-09t10:39:51.394817z 0 [error] [my-010020] [server] data dictionary into failed. 2018-10-09t10:39:51.394831z 0 [error] [my-010119] [server] abort 2018-10-09t10:39:51.395363z 0 [system] [my-010910] [server] /home/own/myself/myself-8.0/bin/myself: shutdown complete (myself 8.0.12) myself common server - gal."
48370045,Android Room Persistence Library - How to find entities with ids contained in list of ids?,"I am trying to do the following query in my DAO.
   @Query(""SELECT * FROM objects WHERE obj_id IN :ids"")
   List&lt;Object&gt; queryObjects(List&lt;String&gt; ids);
It gives me this compile-time error:
Error: no viable alternative at input 'SELECT * FROM objects WHERE obj_id IN :ids'
Both List&lt;String&gt; ids as well as String... ids and Sring[] ids don't work. However, since I don't know how many ids I will have in compile-time and therefore, I need a list/array and not varargs. 
How can I make this SQL query work?
",<java><android><sql><sqlite><android-room>,524,0,6,5875,6,34,62,42,10642,0.0,70,2,20,2018-01-21 18:07,2018-01-21 18:23,2018-01-21 18:23,0.0,0.0,Basic,10,"<java><android><sql><sqlite><android-room>, Android Room Persistence Library - How to find entities with ids contained in list of ids?, I am trying to do the following query in my DAO.
   @Query(""SELECT * FROM objects WHERE obj_id IN :ids"")
   List&lt;Object&gt; queryObjects(List&lt;String&gt; ids);
It gives me this compile-time error:
Error: no viable alternative at input 'SELECT * FROM objects WHERE obj_id IN :ids'
Both List&lt;String&gt; ids as well as String... ids and Sring[] ids don't work. However, since I don't know how many ids I will have in compile-time and therefore, I need a list/array and not varargs. 
How can I make this SQL query work?
","<cava><andros><sal><quite><andros-room>, andros room persist library - find entity id contain list is?, try follow query do. @query(""select * object obj_id :is"") list&it;object&it; queryobjects(list&it;string&it; is); give compile-tim error: error: viable alter input 'select * object obj_id :is' list&it;string&it; id well string... id bring[] id work. however, since know man id compile-tim therefore, need list/array varargs. make sal query work?"
51062920,pip install mysqlclient : Microsoft Visual C++ 14.0 is required,"i'm tryng to import mysqlclient library for python with pip, when i use the command
pip install mysqlclient it return an error:
Collecting mysqlclient
Using cached     https://files.pythonhosted.org/packages/ec/fd/83329b9d3e14f7344d1cb31f128e6dbba70c5975c9e57896815dbb1988ad/mysqlclient-1.3.13.tar.gz
Installing collected packages: mysqlclient
Running setup.py install for mysqlclient ... error
Complete output from command c:\users\astrina\appdata\local\programs\python\python36\python.exe -u -c ""import setuptools, tokenize;__file__='C:\\Users\\astrina\\AppData\\Local\\Temp\\pip-install-40l_x_f4\\mysqlclient\\setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\r\n', '\n');f.close();exec(compile(code, __file__, 'exec'))"" install --record C:\Users\astrina\AppData\Local\Temp\pip-record-va173t5v\install-record.txt --single-version-externally-managed --compile:
c:\users\astrina\appdata\local\programs\python\python36\lib\distutils\dist.py:261: UserWarning: Unknown distribution option: 'long_description_content_type'
  warnings.warn(msg)
running install
running build
running build_py
creating build
creating build\lib.win-amd64-3.6
copying _mysql_exceptions.py -&gt; build\lib.win-amd64-3.6
creating build\lib.win-amd64-3.6\MySQLdb
copying MySQLdb\__init__.py -&gt; build\lib.win-amd64-3.6\MySQLdb
copying MySQLdb\compat.py -&gt; build\lib.win-amd64-3.6\MySQLdb
copying MySQLdb\connections.py -&gt; build\lib.win-amd64-3.6\MySQLdb
copying MySQLdb\converters.py -&gt; build\lib.win-amd64-3.6\MySQLdb
copying MySQLdb\cursors.py -&gt; build\lib.win-amd64-3.6\MySQLdb
copying MySQLdb\release.py -&gt; build\lib.win-amd64-3.6\MySQLdb
copying MySQLdb\times.py -&gt; build\lib.win-amd64-3.6\MySQLdb
creating build\lib.win-amd64-3.6\MySQLdb\constants
copying MySQLdb\constants\__init__.py -&gt; build\lib.win-amd64-3.6\MySQLdb\constants
copying MySQLdb\constants\CLIENT.py -&gt; build\lib.win-amd64-3.6\MySQLdb\constants
copying MySQLdb\constants\CR.py -&gt; build\lib.win-amd64-3.6\MySQLdb\constants
copying MySQLdb\constants\ER.py -&gt; build\lib.win-amd64-3.6\MySQLdb\constants
copying MySQLdb\constants\FIELD_TYPE.py -&gt; build\lib.win-amd64-3.6\MySQLdb\constants
copying MySQLdb\constants\FLAG.py -&gt; build\lib.win-amd64-3.6\MySQLdb\constants
copying MySQLdb\constants\REFRESH.py -&gt; build\lib.win-amd64-3.6\MySQLdb\constants
running build_ext
building '_mysql' extension
error: Microsoft Visual C++ 14.0 is required. Get it with ""Microsoft Visual C++ Build Tools"": http://landinghub.visualstudio.com/visual-cpp-build-tools
----------------------------------------
Command ""c:\users\astrina\appdata\local\programs\python\python36\python.exe -u -c ""import setuptools, 
tokenize;__file__='C:\\Users\\astrina\\AppData\\Local\\Temp\\pip-install- 
40l_x_f4\\mysqlclient\\setup.py';f=getattr(tokenize, 'open', open) 
(__file__);code=f.read().replace('\r\n', '\n');f.close();exec(compile(code, 
__file__, 'exec'))"" install --record C:\Users\astrina\AppData\Local\Temp\pip- 
record-va173t5v\install-record.txt --single-version-externally-managed -- 
compile"" failed with error code 1 in C:\Users\astrina\AppData\Local\Temp\pip- 
install-40l_x_f4\mysqlclient\
I've already installed Microsoft Build Tools 2015 but the problem persist
",<python><mysql><pip><build-tools>,3259,2,43,420,2,5,18,37,85328,0.0,42,13,20,2018-06-27 12:33,2018-08-09 7:00,2018-08-10 6:19,43.0,44.0,Intermediate,24,"<python><mysql><pip><build-tools>, pip install mysqlclient : Microsoft Visual C++ 14.0 is required, i'm tryng to import mysqlclient library for python with pip, when i use the command
pip install mysqlclient it return an error:
Collecting mysqlclient
Using cached     https://files.pythonhosted.org/packages/ec/fd/83329b9d3e14f7344d1cb31f128e6dbba70c5975c9e57896815dbb1988ad/mysqlclient-1.3.13.tar.gz
Installing collected packages: mysqlclient
Running setup.py install for mysqlclient ... error
Complete output from command c:\users\astrina\appdata\local\programs\python\python36\python.exe -u -c ""import setuptools, tokenize;__file__='C:\\Users\\astrina\\AppData\\Local\\Temp\\pip-install-40l_x_f4\\mysqlclient\\setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\r\n', '\n');f.close();exec(compile(code, __file__, 'exec'))"" install --record C:\Users\astrina\AppData\Local\Temp\pip-record-va173t5v\install-record.txt --single-version-externally-managed --compile:
c:\users\astrina\appdata\local\programs\python\python36\lib\distutils\dist.py:261: UserWarning: Unknown distribution option: 'long_description_content_type'
  warnings.warn(msg)
running install
running build
running build_py
creating build
creating build\lib.win-amd64-3.6
copying _mysql_exceptions.py -&gt; build\lib.win-amd64-3.6
creating build\lib.win-amd64-3.6\MySQLdb
copying MySQLdb\__init__.py -&gt; build\lib.win-amd64-3.6\MySQLdb
copying MySQLdb\compat.py -&gt; build\lib.win-amd64-3.6\MySQLdb
copying MySQLdb\connections.py -&gt; build\lib.win-amd64-3.6\MySQLdb
copying MySQLdb\converters.py -&gt; build\lib.win-amd64-3.6\MySQLdb
copying MySQLdb\cursors.py -&gt; build\lib.win-amd64-3.6\MySQLdb
copying MySQLdb\release.py -&gt; build\lib.win-amd64-3.6\MySQLdb
copying MySQLdb\times.py -&gt; build\lib.win-amd64-3.6\MySQLdb
creating build\lib.win-amd64-3.6\MySQLdb\constants
copying MySQLdb\constants\__init__.py -&gt; build\lib.win-amd64-3.6\MySQLdb\constants
copying MySQLdb\constants\CLIENT.py -&gt; build\lib.win-amd64-3.6\MySQLdb\constants
copying MySQLdb\constants\CR.py -&gt; build\lib.win-amd64-3.6\MySQLdb\constants
copying MySQLdb\constants\ER.py -&gt; build\lib.win-amd64-3.6\MySQLdb\constants
copying MySQLdb\constants\FIELD_TYPE.py -&gt; build\lib.win-amd64-3.6\MySQLdb\constants
copying MySQLdb\constants\FLAG.py -&gt; build\lib.win-amd64-3.6\MySQLdb\constants
copying MySQLdb\constants\REFRESH.py -&gt; build\lib.win-amd64-3.6\MySQLdb\constants
running build_ext
building '_mysql' extension
error: Microsoft Visual C++ 14.0 is required. Get it with ""Microsoft Visual C++ Build Tools"": http://landinghub.visualstudio.com/visual-cpp-build-tools
----------------------------------------
Command ""c:\users\astrina\appdata\local\programs\python\python36\python.exe -u -c ""import setuptools, 
tokenize;__file__='C:\\Users\\astrina\\AppData\\Local\\Temp\\pip-install- 
40l_x_f4\\mysqlclient\\setup.py';f=getattr(tokenize, 'open', open) 
(__file__);code=f.read().replace('\r\n', '\n');f.close();exec(compile(code, 
__file__, 'exec'))"" install --record C:\Users\astrina\AppData\Local\Temp\pip- 
record-va173t5v\install-record.txt --single-version-externally-managed -- 
compile"" failed with error code 1 in C:\Users\astrina\AppData\Local\Temp\pip- 
install-40l_x_f4\mysqlclient\
I've already installed Microsoft Build Tools 2015 but the problem persist
","<patron><myself><pp><build-tools>, pp instal mysqlclient : microsoft visual c++ 14.0 required, i'm trying import mysqlclient library patron pp, use command pp instal mysqlclient return error: collect mysqlclient use each http://files.pythonhosted.org/packages/c/ff/83329b9d3e14f7344d1cb31f128e6dbba70c5975c9e57896815dbb1988ad/mysqlclient-1.3.13.tar.go instal collect packages: mysqlclient run set.i instal mysqlclient ... error complete output command c:\users\austrian\appdata\local\programs\patron\python36\patron.ex -u -c ""import setuptools, tokenize;__file__='c:\\users\\austrian\\appdata\\local\\hemp\\pp-install-40l_x_f4\\mysqlclient\\set.by';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\r\n', '\n');f.close();even(compile(code, __file__, 'even'))"" instal --record c:\users\austrian\appdata\local\hemp\pp-record-va173t5v\install-record.txt --single-version-externally-manage --compile: c:\users\austrian\appdata\local\programs\patron\python36\limb\distutils\list.by:261: userwarning: unknown distribute option: 'long_description_content_type' warnings.warn(mug) run instal run build run build_pi great build great build\limb.win-amd64-3.6 copy _mysql_exceptions.i -&it; build\limb.win-amd64-3.6 great build\limb.win-amd64-3.6\mysqldb copy mysqldb\__init__.i -&it; build\limb.win-amd64-3.6\mysqldb copy mysqldb\compact.i -&it; build\limb.win-amd64-3.6\mysqldb copy mysqldb\connections.i -&it; build\limb.win-amd64-3.6\mysqldb copy mysqldb\converted.i -&it; build\limb.win-amd64-3.6\mysqldb copy mysqldb\curious.i -&it; build\limb.win-amd64-3.6\mysqldb copy mysqldb\release.i -&it; build\limb.win-amd64-3.6\mysqldb copy mysqldb\times.i -&it; build\limb.win-amd64-3.6\mysqldb great build\limb.win-amd64-3.6\mysqldb\cost copy mysqldb\constant\__init__.i -&it; build\limb.win-amd64-3.6\mysqldb\cost copy mysqldb\constant\client.i -&it; build\limb.win-amd64-3.6\mysqldb\cost copy mysqldb\constant\or.i -&it; build\limb.win-amd64-3.6\mysqldb\cost copy mysqldb\constant\er.i -&it; build\limb.win-amd64-3.6\mysqldb\cost copy mysqldb\constant\field_type.i -&it; build\limb.win-amd64-3.6\mysqldb\cost copy mysqldb\constant\flag.i -&it; build\limb.win-amd64-3.6\mysqldb\cost copy mysqldb\constant\refresh.i -&it; build\limb.win-amd64-3.6\mysqldb\cost run build_ext build '_mysql' extent error: microsoft visual c++ 14.0 required. get ""microsoft visual c++ build tools"": http://landinghub.visualstudio.com/visual-pp-build-tool ---------------------------------------- command ""c:\users\austrian\appdata\local\programs\patron\python36\patron.ex -u -c ""import setuptools, tokenize;__file__='c:\\users\\austrian\\appdata\\local\\hemp\\pp-install- 40l_x_f4\\mysqlclient\\set.by';f=getattr(tokenize, 'open', open) (__file__);code=f.read().replace('\r\n', '\n');f.close();even(compile(code, __file__, 'even'))"" instal --record c:\users\austrian\appdata\local\hemp\pp- record-va173t5v\install-record.txt --single-version-externally-manage -- compile"" fail error code 1 c:\users\austrian\appdata\local\hemp\pp- install-40l_x_f4\mysqlclient\ i'v already instal microsoft build tool 2015 problem persist"
50151476,"""HostName not verified error message"" on SSL connection in postgresql","I created server.crt, server.key and root.crt files on Centos 7 and put the same onto the C:\Users\xxxx\AppData\Roaming\postgresql folder in windows as i am running the postgresql server on windows. Now on running my applications using SSL, i am getting the error as 
  ""The host name could not be verified""
Any help please.
",<postgresql><ssl><ssl-certificate>,325,0,4,355,1,3,15,64,16822,0.0,4,3,20,2018-05-03 9:26,2018-05-03 10:38,,0.0,,Advanced,45,"<postgresql><ssl><ssl-certificate>, ""HostName not verified error message"" on SSL connection in postgresql, I created server.crt, server.key and root.crt files on Centos 7 and put the same onto the C:\Users\xxxx\AppData\Roaming\postgresql folder in windows as i am running the postgresql server on windows. Now on running my applications using SSL, i am getting the error as 
  ""The host name could not be verified""
Any help please.
","<postgresql><sal><sal-certificate>, ""hostnam verify error message"" sal connect postgresql, great server.cut, server.key root.cut file cent 7 put onto c:\users\xxxi\appdata\roaming\postgresql older window run postgresql server windows. run applied use sal, get error ""the host name could verified"" help please."
56416437,Confusion about URI path to configure SQLite database,"Hi I am building a web application using Flask and Sqlite3. I had issues with connecting the database for a while and it did not work when I wrote this:
#version 1
app.config['SQLALCHEMY_DATABASE_URI'] =
'sqlite:////C:/Users/Giang/PyCharmProjects/FlaskWebBlog/FlaskWebBlog/site.db'
Python gave me operational error: can not open database because I wrote with 4 slashes after the colon. After reading sqlalchemy documentation and doing so many trials, I found out this worked:
#with 3 slashes, version 2
app.config['SQLALCHEMY_DATABASE_URI'] = 
 'sqlite:///C:/Users/Giang/PyCharmProjects/FlaskWebBlog/FlaskWebBlog/site.db'
or this with 4 slashes but no C:
#version 3
app.config['SQLALCHEMY_DATABASE_URI'] = 
'sqlite:////Users/Giang/PyCharmProjects/FlaskWebBlog/FlaskWebBlog/site.db'
I am confused because based on the documentation of connecting strings: The file specification for the SQLite database is taken as the “database” portion of the URL. Note that the format of a SQLAlchemy url is:
driver://user:pass@host/database
This means that the actual filename to be used starts with the characters to the right of the third slash. So connecting to a relative filepath looks like:
# relative path
e = create_engine('sqlite:///path/to/database.db')
An absolute path, which is denoted by starting with a slash, means you need four slashes:
# absolute path
e = create_engine('sqlite:////path/to/database.db')
SO according to this, if I use absolute path, I need 4 slashes, but when I did that with version 1, python gave me errors. And when I used 3 slashes for absolute path in version 2, it worked.
So I am really confused. Can anyone explain for me why ? I would really appreciate it. Thank you
",<python><sqlite><uri><relative-path><absolute-path>,1696,0,16,411,1,5,10,77,36603,0.0,13,2,20,2019-06-02 15:30,2019-06-02 16:53,,0.0,,Basic,4,"<python><sqlite><uri><relative-path><absolute-path>, Confusion about URI path to configure SQLite database, Hi I am building a web application using Flask and Sqlite3. I had issues with connecting the database for a while and it did not work when I wrote this:
#version 1
app.config['SQLALCHEMY_DATABASE_URI'] =
'sqlite:////C:/Users/Giang/PyCharmProjects/FlaskWebBlog/FlaskWebBlog/site.db'
Python gave me operational error: can not open database because I wrote with 4 slashes after the colon. After reading sqlalchemy documentation and doing so many trials, I found out this worked:
#with 3 slashes, version 2
app.config['SQLALCHEMY_DATABASE_URI'] = 
 'sqlite:///C:/Users/Giang/PyCharmProjects/FlaskWebBlog/FlaskWebBlog/site.db'
or this with 4 slashes but no C:
#version 3
app.config['SQLALCHEMY_DATABASE_URI'] = 
'sqlite:////Users/Giang/PyCharmProjects/FlaskWebBlog/FlaskWebBlog/site.db'
I am confused because based on the documentation of connecting strings: The file specification for the SQLite database is taken as the “database” portion of the URL. Note that the format of a SQLAlchemy url is:
driver://user:pass@host/database
This means that the actual filename to be used starts with the characters to the right of the third slash. So connecting to a relative filepath looks like:
# relative path
e = create_engine('sqlite:///path/to/database.db')
An absolute path, which is denoted by starting with a slash, means you need four slashes:
# absolute path
e = create_engine('sqlite:////path/to/database.db')
SO according to this, if I use absolute path, I need 4 slashes, but when I did that with version 1, python gave me errors. And when I used 3 slashes for absolute path in version 2, it worked.
So I am really confused. Can anyone explain for me why ? I would really appreciate it. Thank you
","<patron><quite><yuri><relative-path><absolute-path>, confuse yuri path configur quite database, hi build web applied use flask sqlite3. issue connect database work wrote this: #version 1 pp.confirm['sqlalchemy_database_uri'] = 'quite:////c:/users/giant/pycharmprojects/flaskwebblog/flaskwebblog/site.do' patron gave over error: open database wrote 4 slash colon. read sqlalchemi document man trials, found worked: #with 3 lashes, version 2 pp.confirm['sqlalchemy_database_uri'] = 'quite:///c:/users/giant/pycharmprojects/flaskwebblog/flaskwebblog/site.do' 4 slash c: #version 3 pp.confirm['sqlalchemy_database_uri'] = 'quite:////users/giant/pycharmprojects/flaskwebblog/flaskwebblog/site.do' confuse base document connect strings: file specie quite database taken “database” portion curl. note format sqlalchemi curl is: driver://user:pass@host/database mean actual filename use start character right third slash. connect red filepath look like: # red path e = create_engine('quite:///path/to/database.do') absolute path, denote start slash, mean need four lashes: # absolute path e = create_engine('quite:////path/to/database.do') accord this, use absolute path, need 4 lashes, version 1, patron gave errors. use 3 slash absolute path version 2, worked. really confused. anyone explain ? would really appreci it. thank"
51972843,Polymorphic entities in Room,"There are 3 entities in my Room DB:
Album, PhotosMediaItem and VideosMediaItem.
VideosMediaItem and PhotosMediaItem inherit from MediaItem.
MediaItem is not an entity in the DB, it's just an abstract base class.
I would like to create a query that returns all the photos and videos media items in a specific album with descending order based on their creation date.
So the query will create a list of MediaItems but with the derived types. (PhotoMediaItem or VideoMediaItem) in a polymorphic way.
Here's what I've tried:
    @Query(""SELECT * FROM PhotosMediaItem WHERE PhotosMediaItem = :albumId "" +
        ""UNION SELECT * FROM VideosMediaItem WHERE VideosMediaItem = :albumId"" +
        "" ORDER by CreationDate DESC"")
    List&lt;MediaItem&gt; getAllMediaInAlbum(int albumId);
This won't work obviously, because it tries to initiate MediaItem object, and it is not my intention. I want this query to initiate the derived class, PhotoMediaItem or VideoMediaItem
Here's how my query looked like before the migration to Room, using the regular SQLiteHelper, and it worked just fine:
public ArrayList&lt;MediaItem&gt; getMediaListByAlbumId(int palbumId)
{
    Cursor cursor = null;
    try{
        ArrayList&lt;MediaItem&gt; mediaList = new ArrayList&lt;&gt;();
        String selectQuery = ""SELECT ""+ mPhotoId +"",""+ mPhotoCreationDate +"", 0 AS mediaType, '' FROM ""+ mPhotosTableName + "" WHERE "" + this.mPhotoAlbumId + ""=""+palbumId +
                "" UNION "" +
                ""SELECT ""+ mVideoId +"",""+ mVideoCreationDate + "" ,1 AS mediaType, "" + mVideoLength + "" FROM "" + mVideosTableName + "" WHERE "" + this.mVideoAlbumId +""=""+palbumId +
                "" ORDER BY CreationDate DESC"";
        cursor = mDB.rawQuery(selectQuery, null);
        // looping through all rows and adding to list
        if (cursor.moveToFirst()){
            do {
                // MediaHolder consists of the media ID and its type
                int mediaType = cursor.getInt(2);
                MediaItem mediaItem = null;
                if (mediaType == 0) {
                    mediaItem = new PhotoMediaItem(cursor.getInt(0), null, palbumId);
                } else if (mediaType == 1) {
                    mediaItem = new VideoMediaItem(cursor.getInt(0), null, palbumId, cursor.getLong(3));
                }
                mediaList.add(mediaItem);
            }
            while (cursor.moveToNext());
        }
        return mediaList;
    }
    finally  {
        if(cursor != null){
            cursor.close();
        }
    }
}
How can I achieve the same effect using Room then?
",<android><sqlite><polymorphism><union><android-room>,2577,0,49,3190,13,53,85,52,4819,0.0,215,2,20,2018-08-22 18:13,2018-08-31 10:42,2018-08-31 10:42,9.0,9.0,Basic,10,"<android><sqlite><polymorphism><union><android-room>, Polymorphic entities in Room, There are 3 entities in my Room DB:
Album, PhotosMediaItem and VideosMediaItem.
VideosMediaItem and PhotosMediaItem inherit from MediaItem.
MediaItem is not an entity in the DB, it's just an abstract base class.
I would like to create a query that returns all the photos and videos media items in a specific album with descending order based on their creation date.
So the query will create a list of MediaItems but with the derived types. (PhotoMediaItem or VideoMediaItem) in a polymorphic way.
Here's what I've tried:
    @Query(""SELECT * FROM PhotosMediaItem WHERE PhotosMediaItem = :albumId "" +
        ""UNION SELECT * FROM VideosMediaItem WHERE VideosMediaItem = :albumId"" +
        "" ORDER by CreationDate DESC"")
    List&lt;MediaItem&gt; getAllMediaInAlbum(int albumId);
This won't work obviously, because it tries to initiate MediaItem object, and it is not my intention. I want this query to initiate the derived class, PhotoMediaItem or VideoMediaItem
Here's how my query looked like before the migration to Room, using the regular SQLiteHelper, and it worked just fine:
public ArrayList&lt;MediaItem&gt; getMediaListByAlbumId(int palbumId)
{
    Cursor cursor = null;
    try{
        ArrayList&lt;MediaItem&gt; mediaList = new ArrayList&lt;&gt;();
        String selectQuery = ""SELECT ""+ mPhotoId +"",""+ mPhotoCreationDate +"", 0 AS mediaType, '' FROM ""+ mPhotosTableName + "" WHERE "" + this.mPhotoAlbumId + ""=""+palbumId +
                "" UNION "" +
                ""SELECT ""+ mVideoId +"",""+ mVideoCreationDate + "" ,1 AS mediaType, "" + mVideoLength + "" FROM "" + mVideosTableName + "" WHERE "" + this.mVideoAlbumId +""=""+palbumId +
                "" ORDER BY CreationDate DESC"";
        cursor = mDB.rawQuery(selectQuery, null);
        // looping through all rows and adding to list
        if (cursor.moveToFirst()){
            do {
                // MediaHolder consists of the media ID and its type
                int mediaType = cursor.getInt(2);
                MediaItem mediaItem = null;
                if (mediaType == 0) {
                    mediaItem = new PhotoMediaItem(cursor.getInt(0), null, palbumId);
                } else if (mediaType == 1) {
                    mediaItem = new VideoMediaItem(cursor.getInt(0), null, palbumId, cursor.getLong(3));
                }
                mediaList.add(mediaItem);
            }
            while (cursor.moveToNext());
        }
        return mediaList;
    }
    finally  {
        if(cursor != null){
            cursor.close();
        }
    }
}
How can I achieve the same effect using Room then?
","<andros><quite><polymorphism><union><andros-room>, polymorph entity room, 3 entity room do: album, photosmediaitem videosmediaitem. videosmediaitem photosmediaitem inherit mediate. mediate entity do, abstract base class. would like great query return photo video media item specie album descend order base creation date. query great list mediate derive types. (photomediaitem videomediaitem) polymorph way. here' i'v tried: @query(""select * photosmediaitem photosmediaitem = :albumin "" + ""union select * videosmediaitem videosmediaitem = :albumin"" + "" order creation desk"") list&it;mediate&it; getallmediainalbum(in albumin); work obviously, try into mediate object, intention. want query into derive class, photomediaitem videomediaitem here' query look like migrate room, use regular sqlitehelper, work fine: public arraylist&it;mediate&it; getmedialistbyalbumid(in albumin) { curses curses = null; try{ arraylist&it;mediate&it; medialist = new arraylist&it;&it;(); string selectqueri = ""select ""+ mphotoid +"",""+ mphotocreationd +"", 0 mediate, '' ""+ mphotostablenam + "" "" + this.mphotoalbumid + ""=""+albumin + "" union "" + ""select ""+ mvideoid +"",""+ mvideocreationd + "" ,1 mediate, "" + mvideolength + "" "" + mvideostablenam + "" "" + this.mvideoalbumid +""=""+albumin + "" order creation desk""; curses = mob.rawquery(selectquery, null); // loop row ad list (curses.movetofirst()){ { // mediahold consist media id type in mediator = curses.getting(2); mediate mediate = null; (mediator == 0) { mediate = new photomediaitem(curses.getting(0), null, albumin); } else (mediator == 1) { mediate = new videomediaitem(curses.getting(0), null, albumin, curses.getting(3)); } medialist.add(mediate); } (curses.movetonext()); } return medialist; } final { if(curses != null){ curses.close(); } } } achieve effect use room then?"
49610908,Exporting a PostgreSQL query to a csv file using Python,"I need to export some rows from a table in a PostgreSQL database to a .csv file using a Python script:
#!/usr/bin/python
# -*- coding: utf-8 -*-
import sys, psycopg2
...
    conn = psycopg2.connect(""dbname=dbname user=user password=password"")
    cur = conn.cursor()
    sql = ""\copy (SELECT * FROM table WHERE month=6) TO '/mnt/results/month/table.csv' WITH CSV DELIMITER ';';""
    cur.execute(sql)
    cur.close()
...
But when I run the script I get this:
Syntax error at or near «\»
LINE 1: \copy (SELECT * FROM TABLE WHERE month=6) TO '...
Does anyone know what can be wrong or give me a tip about?
",<python><sql><postgresql><export-to-csv><psycopg2>,603,0,17,435,1,3,13,43,26778,0.0,175,4,20,2018-04-02 12:00,2018-04-02 13:43,2018-04-02 13:51,0.0,0.0,Basic,10,"<python><sql><postgresql><export-to-csv><psycopg2>, Exporting a PostgreSQL query to a csv file using Python, I need to export some rows from a table in a PostgreSQL database to a .csv file using a Python script:
#!/usr/bin/python
# -*- coding: utf-8 -*-
import sys, psycopg2
...
    conn = psycopg2.connect(""dbname=dbname user=user password=password"")
    cur = conn.cursor()
    sql = ""\copy (SELECT * FROM table WHERE month=6) TO '/mnt/results/month/table.csv' WITH CSV DELIMITER ';';""
    cur.execute(sql)
    cur.close()
...
But when I run the script I get this:
Syntax error at or near «\»
LINE 1: \copy (SELECT * FROM TABLE WHERE month=6) TO '...
Does anyone know what can be wrong or give me a tip about?
","<patron><sal><postgresql><export-to-is><psycopg2>, export postgresql query is file use patron, need export row table postgresql database .is file use patron script: #!/us/bin/patron # -*- coming: utf-8 -*- import says, psycopg2 ... corn = psycopg2.connect(""name=dream user=us password=password"") our = corn.curses() sal = ""\copy (select * table month=6) '/met/results/month/table.is' is delight ';';"" our.execute(sal) our.close() ... run script get this: santa error near «\» line 1: \copy (select * table month=6) '... anyone know wrong give tip about?"
51538158,PostgreSQL update all value to upper case for one column,"I have a table : Customer and column = [name,surname,language]
I want to update all language columns value to upper case how can I do it?
I have seen upper() method but it used on select operations. I need to update.
",<sql><postgresql>,217,0,0,1103,4,14,27,46,14405,0.0,19,1,20,2018-07-26 11:50,2018-07-26 11:59,2018-07-26 11:59,0.0,0.0,Basic,2,"<sql><postgresql>, PostgreSQL update all value to upper case for one column, I have a table : Customer and column = [name,surname,language]
I want to update all language columns value to upper case how can I do it?
I have seen upper() method but it used on select operations. I need to update.
","<sal><postgresql>, postgresql update value upper case one column, table : custom column = [name,surname,language] want update language column value upper case it? seen upper() method use select operations. need update."
59553246,What's the recommended way to do database migrations with Ktor + Exposed (Kotlin)?,"The Ktor or Exposed frameworks do not have any built-in support for database migrations. What's the recommended way to do this?
",<sql><database><kotlin><migration>,128,0,0,806,2,11,29,71,11334,0.0,14,4,20,2020-01-01 14:14,2020-01-23 21:24,,22.0,,Basic,3,"<sql><database><kotlin><migration>, What's the recommended way to do database migrations with Ktor + Exposed (Kotlin)?, The Ktor or Exposed frameworks do not have any built-in support for database migrations. What's the recommended way to do this?
","<sal><database><olin><migration>, what' recommend way database migrate to + expose (olin)?, to expose framework built-in support database migrations. what' recommend way this?"
62955635,How to restore a PostgreSQL database from dump file in dbeaver?,"In our company we have a dump of PostgreSQL database - file db.sql. It weighs 8 Gigabyte. How to restore this database in DBeaver? And we don't have another databases in DBeaver 7.0.5.
I have digged all Internet and haven't found anything how to do this without another database/
",<postgresql><dump><dbeaver>,280,0,1,381,1,2,12,37,49790,,25,2,20,2020-07-17 14:02,2020-07-17 14:57,2020-07-17 14:57,0.0,0.0,Basic,10,"<postgresql><dump><dbeaver>, How to restore a PostgreSQL database from dump file in dbeaver?, In our company we have a dump of PostgreSQL database - file db.sql. It weighs 8 Gigabyte. How to restore this database in DBeaver? And we don't have another databases in DBeaver 7.0.5.
I have digged all Internet and haven't found anything how to do this without another database/
","<postgresql><dump><beaver>, restore postgresql database dump file beaver?, company dump postgresql database - file do.sal. weigh 8 gigabyte. restore database beaver? not database beaver 7.0.5. dig internet found any without not database/"
54973536,FOR JSON PATH results in SSMS truncated to 2033 characters,"I'm concatenating strings together using ""for JSON path('')"".
I have set the Tools->Options->SQL Server->Results to Grid options to max.
I have set the Tools->Options->SQL Server->Results to Text options to max.
Executing the query in Grid mode and copying the one row/one column results, I see the return value is limited to 2033 characters.
How can I ensure the returned value isn't truncated?
",<sql-server><t-sql><ssms>,396,0,0,371,1,3,9,48,14922,0.0,8,10,20,2019-03-03 20:42,2019-03-03 20:57,2019-03-03 20:57,0.0,0.0,Basic,10,"<sql-server><t-sql><ssms>, FOR JSON PATH results in SSMS truncated to 2033 characters, I'm concatenating strings together using ""for JSON path('')"".
I have set the Tools->Options->SQL Server->Results to Grid options to max.
I have set the Tools->Options->SQL Server->Results to Text options to max.
Executing the query in Grid mode and copying the one row/one column results, I see the return value is limited to 2033 characters.
How can I ensure the returned value isn't truncated?
","<sal-server><t-sal><sums>, son path result sum truncated 2033 characters, i'm concave string together use ""for son path('')"". set tools->option->sal server->result grid option max. set tools->option->sal server->result text option max. execute query grid mode copy one row/on column results, see return value limit 2033 characters. ensue return value truncated?"
48866673,malformed array literal - PostgreSQL,"I want to copy an array from jsonb field to a PostgreSQL array column:
CREATE TABLE survey_results (
    id integer NOT NULL,
    areas text[],  
    raw jsonb DEFAULT '{}'::jsonb
);
INSERT INTO survey_results (id, raw)
    VALUES (1, '{""areas"": [""test"", ""test2""]}');
UPDATE survey_results SET areas = CAST(raw#&gt;&gt;'{areas}' AS text[]);
This returns me?
ERROR: malformed array literal: ""[""test"", ""test2""]"" Detail: ""["" must introduce explicitly-specified array dimensions.
How can I fix that?
http://sqlfiddle.com/#!17/d8122/2
",<sql><postgresql>,530,2,11,7462,15,68,135,69,98953,0.0,499,2,20,2018-02-19 12:52,2018-02-19 13:03,2018-02-19 13:03,0.0,0.0,Basic,2,"<sql><postgresql>, malformed array literal - PostgreSQL, I want to copy an array from jsonb field to a PostgreSQL array column:
CREATE TABLE survey_results (
    id integer NOT NULL,
    areas text[],  
    raw jsonb DEFAULT '{}'::jsonb
);
INSERT INTO survey_results (id, raw)
    VALUES (1, '{""areas"": [""test"", ""test2""]}');
UPDATE survey_results SET areas = CAST(raw#&gt;&gt;'{areas}' AS text[]);
This returns me?
ERROR: malformed array literal: ""[""test"", ""test2""]"" Detail: ""["" must introduce explicitly-specified array dimensions.
How can I fix that?
http://sqlfiddle.com/#!17/d8122/2
","<sal><postgresql>, malform array later - postgresql, want copy array son field postgresql array column: great table survey_result ( id inter null, area text[], raw son default '{}'::son ); insert survey_result (id, raw) value (1, '{""areas"": [""test"", ""test""]}'); update survey_result set area = cast(raw#&it;&it;'{areas}' text[]); return me? error: malform array literal: ""[""test"", ""test""]"" detail: ""["" must introduce explicitly-specific array dimensions. fix that? http://sqlfiddle.com/#!17/d8122/2"
49596061,TypeORM updating entity/table,"This is my User entity:
@PrimaryGeneratedColumn()
userId: number;
@Column({type:""varchar"", length:""300""})
userName: string;
@OneToOne(type =&gt; UserProfile, {cascadeAll:true})
@JoinColumn()
userProfile: UserProfile;
@OneToOne(type =&gt; UserCredential, {cascadeAll:true, eager:true})
@JoinColumn()
userCredential: UserCredential;
@OneToOne(type =&gt; BusinessUnit, {cascadeAll:true})
@JoinColumn()
businessUnit: BusinessUnit;
@ManyToMany(type =&gt; ProductCategory)
@JoinTable()
productCategory: ProductCategory[];
and this is my new data which i want to update:
User {
  userName: 'qweret@gmail.com',
  userProfile: 
   UserProfile {
     firstName: 'dcds',
     lastName: 'Faiz',
     mobile: '42423423',
     addressLine1: 'Delhi',
     addressLine2: 'Delhi',
     city: '-',
     country: '-',
     zipCode: '234243',
     homeTelephone: '-',
     dayOfBirth: 0,
     monthOfBirth: 0,
     yearOfBirth: 0 },
  userCredential: UserCredential { credential: 'abcd@123' } }
i'm searching user by its userId.
return await getManager()
               .createQueryBuilder(User, ""user"")
               .where(""user.userId = :id"", {id})
               .getOne();
the above query gives me result:
User {
  createdDate: 2018-03-29T06:45:16.322Z,
  updatedDate: 2018-04-01T06:28:24.171Z,
  userId: 1,
  userName: 'qweret@gmail.com' }
i want to update my user table and its related tables
manager.save(user)
will insert a new row in the table instead of updating the existing the row. Is there a way to update the whole user table and its related table without updating every column manually?
i don't want to perform this task like this:
let user = await userRepositiory.findOneById(1);
user.userName = ""Me, my friends and polar bears"";
await userRepository.save(user);
let userProfile = await userProfileRepository.findOneById(1);
 userProfile.firstName = """";
 userProfile.lastName = """";
    ....// etc
 await userRepository.save(userProfile);
 // and so on update other tables.
",<mysql><node.js><database><typeorm>,1972,0,59,211,1,2,4,39,48282,0.0,0,3,20,2018-04-01 8:02,2019-09-03 15:48,,520.0,,Basic,11,"<mysql><node.js><database><typeorm>, TypeORM updating entity/table, This is my User entity:
@PrimaryGeneratedColumn()
userId: number;
@Column({type:""varchar"", length:""300""})
userName: string;
@OneToOne(type =&gt; UserProfile, {cascadeAll:true})
@JoinColumn()
userProfile: UserProfile;
@OneToOne(type =&gt; UserCredential, {cascadeAll:true, eager:true})
@JoinColumn()
userCredential: UserCredential;
@OneToOne(type =&gt; BusinessUnit, {cascadeAll:true})
@JoinColumn()
businessUnit: BusinessUnit;
@ManyToMany(type =&gt; ProductCategory)
@JoinTable()
productCategory: ProductCategory[];
and this is my new data which i want to update:
User {
  userName: 'qweret@gmail.com',
  userProfile: 
   UserProfile {
     firstName: 'dcds',
     lastName: 'Faiz',
     mobile: '42423423',
     addressLine1: 'Delhi',
     addressLine2: 'Delhi',
     city: '-',
     country: '-',
     zipCode: '234243',
     homeTelephone: '-',
     dayOfBirth: 0,
     monthOfBirth: 0,
     yearOfBirth: 0 },
  userCredential: UserCredential { credential: 'abcd@123' } }
i'm searching user by its userId.
return await getManager()
               .createQueryBuilder(User, ""user"")
               .where(""user.userId = :id"", {id})
               .getOne();
the above query gives me result:
User {
  createdDate: 2018-03-29T06:45:16.322Z,
  updatedDate: 2018-04-01T06:28:24.171Z,
  userId: 1,
  userName: 'qweret@gmail.com' }
i want to update my user table and its related tables
manager.save(user)
will insert a new row in the table instead of updating the existing the row. Is there a way to update the whole user table and its related table without updating every column manually?
i don't want to perform this task like this:
let user = await userRepositiory.findOneById(1);
user.userName = ""Me, my friends and polar bears"";
await userRepository.save(user);
let userProfile = await userProfileRepository.findOneById(1);
 userProfile.firstName = """";
 userProfile.lastName = """";
    ....// etc
 await userRepository.save(userProfile);
 // and so on update other tables.
","<myself><node.is><database><typeorm>, typeorm update entity/table, user entity: @primarygeneratedcolumn() used: number; @column({type:""varchar"", length:""300""}) surname: string; @onetoone(type =&it; userprofile, {cascadeall:true}) @joincolumn() userprofile: userprofile; @onetoone(type =&it; usercredential, {cascadeall:true, eager:true}) @joincolumn() usercredential: usercredential; @onetoone(type =&it; businessunit, {cascadeall:true}) @joincolumn() businessunit: businessunit; @manytomany(type =&it; productcategory) @jointable() productcategory: productcategory[]; new data want update: user { surname: 'were@email.com', userprofile: userprofil { firstname: 'did', lastname: 'fair', mobile: '42423423', addressline1: 'delhi', addressline2: 'delhi', city: '-', country: '-', zipcode: '234243', hometelephone: '-', dayofbirth: 0, monthofbirth: 0, yearofbirth: 0 }, usercredential: usercredenti { credentials: 'abc@123' } } i'm search user used. return await getmanager() .createquerybuilder(user, ""user"") .where(""user.used = :id"", {id}) .gone(); query give result: user { createddate: 2018-03-29t06:45:16.322z, updateddate: 2018-04-01t06:28:24.171z, used: 1, surname: 'were@email.com' } want update user table relate table manager.save(user) insert new row table instead update exist row. way update whole user table relate table without update every column mentally? want perform task like this: let user = await userrepositiory.findonebyid(1); user.usernam = ""me, friend polar bears""; await userrepository.save(user); let userprofil = await userprofilerepository.findonebyid(1); userprofile.firstnam = """"; userprofile.lastnam = """"; ....// etc await userrepository.save(userprofile); // update tables."
56301656,Disable Lazy Loading in Entity Framework Core,"There are plenty of posts about how to disable lazy loading in Entity Framework, but the same techniques don't work in EF Core. I found the LazyLoadingEnabled property in the change tracker, but this doesn't seem to work at all.
Everything points to this in EF:
this.Configuration.LazyLoadingEnabled = false;
But, the Configuration property is missing in EF Core.
Here is an example of what I am talking about:
public class TestContext : DbContext
{
    public DbSet&lt;Person&gt; People { get; set; }
    public DbSet&lt;Address&gt; Addresses { get; set; }
    public TestContext()
    {
        this.ChangeTracker.LazyLoadingEnabled = false;
    }
    protected override void OnConfiguring(DbContextOptionsBuilder optionsBuilder)
    {            
        var connection = new SqliteConnection($""Data Source=Test.db"");
        connection.Open();
        var command = connection.CreateCommand();
        command.CommandText = $""PRAGMA foreign_keys = ON;"";
        command.ExecuteNonQuery();
        optionsBuilder.UseSqlite(connection);
        optionsBuilder.UseLazyLoadingProxies(false);
        base.OnConfiguring(optionsBuilder);
    }
    private static void Main(string[] args)
    {
        Console.WriteLine(""Hello World!"");
        using (var context = new TestContext())
        {
            context.Database.EnsureCreated();
            var personKey = Guid.NewGuid().ToString();
            var addressKey = Guid.NewGuid().ToString();
            context.People.Add(new Entities.Person { PersonKey = personKey, BillingAddress = new Entities.Address { AddressKey = addressKey } });
            context.SaveChanges();
        }
        using (var context = new TestContext())
        {
            var people = context.People.ToList();
            foreach (var person in people)
            {
                if (person.BillingAddress == null) throw new Exception(""The billing address wasn't loaded"");
            }
        }
    }
}
The above throws an exception because BillingAddress is not getting loaded even though I turned lazy loading off.
I suspect this is a bug, but please tell me it isn't. I logged it here: https://github.com/aspnet/EntityFrameworkCore/issues/15802
You can download the sample here:
https://www.dropbox.com/s/mimvgvcmibr7em2/EFSQLiteTest.7z?dl=0
",<c#><sqlite><.net-core><entity-framework-core>,2289,4,56,7010,5,51,106,51,31973,0.0,263,1,20,2019-05-25 4:17,2019-11-27 15:12,,186.0,,Basic,11,"<c#><sqlite><.net-core><entity-framework-core>, Disable Lazy Loading in Entity Framework Core, There are plenty of posts about how to disable lazy loading in Entity Framework, but the same techniques don't work in EF Core. I found the LazyLoadingEnabled property in the change tracker, but this doesn't seem to work at all.
Everything points to this in EF:
this.Configuration.LazyLoadingEnabled = false;
But, the Configuration property is missing in EF Core.
Here is an example of what I am talking about:
public class TestContext : DbContext
{
    public DbSet&lt;Person&gt; People { get; set; }
    public DbSet&lt;Address&gt; Addresses { get; set; }
    public TestContext()
    {
        this.ChangeTracker.LazyLoadingEnabled = false;
    }
    protected override void OnConfiguring(DbContextOptionsBuilder optionsBuilder)
    {            
        var connection = new SqliteConnection($""Data Source=Test.db"");
        connection.Open();
        var command = connection.CreateCommand();
        command.CommandText = $""PRAGMA foreign_keys = ON;"";
        command.ExecuteNonQuery();
        optionsBuilder.UseSqlite(connection);
        optionsBuilder.UseLazyLoadingProxies(false);
        base.OnConfiguring(optionsBuilder);
    }
    private static void Main(string[] args)
    {
        Console.WriteLine(""Hello World!"");
        using (var context = new TestContext())
        {
            context.Database.EnsureCreated();
            var personKey = Guid.NewGuid().ToString();
            var addressKey = Guid.NewGuid().ToString();
            context.People.Add(new Entities.Person { PersonKey = personKey, BillingAddress = new Entities.Address { AddressKey = addressKey } });
            context.SaveChanges();
        }
        using (var context = new TestContext())
        {
            var people = context.People.ToList();
            foreach (var person in people)
            {
                if (person.BillingAddress == null) throw new Exception(""The billing address wasn't loaded"");
            }
        }
    }
}
The above throws an exception because BillingAddress is not getting loaded even though I turned lazy loading off.
I suspect this is a bug, but please tell me it isn't. I logged it here: https://github.com/aspnet/EntityFrameworkCore/issues/15802
You can download the sample here:
https://www.dropbox.com/s/mimvgvcmibr7em2/EFSQLiteTest.7z?dl=0
","<c#><quite><.net-core><entity-framework-core>, distal lazy load entity framework core, plenty post distal lazy load entity framework, technique work of core. found lazyloadingen property change trace, seem work all. every point of: this.configuration.lazyloadingen = false; but, configur property miss of core. example talk about: public class testcontext : context { public set&it;person&it; people { get; set; } public set&it;address&it; address { get; set; } public testcontext() { this.changetracker.lazyloadingen = false; } protect overdid void onconfiguring(dbcontextoptionsbuild optionsbuilder) { war connect = new sqliteconnection($""data source=test.do""); connection.open(); war command = connection.createcommand(); command.commandtext = $""trauma foreign_key = on;""; command.executenonquery(); optionsbuilder.usesqlite(connection); optionsbuilder.uselazyloadingproxies(false); base.onconfiguring(optionsbuilder); } privat static void main(string[] arms) { console.writeline(""hello world!""); use (war context = new testcontext()) { context.database.ensurecreated(); war personnel = guide.newguid().string(); war addressed = guide.newguid().string(); context.people.add(new entitles.person { personnel = personnel, billingaddress = new entitles.address { addressed = addressed } }); context.savechanges(); } use (war context = new testcontext()) { war people = context.people.moist(); french (war person people) { (person.billingaddress == null) throw new exception(""th bill address loaded""); } } } } throw except billingaddress get load even though turn lazy load off. suspect bug, pleas tell isn't. log here: http://github.com/spent/entityframeworkcore/issues/15802 download sample here: http://www.dropbox.com/s/mimvgvcmibr7em2/efsqlitetest.z?do=0"
55701029,How to insert value to identity column in PostgreSQL 11.1,"I would like to insert my own value to identity column.
Table Schema:
CREATE TABLE public.userdetail (
    userdetailid int4 NOT NULL GENERATED ALWAYS AS IDENTITY,
    username varchar(30) NOT NULL,
    ""password"" varchar(1000) NOT NULL,
    CONSTRAINT pk_userdetail PRIMARY KEY (userdetailid)
);
Insert Query:
INSERT INTO UserDetail (UserDetailId,UserName, Password) 
  VALUES(1,'admin', 'password');
Here insert query throwing below error: 
  cannot insert into column ""userdetailid""
Is there any command exists to force insert to identity column like MS SQL :
 SET IDENTITY_INSERT UserDetail ON
Let me know if you have any solution.
",<database><postgresql>,636,0,9,1089,3,12,24,68,33643,0.0,20,1,20,2019-04-16 5:20,2019-04-16 5:27,2019-04-16 5:27,0.0,0.0,Basic,10,"<database><postgresql>, How to insert value to identity column in PostgreSQL 11.1, I would like to insert my own value to identity column.
Table Schema:
CREATE TABLE public.userdetail (
    userdetailid int4 NOT NULL GENERATED ALWAYS AS IDENTITY,
    username varchar(30) NOT NULL,
    ""password"" varchar(1000) NOT NULL,
    CONSTRAINT pk_userdetail PRIMARY KEY (userdetailid)
);
Insert Query:
INSERT INTO UserDetail (UserDetailId,UserName, Password) 
  VALUES(1,'admin', 'password');
Here insert query throwing below error: 
  cannot insert into column ""userdetailid""
Is there any command exists to force insert to identity column like MS SQL :
 SET IDENTITY_INSERT UserDetail ON
Let me know if you have any solution.
","<database><postgresql>, insert value went column postgresql 11.1, would like insert value went column. table scheme: great table public.userdetail ( userdetailid into null genet away identity, usernam varchar(30) null, ""password"" varchar(1000) null, constraint pk_userdetail primary key (userdetailid) ); insert query: insert userdetail (userdetailid,surname, password) values(1,'admit', 'password'); insert query throw error: cannot insert column ""userdetailid"" command exist for insert went column like ms sal : set identity_insert userdetail let know solution."
50983177,How to connect to PostgreSQL using docker-compose?,"Want to use docker-compose to run api application and postgresql database together. 
docker-compose file:
version: '3'
volumes:
  database_data:
    driver: local
services:
  db:
    image: postgres:latest
    volumes:
      - database_data:/var/lib/postgresql/data
  api:
    build: ./api
    expose:
      - 8080
    ports:
      - 8080:8080
    volumes:
      - ./api:/usr/src/app/
    links:
      - db
    environment:
      - PGHOST=db
      - PGDATABASE=postgres
      - PGUSER=postgres
Api main.go file:
func main() {
    db, err = gorm.Open(""postgres"", ""host=db port=5432 user=postgres dbname=postgres"")
  // ...
}
When run the services, got message from log:
api_1     | [GIN] 2018/06/22 - 07:31:10 | 404 |      1.4404ms |      172.20.0.1 | GET      /posts
api_1     |
api_1     | (sql: database is closed)
api_1     | [2018-06-22 07:31:10]
api_1     |
api_1     | (sql: database is closed)
api_1     | [2018-06-22 07:31:10]
api_1     | [GIN] 2018/06/22 - 07:32:14 | 403 |        15.6µs |      172.20.0.1 | GET      /posts
db_1      | 2018-06-22 07:34:27.296 UTC [81] FATAL:  role ""root"" does not exist
db_1      | 2018-06-22 07:34:36.897 UTC [90] FATAL:  role ""root"" does not exist
Does this way not good? host=db in the connection string? Since db is the docker compose service name.
Add
It can work:
https://docs.docker.com/samples/library/postgres/#-or-via-psql
",<postgresql><docker><go><service><docker-compose>,1376,2,45,633,3,13,26,74,52641,0.0,12,1,20,2018-06-22 7:50,2018-09-27 19:19,,97.0,,Basic,10,"<postgresql><docker><go><service><docker-compose>, How to connect to PostgreSQL using docker-compose?, Want to use docker-compose to run api application and postgresql database together. 
docker-compose file:
version: '3'
volumes:
  database_data:
    driver: local
services:
  db:
    image: postgres:latest
    volumes:
      - database_data:/var/lib/postgresql/data
  api:
    build: ./api
    expose:
      - 8080
    ports:
      - 8080:8080
    volumes:
      - ./api:/usr/src/app/
    links:
      - db
    environment:
      - PGHOST=db
      - PGDATABASE=postgres
      - PGUSER=postgres
Api main.go file:
func main() {
    db, err = gorm.Open(""postgres"", ""host=db port=5432 user=postgres dbname=postgres"")
  // ...
}
When run the services, got message from log:
api_1     | [GIN] 2018/06/22 - 07:31:10 | 404 |      1.4404ms |      172.20.0.1 | GET      /posts
api_1     |
api_1     | (sql: database is closed)
api_1     | [2018-06-22 07:31:10]
api_1     |
api_1     | (sql: database is closed)
api_1     | [2018-06-22 07:31:10]
api_1     | [GIN] 2018/06/22 - 07:32:14 | 403 |        15.6µs |      172.20.0.1 | GET      /posts
db_1      | 2018-06-22 07:34:27.296 UTC [81] FATAL:  role ""root"" does not exist
db_1      | 2018-06-22 07:34:36.897 UTC [90] FATAL:  role ""root"" does not exist
Does this way not good? host=db in the connection string? Since db is the docker compose service name.
Add
It can work:
https://docs.docker.com/samples/library/postgres/#-or-via-psql
","<postgresql><doctor><go><service><doctor-compose>, connect postgresql use doctor-compose?, want use doctor-compose run apt applied postgresql database together. doctor-compose file: version: '3' volumes: database_data: driver: local services: do: image: postures:latest volumes: - database_data:/war/limb/postgresql/data apt: build: ./apt expose: - 8080 ports: - 8080:8080 volumes: - ./apt:/us/sac/pp/ links: - do environment: - ghost=do - database=poster - paused=poster apt main.go file: fun main() { do, err = form.open(""postures"", ""host=do port=5432 user=poster name=postures"") // ... } run services, got message log: api_1 | [gin] 2018/06/22 - 07:31:10 | 404 | 1.4404m | 172.20.0.1 | get /post api_1 | api_1 | (sal: database closed) api_1 | [2018-06-22 07:31:10] api_1 | api_1 | (sal: database closed) api_1 | [2018-06-22 07:31:10] api_1 | [gin] 2018/06/22 - 07:32:14 | 403 | 15.of | 172.20.0.1 | get /post db_1 | 2018-06-22 07:34:27.296 etc [81] fatal: role ""root"" exist db_1 | 2018-06-22 07:34:36.897 etc [90] fatal: role ""root"" exist way good? host=do connect string? since do doctor compose service name. add work: http://docs.doctor.com/samples/library/postures/#-or-via-pool"
50019457,Why does Spark Planner prefer sort merge join over shuffled hash join?,"Why does Spark Planner in Spark 2.3 prefer a sort merge join over a shuffled hash join? In other words, why is spark.sql.join.preferSortMergeJoin configuration property internal and turned on by default? What's wrong with a shuffled hash join? Is this specific to Spark that it does computations in distributed fashion or something else more inherent in the join algorithm?
You can find the property used in the JoinSelection execution planning strategy here and here that looks like:
case ... if !conf.preferSortMergeJoin &amp;&amp; ... =&gt;
  Seq(joins.ShuffledHashJoinExec(...))
",<apache-spark><join><apache-spark-sql>,583,3,4,73211,27,243,423,67,10622,0.0,5053,1,20,2018-04-25 10:04,2018-04-25 12:03,2018-04-25 12:03,0.0,0.0,Intermediate,23,"<apache-spark><join><apache-spark-sql>, Why does Spark Planner prefer sort merge join over shuffled hash join?, Why does Spark Planner in Spark 2.3 prefer a sort merge join over a shuffled hash join? In other words, why is spark.sql.join.preferSortMergeJoin configuration property internal and turned on by default? What's wrong with a shuffled hash join? Is this specific to Spark that it does computations in distributed fashion or something else more inherent in the join algorithm?
You can find the property used in the JoinSelection execution planning strategy here and here that looks like:
case ... if !conf.preferSortMergeJoin &amp;&amp; ... =&gt;
  Seq(joins.ShuffledHashJoinExec(...))
","<apache-spark><join><apache-spark-sal>, spark planner prefer sort berg join stuff has join?, spark planner spark 2.3 prefer sort berg join stuff has join? words, spark.sal.join.prefersortmergejoin configur property inter turn default? what' wrong stuff has join? specie spark compute distribute fashion cometh else inner join algorithm? find property use joinselect execute plan strategic look like: case ... !cone.prefersortmergejoin &amp;&amp; ... =&it; see(joins.shuffledhashjoinexec(...))"
48522640,Failure to connect to Docker Postgresql instance from Python,"I am using Docker to ""containerize"" a PostgreSQL deployment. I can spin up the container and connect to PostgreSQL via the command line as shown below:
minime2@CEBERUS:~/Projects/skunkworks$ docker ps
CONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS               NAMES
dc176901052a        df:pg               ""docker-entrypoint...""   About an hour ago   Up About an hour    5432/tcp            vigilant_agnesi
minime2@CEBERUS:~/Projects/skunkworks$ CONTAINER_ID=dc176901052a
minime2@CEBERUS:~/Projects/skunkworks$ IP=$(docker inspect -f '{{.NetworkSettings.Networks.bridge.IPAddress}}' $CONTAINER_ID)
minime2@CEBERUS:~/Projects/skunkworks$ echo $IP
172.17.0.2
minime2@CEBERUS:~/Projects/skunkworks$ docker exec -it vigilant_agnesi psql -U postgres -W cookiebox
Passwod for user postgres:
psql (9.6.5)
Type ""help"" for help
cookiebox#
Now attempting connection with Python:
Python 3.5.2 (default, Sep 14 2017, 22:51:06) 
[GCC 5.4.0 20160609] on linux
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
&gt;&gt;&gt; import psycopg2
&gt;&gt;&gt; conn = psycopg2.connect(""dbname='cookiebox' user='postgres' host='172.17.0.2' password='nunyabiznes'"")                                     Traceback (most recent call last):
  File ""&lt;stdin&gt;"", line 1, in &lt;module&gt;
  File ""/home/minime2/Projects/skunkworks/archivers/env/lib/python3.5/site-packages/psycopg2/__init__.py"", line 130, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: could not connect to server: Connection refused
        Is the server running on host ""172.17.0.2"" and accepting
        TCP/IP connections on port 5432?
&gt;&gt;&gt; 
Can anyone explain why I can't connect to PostgreSQL using Python - even though I'm using the same arguments/parameters that enable a successful connection at the command line (using docker exec?).
[[Additional Info]]
As suggested by @Itvhillo, I tried to use a desktop application to connect to the PG service. I run the docker service using the following command:
docker run -i -p 5432:5432 --name $CONTAINER_NAME $DOCKER_IMAGE
I am using Db Visualizer to connect to the database, and I have set the hostname to 'localhost'. I can successfully ping the port, but still get an error message when I try to connect to the database (possible permissions related error):
An error occurred while establishing the connection:
Long Message:
The connection attempt failed.
Details:
   Type: org.postgresql.util.PSQLException
   SQL State: 08001
Incidentally, this is the tail end of the output for the PG service instance:
PostgreSQL init process complete; ready for start up.
LOG:  could not bind IPv6 socket: Cannot assign requested address
HINT:  Is another postmaster already running on port 5432? If not, wait a few seconds and retry.
LOG:  database system was shut down at 2018-01-30 16:21:59 UTC
LOG:  MultiXact member wraparound protections are now enabled
LOG:  database system is ready to accept connections
LOG:  autovacuum launcher started
[[Additional Info2]]
Here is the tail end of my Dockerfile:
# modified target locations (checked by login onto Docker container)
# show hba_file;
# show config_file;
#################################################################################
# From here: https://docs.docker.com/engine/examples/postgresql_service/
# Adjust PostgreSQL configuration so that remote connections to the
# database are possible.
RUN echo ""host all  all    0.0.0.0/0  md5"" &gt;&gt; /var/lib/postgresql/data/pg_hba.conf
# And add ``listen_addresses`` to ``/var/lib/postgresql/data/postgresql.conf``
RUN echo ""listen_addresses='*'"" &gt;&gt; /var/lib/postgresql/data/postgresql.conf
#################################################################################
EXPOSE 5432
# Add VOLUMEs to allow backup of config, logs and databases
VOLUME  [""/etc/postgresql"", ""/var/log/postgresql"", ""/var/lib/postgresql"", ""/usr/lib/postgresql/""]
",<python><postgresql><docker><psycopg2>,4008,2,67,65877,82,222,348,46,13011,0.0,948,5,20,2018-01-30 13:29,2018-02-01 14:42,2018-02-06 17:45,2.0,7.0,Advanced,38,"<python><postgresql><docker><psycopg2>, Failure to connect to Docker Postgresql instance from Python, I am using Docker to ""containerize"" a PostgreSQL deployment. I can spin up the container and connect to PostgreSQL via the command line as shown below:
minime2@CEBERUS:~/Projects/skunkworks$ docker ps
CONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS               NAMES
dc176901052a        df:pg               ""docker-entrypoint...""   About an hour ago   Up About an hour    5432/tcp            vigilant_agnesi
minime2@CEBERUS:~/Projects/skunkworks$ CONTAINER_ID=dc176901052a
minime2@CEBERUS:~/Projects/skunkworks$ IP=$(docker inspect -f '{{.NetworkSettings.Networks.bridge.IPAddress}}' $CONTAINER_ID)
minime2@CEBERUS:~/Projects/skunkworks$ echo $IP
172.17.0.2
minime2@CEBERUS:~/Projects/skunkworks$ docker exec -it vigilant_agnesi psql -U postgres -W cookiebox
Passwod for user postgres:
psql (9.6.5)
Type ""help"" for help
cookiebox#
Now attempting connection with Python:
Python 3.5.2 (default, Sep 14 2017, 22:51:06) 
[GCC 5.4.0 20160609] on linux
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
&gt;&gt;&gt; import psycopg2
&gt;&gt;&gt; conn = psycopg2.connect(""dbname='cookiebox' user='postgres' host='172.17.0.2' password='nunyabiznes'"")                                     Traceback (most recent call last):
  File ""&lt;stdin&gt;"", line 1, in &lt;module&gt;
  File ""/home/minime2/Projects/skunkworks/archivers/env/lib/python3.5/site-packages/psycopg2/__init__.py"", line 130, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: could not connect to server: Connection refused
        Is the server running on host ""172.17.0.2"" and accepting
        TCP/IP connections on port 5432?
&gt;&gt;&gt; 
Can anyone explain why I can't connect to PostgreSQL using Python - even though I'm using the same arguments/parameters that enable a successful connection at the command line (using docker exec?).
[[Additional Info]]
As suggested by @Itvhillo, I tried to use a desktop application to connect to the PG service. I run the docker service using the following command:
docker run -i -p 5432:5432 --name $CONTAINER_NAME $DOCKER_IMAGE
I am using Db Visualizer to connect to the database, and I have set the hostname to 'localhost'. I can successfully ping the port, but still get an error message when I try to connect to the database (possible permissions related error):
An error occurred while establishing the connection:
Long Message:
The connection attempt failed.
Details:
   Type: org.postgresql.util.PSQLException
   SQL State: 08001
Incidentally, this is the tail end of the output for the PG service instance:
PostgreSQL init process complete; ready for start up.
LOG:  could not bind IPv6 socket: Cannot assign requested address
HINT:  Is another postmaster already running on port 5432? If not, wait a few seconds and retry.
LOG:  database system was shut down at 2018-01-30 16:21:59 UTC
LOG:  MultiXact member wraparound protections are now enabled
LOG:  database system is ready to accept connections
LOG:  autovacuum launcher started
[[Additional Info2]]
Here is the tail end of my Dockerfile:
# modified target locations (checked by login onto Docker container)
# show hba_file;
# show config_file;
#################################################################################
# From here: https://docs.docker.com/engine/examples/postgresql_service/
# Adjust PostgreSQL configuration so that remote connections to the
# database are possible.
RUN echo ""host all  all    0.0.0.0/0  md5"" &gt;&gt; /var/lib/postgresql/data/pg_hba.conf
# And add ``listen_addresses`` to ``/var/lib/postgresql/data/postgresql.conf``
RUN echo ""listen_addresses='*'"" &gt;&gt; /var/lib/postgresql/data/postgresql.conf
#################################################################################
EXPOSE 5432
# Add VOLUMEs to allow backup of config, logs and databases
VOLUME  [""/etc/postgresql"", ""/var/log/postgresql"", ""/var/lib/postgresql"", ""/usr/lib/postgresql/""]
","<patron><postgresql><doctor><psycopg2>, failure connect doctor postgresql instant patron, use doctor ""containerize"" postgresql employment. spin contain connect postgresql via command line shown below: minimum@ceberus:~/projects/skunkworks$ doctor is contain id image command great state port name dc176901052a of:pg ""doctor-entrypoint..."" hour ago hour 5432/top vigilant_agnesi minimum@ceberus:~/projects/skunkworks$ container_id=dc176901052a minimum@ceberus:~/projects/skunkworks$ in=$(dock inspect -f '{{.networksettings.network.bridge.address}}' $container_id) minimum@ceberus:~/projects/skunkworks$ echo $in 172.17.0.2 minimum@ceberus:~/projects/skunkworks$ doctor even -it vigilant_agnesi pool -u poster -w cookiebox password user postures: pool (9.6.5) type ""help"" help cookiebox# attempt connect patron: patron 3.5.2 (default, see 14 2017, 22:51:06) [go 5.4.0 20160609] line type ""help"", ""copyright"", ""credits"" ""license"" information. &it;&it;&it; import psycopg2 &it;&it;&it; corn = psycopg2.connect(""name='cookiebox' user='postures' host='172.17.0.2' password='nunyabiznes'"") traceback (most recent call last): file ""&it;stain&it;"", line 1, &it;module&it; file ""/home/minimum/projects/skunkworks/archives/end/limb/python3.5/site-packages/psycopg2/__init__.by"", line 130, connect corn = connect(don, connection_factory=connection_factory, **kwasync) psycopg2.operationalerror: could connect server: connect refuse server run host ""172.17.0.2"" accept top/in connect port 5432? &it;&it;&it; anyone explain can't connect postgresql use patron - even though i'm use arguments/parapet enable success connect command line (use doctor even?). [[admit into]] suggest @itvhillo, try use desktop applied connect pg service. run doctor service use follow command: doctor run -i -p 5432:5432 --name $container_nam $docker_imag use do visual connect database, set hostnam 'localhost'. success king port, still get error message try connect database (possible permits relate error): error occur establish connection: long message: connect attempt failed. details: type: org.postgresql.until.psqlexcept sal state: 08001 incidentally, tail end output pg service instance: postgresql knit process complete; ready start up. log: could bind iv socket: cannot assign request address hint: not postmaster already run port 5432? not, wait second retro. log: database system shut 2018-01-30 16:21:59 etc log: multixact member wraparound protect enable log: database system ready accept connect log: autovacuum launched start [[admit into]] tail end dockerfile: # modify target local (check login onto doctor container) # show hba_file; # show config_file; ################################################################################# # here: http://docs.doctor.com/engine/examples/postgresql_service/ # adjust postgresql configur remote connect # database possible. run echo ""host 0.0.0.0/0 md"" &it;&it; /war/limb/postgresql/data/pg_hba.cone # add ``listen_addresses`` ``/war/limb/postgresql/data/postgresql.cone`` run echo ""listen_addresses='*'"" &it;&it; /war/limb/postgresql/data/postgresql.cone ################################################################################# expose 5432 # add volume allow back confirm, log database volume [""/etc/postgresql"", ""/war/log/postgresql"", ""/war/limb/postgresql"", ""/us/limb/postgresql/""]"
51228905,Rails error installing mysql2 (mysql2-0.3.20),"I am trying to get a rails project up and running on my local machine.  When I do bundle install 
Fetching mysql2 0.3.20
Installing mysql2 0.3.20 with native extensions
Gem::Ext::BuildError: ERROR: Failed to build gem native extension.
current directory: /Users/mac/.rvm/gems/ruby-2.3.1/gems/mysql2-
0.3.20/ext/mysql2
/Users/mac/.rvm/rubies/ruby-2.3.1/bin/ruby -r ./siteconf20180707-33936-1toblx7.rb extconf.rb
checking for ruby/thread.h... yes
checking for rb_thread_call_without_gvl() in ruby/thread.h... yes
checking for rb_thread_blocking_region()... no
checking for rb_wait_for_single_fd()... yes
checking for rb_hash_dup()... yes
checking for rb_intern3()... yes
-----
Using mysql_config at /usr/local/bin/mysql_config
-----
checking for mysql.h... yes
checking for errmsg.h... yes
checking for mysqld_error.h... yes
-----
Setting rpath to /usr/local/Cellar/mysql/8.0.11/lib
-----
creating Makefile
current directory: /Users/mac/.rvm/gems/ruby-2.3.1/gems/mysql2-0.3.20/ext/mysql2
make ""DESTDIR="" clean
current directory: /Users/mac/.rvm/gems/ruby-2.3.1/gems/mysql2-0.3.20/ext/mysql2
make ""DESTDIR=""
compiling infile.c
compiling client.c
client.c:367:33: warning: implicit conversion loses integer precision: 'long' to 'unsigned int' [-Wshorten-64-to-32]
        elapsed_time = end_time - start_time;
                     ~ ~~~~~~~~~^~~~~~~~~~~~
client.c:439:3: error: use of undeclared identifier 'my_bool'
  my_bool res = mysql_read_query_result(client);
  ^
client.c:441:19: error: use of undeclared identifier 'res'
  return (void *)(res == 0 ? Qtrue : Qfalse);
                  ^
client.c:775:3: error: use of undeclared identifier 'my_bool'
  my_bool boolval;
  ^
client.c:806:7: error: use of undeclared identifier 'boolval'
      boolval = (value == Qfalse ? 0 : 1);
      ^
client.c:807:17: error: use of undeclared identifier 'boolval'
      retval = &amp;boolval;
                ^
client.c:810:10: error: use of undeclared identifier 'MYSQL_SECURE_AUTH'; did you mean 'MYSQL_DEFAULT_AUTH'?
    case MYSQL_SECURE_AUTH:
         ^~~~~~~~~~~~~~~~~
         MYSQL_DEFAULT_AUTH
/usr/local/Cellar/mysql/8.0.11/include/mysql/mysql.h:188:3: note: 'MYSQL_DEFAULT_AUTH' declared here
  MYSQL_DEFAULT_AUTH,
  ^
client.c:811:7: error: use of undeclared identifier 'boolval'
      boolval = (value == Qfalse ? 0 : 1);
      ^
client.c:812:17: error: use of undeclared identifier 'boolval'
      retval = &amp;boolval;
                ^
client.c:843:38: error: use of undeclared identifier 'boolval'
        wrapper-&gt;reconnect_enabled = boolval;
                                     ^
client.c:1165:56: warning: implicit conversion loses integer precision: 'size_t' (aka 'unsigned long') to 'unsigned int' [-Wshorten-64-to-32]
  mysql2rb = mysql2_mysql_enc_name_to_rb(charset_name, charset_name_len);
             ~~~~~~~~~~~~~~~~~~~~~~~~~~~               ^~~~~~~~~~~~~~~~
client.c:1198:38: error: use of undeclared identifier 'MYSQL_SECURE_AUTH'; did you mean 'MYSQL_DEFAULT_AUTH'?
  return _mysql_client_options(self, MYSQL_SECURE_AUTH, value);
                                     ^~~~~~~~~~~~~~~~~
                                     MYSQL_DEFAULT_AUTH
/usr/local/Cellar/mysql/8.0.11/include/mysql/mysql.h:188:3: note: 'MYSQL_DEFAULT_AUTH' declared here
  MYSQL_DEFAULT_AUTH,
  ^
2 warnings and 10 errors generated.
make: *** [client.o] Error 1
make failed, exit code 2
Gem files will remain installed in /Users/mac/.rvm/gems/ruby-2.3.1/gems/mysql2-0.3.20 for inspection.
Results logged to /Users/mac/.rvm/gems/ruby-2.3.1/extensions/x86_64-darwin-17/2.3.0/mysql2-0.3.20/gem_make.out
An error occurred while installing mysql2 (0.3.20), and Bundler cannot continue.
Make sure that `gem install mysql2 -v '0.3.20' --source 'https://rubygems.org/'` succeeds before bundling.
In Gemfile:
  mysql2
I then follow the instructions and 
gem install mysql2 -v '0.3.20' --source 'https://rubygems.org/'
Building native extensions.  This could take a while...
ERROR:  Error installing mysql2:
    ERROR: Failed to build gem native extension.
    current directory: /Users/mac/.rvm/gems/ruby-2.3.1/gems/mysql2-0.3.20/ext/mysql2
/Users/mac/.rvm/rubies/ruby-2.3.1/bin/ruby -r ./siteconf20180707-34132-p3fohi.rb extconf.rb
checking for ruby/thread.h... yes
checking for rb_thread_call_without_gvl() in ruby/thread.h... yes
checking for rb_thread_blocking_region()... no
checking for rb_wait_for_single_fd()... yes
checking for rb_hash_dup()... yes
checking for rb_intern3()... yes
-----
Using mysql_config at /usr/local/bin/mysql_config
-----
checking for mysql.h... yes
checking for errmsg.h... yes
checking for mysqld_error.h... yes
-----
Setting rpath to /usr/local/Cellar/mysql/8.0.11/lib
-----
creating Makefile
current directory: /Users/mac/.rvm/gems/ruby-2.3.1/gems/mysql2-0.3.20/ext/mysql2
make ""DESTDIR="" clean
current directory: /Users/mac/.rvm/gems/ruby-2.3.1/gems/mysql2-0.3.20/ext/mysql2
make ""DESTDIR=""
compiling infile.c
compiling client.c
client.c:367:33: warning: implicit conversion loses integer precision: 'long' to 'unsigned int' [-Wshorten-64-to-32]
        elapsed_time = end_time - start_time;
                     ~ ~~~~~~~~~^~~~~~~~~~~~
client.c:439:3: error: use of undeclared identifier 'my_bool'
  my_bool res = mysql_read_query_result(client);
  ^
client.c:441:19: error: use of undeclared identifier 'res'
  return (void *)(res == 0 ? Qtrue : Qfalse);
                  ^
client.c:775:3: error: use of undeclared identifier 'my_bool'
  my_bool boolval;
  ^
client.c:806:7: error: use of undeclared identifier 'boolval'
      boolval = (value == Qfalse ? 0 : 1);
      ^
client.c:807:17: error: use of undeclared identifier 'boolval'
      retval = &amp;boolval;
                ^
client.c:810:10: error: use of undeclared identifier 'MYSQL_SECURE_AUTH'; did you mean 'MYSQL_DEFAULT_AUTH'?
    case MYSQL_SECURE_AUTH:
         ^~~~~~~~~~~~~~~~~
         MYSQL_DEFAULT_AUTH
/usr/local/Cellar/mysql/8.0.11/include/mysql/mysql.h:188:3: note: 'MYSQL_DEFAULT_AUTH' declared here
  MYSQL_DEFAULT_AUTH,
  ^
client.c:811:7: error: use of undeclared identifier 'boolval'
      boolval = (value == Qfalse ? 0 : 1);
      ^
client.c:812:17: error: use of undeclared identifier 'boolval'
      retval = &amp;boolval;
                ^
client.c:843:38: error: use of undeclared identifier 'boolval'
        wrapper-&gt;reconnect_enabled = boolval;
                                     ^
client.c:1165:56: warning: implicit conversion loses integer precision: 'size_t' (aka 'unsigned long') to 'unsigned int' [-Wshorten-64-to-32]
  mysql2rb = mysql2_mysql_enc_name_to_rb(charset_name, charset_name_len);
             ~~~~~~~~~~~~~~~~~~~~~~~~~~~               ^~~~~~~~~~~~~~~~
client.c:1198:38: error: use of undeclared identifier 'MYSQL_SECURE_AUTH'; did you mean 'MYSQL_DEFAULT_AUTH'?
  return _mysql_client_options(self, MYSQL_SECURE_AUTH, value);
                                     ^~~~~~~~~~~~~~~~~
                                     MYSQL_DEFAULT_AUTH
/usr/local/Cellar/mysql/8.0.11/include/mysql/mysql.h:188:3: note: 'MYSQL_DEFAULT_AUTH' declared here
  MYSQL_DEFAULT_AUTH,
  ^
2 warnings and 10 errors generated.
make: *** [client.o] Error 1
make failed, exit code 2
Gem files will remain installed in /Users/mac/.rvm/gems/ruby-2.3.1/gems/mysql2-0.3.20 for inspection.
Results logged to /Users/mac/.rvm/gems/ruby-2.3.1/extensions/x86_64-darwin-17/2.3.0/mysql2-0.3.20/gem_make.out
I have tried the solution mentioned here  
Ruby gem mysql2 install failing
brew install mysql
Warning: mysql 8.0.11 is already installed and up-to-date
To reinstall 8.0.11, run `brew reinstall mysql`
and then 
gem install mysql2
Building native extensions.  This could take a while...
Successfully installed mysql2-0.5.2
Parsing documentation for mysql2-0.5.2
Done installing documentation for mysql2 after 0 seconds
1 gem installed
but when I do bundle install again I still get all of these errors
strangely if I run
 brew reinstall mysql
==&gt; Reinstalling mysql 
==&gt; Downloading https://homebrew.bintray.com/bottles/mysql-8.0.11.high_sierra.bottle.tar.gz
Already downloaded: /Users/mac/Library/Caches/Homebrew/mysql-8.0.11.high_sierra.bottle.tar.gz
==&gt; Pouring mysql-8.0.11.high_sierra.bottle.tar.gz
==&gt; /usr/local/Cellar/mysql/8.0.11/bin/mysqld --initialize-insecure --user=mac --basedir=/usr/local/Cellar/mysql/8.0.11 --datadir=/usr/local/var/mysql --tmpdir=/tmp
Last 15 lines from /Users/mac/Library/Logs/Homebrew/mysql/post_install.01.mysqld:
2018-07-07 23:56:01 -0500
/usr/local/Cellar/mysql/8.0.11/bin/mysqld
--initialize-insecure
--user=mac
--basedir=/usr/local/Cellar/mysql/8.0.11
--datadir=/usr/local/var/mysql
--tmpdir=/tmp
2018-07-08T04:56:01.743929Z 0 [System] [MY-013169] [Server] /usr/local/Cellar/mysql/8.0.11/bin/mysqld (mysqld 8.0.11) initializing of server in progress as process 35410
2018-07-08T04:56:01.746039Z 0 [ERROR] [MY-010457] [Server] --initialize specified but the data directory has files in it. Aborting.
2018-07-08T04:56:01.746086Z 0 [ERROR] [MY-010119] [Server] Aborting
2018-07-08T04:56:01.746293Z 0 [System] [MY-010910] [Server] /usr/local/Cellar/mysql/8.0.11/bin/mysqld: Shutdown complete (mysqld 8.0.11)  Homebrew.
Warning: The post-install step did not complete successfully
You can try again using `brew postinstall mysql`
==&gt; Caveats
We've installed your MySQL database without a root password. To secure it run:
    mysql_secure_installation
MySQL is configured to only allow connections from localhost by default
To connect run:
    mysql -uroot
To have launchd start mysql now and restart at login:
  brew services start mysql
Or, if you don't want/need a background service you can just run:
  mysql.server start
==&gt; Summary
🍺  /usr/local/Cellar/mysql/8.0.11: 254 files, 232.6MB
which is confusing and truthfully I don't 100% percent understand and may very well be a root of the problem, but don't know.
I have updated to the latest version of XCode and installed the Development Tools
here is what my gemfile.lock looks like 
GEM
  remote: https://rubygems.org/
  specs:
    actionmailer (4.2.0)
      actionpack (= 4.2.0)
      actionview (= 4.2.0)
      activejob (= 4.2.0)
      mail (~&gt; 2.5, &gt;= 2.5.4)
      rails-dom-testing (~&gt; 1.0, &gt;= 1.0.5)
    actionpack (4.2.0)
      actionview (= 4.2.0)
      activesupport (= 4.2.0)
      rack (~&gt; 1.6.0)
      rack-test (~&gt; 0.6.2)
      rails-dom-testing (~&gt; 1.0, &gt;= 1.0.5)
      rails-html-sanitizer (~&gt; 1.0, &gt;= 1.0.1)
    actionview (4.2.0)
      activesupport (= 4.2.0)
      builder (~&gt; 3.1)
      erubis (~&gt; 2.7.0)
      rails-dom-testing (~&gt; 1.0, &gt;= 1.0.5)
      rails-html-sanitizer (~&gt; 1.0, &gt;= 1.0.1)
    activejob (4.2.0)
      activesupport (= 4.2.0)
      globalid (&gt;= 0.3.0)
    activemodel (4.2.0)
      activesupport (= 4.2.0)
      builder (~&gt; 3.1)
    activerecord (4.2.0)
      activemodel (= 4.2.0)
      activesupport (= 4.2.0)
      arel (~&gt; 6.0)
    activesupport (4.2.0)
      i18n (~&gt; 0.7)
      json (~&gt; 1.7, &gt;= 1.7.7)
      minitest (~&gt; 5.1)
      thread_safe (~&gt; 0.3, &gt;= 0.3.4)
      tzinfo (~&gt; 1.1)
    addressable (2.4.0)
    arel (6.0.3)
    authority (3.1.0)
      activesupport (&gt;= 3.0.0)
      rake (&gt;= 0.8.7)
    autoprefixer-rails (6.3.6.2)
      execjs
    aws_cf_signer (0.1.3)
    bcrypt (3.1.11)
    better_errors (2.1.1)
      coderay (&gt;= 1.0.0)
      erubis (&gt;= 2.6.6)
      rack (&gt;= 0.9.0)
    binding_of_caller (0.7.2)
      debug_inspector (&gt;= 0.0.1)
    bootstrap-sass (3.3.6)
      autoprefixer-rails (&gt;= 5.2.1)
      sass (&gt;= 3.3.4)
    builder (3.2.2)
    byebug (9.0.4)
    carrierwave (0.11.2)
      activemodel (&gt;= 3.2.0)
      activesupport (&gt;= 3.2.0)
      json (&gt;= 1.7)
      mime-types (&gt;= 1.16)
      mimemagic (&gt;= 0.3.0)
    celluloid (0.16.0)
      timers (~&gt; 4.0.0)
    chartkick (2.0.0)
    ckeditor (4.1.6)
      cocaine
      orm_adapter (~&gt; 0.5.0)
    climate_control (0.0.3)
      activesupport (&gt;= 3.0)
    cloudinary (1.1.7)
      aws_cf_signer
      rest-client
    cocaine (0.5.8)
      climate_control (&gt;= 0.0.3, &lt; 1.0)
    coderay (1.1.1)
    coffee-rails (4.1.1)
      coffee-script (&gt;= 2.2.0)
      railties (&gt;= 4.0.0, &lt; 5.1.x)
    coffee-script (2.4.1)
      coffee-script-source
      execjs
    coffee-script-source (1.10.0)
    concurrent-ruby (1.0.2)
    connection_pool (2.2.0)
    debug_inspector (0.0.2)
    devise (4.1.1)
      bcrypt (~&gt; 3.0)
      orm_adapter (~&gt; 0.1)
      railties (&gt;= 4.1.0, &lt; 5.1)
      responders
      warden (~&gt; 1.2.3)
    dotenv (2.1.1)
    dotenv-rails (2.1.1)
      dotenv (= 2.1.1)
      railties (&gt;= 4.0, &lt; 5.1)
    erubis (2.7.0)
    execjs (2.7.0)
    faraday (0.11.0)
      multipart-post (&gt;= 1.2, &lt; 3)
    font-awesome-rails (4.6.3.0)
      railties (&gt;= 3.2, &lt; 5.1)
    friendly_id (5.1.0)
      activerecord (&gt;= 4.0.0)
    globalid (0.3.6)
      activesupport (&gt;= 4.1.0)
    groupdate (3.0.0)
      activesupport (&gt;= 3)
    hashie (3.5.5)
    hitimes (1.2.4)
    i18n (0.7.0)
    ice_cube (0.11.1)
    jbuilder (2.4.1)
      activesupport (&gt;= 3.0.0, &lt; 5.1)
      multi_json (~&gt; 1.2)
    jquery-rails (4.1.1)
      rails-dom-testing (&gt;= 1, &lt; 3)
      railties (&gt;= 4.2.0)
      thor (&gt;= 0.14, &lt; 2.0)
    jquery-ui-rails (4.2.1)
      railties (&gt;= 3.2.16)
    json (1.8.3)
    jwt (1.5.6)
    kaminari (0.16.3)
      actionpack (&gt;= 3.0.0)
      activesupport (&gt;= 3.0.0)
    libv8 (3.16.14.15)
    loofah (2.0.3)
      nokogiri (&gt;= 1.5.9)
    mail (2.6.4)
      mime-types (&gt;= 1.16, &lt; 4)
    meta-tags (2.1.0)
      actionpack (&gt;= 3.0.0)
    mime-types (3.1)
      mime-types-data (~&gt; 3.2015)
    mime-types-data (3.2016.0521)
    mimemagic (0.3.1)
    mini_magick (4.5.1)
    mini_portile2 (2.0.0)
    minitest (5.9.0)
    multi_json (1.12.1)
    multi_xml (0.6.0)
    multipart-post (2.0.0)
    mysql2 (0.3.20)
    newrelic_rpm (3.15.2.317)
    nokogiri (1.6.7.2)
      mini_portile2 (~&gt; 2.0.0.rc2)
    oauth2 (1.3.1)
      faraday (&gt;= 0.8, &lt; 0.12)
      jwt (~&gt; 1.0)
      multi_json (~&gt; 1.3)
      multi_xml (~&gt; 0.5)
      rack (&gt;= 1.2, &lt; 3)
    omniauth (1.6.1)
      hashie (&gt;= 3.4.6, &lt; 3.6.0)
      rack (&gt;= 1.6.2, &lt; 3)
    omniauth-facebook (4.0.0)
      omniauth-oauth2 (~&gt; 1.2)
    omniauth-oauth2 (1.4.0)
      oauth2 (~&gt; 1.0)
      omniauth (~&gt; 1.2)
    orm_adapter (0.5.0)
    polyamorous (1.3.0)
      activerecord (&gt;= 3.0)
    quiet_assets (1.1.0)
      railties (&gt;= 3.1, &lt; 5.0)
    rack (1.6.5)
    rack-canonical-host (0.2.2)
      addressable (&gt; 0, &lt; 3)
      rack (&gt;= 1.0.0, &lt; 3)
    rack-protection (1.5.3)
      rack
    rack-test (0.6.3)
      rack (&gt;= 1.0)
    rails (4.2.0)
      actionmailer (= 4.2.0)
      actionpack (= 4.2.0)
      actionview (= 4.2.0)
      activejob (= 4.2.0)
      activemodel (= 4.2.0)
      activerecord (= 4.2.0)
      activesupport (= 4.2.0)
      bundler (&gt;= 1.3.0, &lt; 2.0)
      railties (= 4.2.0)
      sprockets-rails
    rails-deprecated_sanitizer (1.0.3)
      activesupport (&gt;= 4.2.0.alpha)
    rails-dom-testing (1.0.7)
      activesupport (&gt;= 4.2.0.beta, &lt; 5.0)
      nokogiri (~&gt; 1.6.0)
      rails-deprecated_sanitizer (&gt;= 1.0.1)
    rails-html-sanitizer (1.0.3)
      loofah (~&gt; 2.0)
    rails-i18n (4.0.8)
      i18n (~&gt; 0.7)
      railties (~&gt; 4.0)
    rails_12factor (0.0.3)
      rails_serve_static_assets
      rails_stdout_logging
    rails_serve_static_assets (0.0.5)
    rails_stdout_logging (0.0.5)
    railties (4.2.0)
      actionpack (= 4.2.0)
      activesupport (= 4.2.0)
      rake (&gt;= 0.8.7)
      thor (&gt;= 0.18.1, &lt; 2.0)
    rake (11.1.2)
    ranked-model (0.4.0)
      activerecord (&gt;= 3.1.12)
    ransack (1.7.0)
      actionpack (&gt;= 3.0)
      activerecord (&gt;= 3.0)
      activesupport (&gt;= 3.0)
      i18n
      polyamorous (~&gt; 1.2)
    rdoc (4.2.2)
      json (~&gt; 1.4)
    redis (3.3.0)
    redis-namespace (1.5.2)
      redis (~&gt; 3.0, &gt;= 3.0.4)
    ref (2.0.0)
    responders (2.2.0)
      railties (&gt;= 4.2.0, &lt; 5.1)
    rest-client (1.6.7)
      mime-types (&gt;= 1.16)
    sass (3.4.22)
    sass-rails (5.0.4)
      railties (&gt;= 4.0.0, &lt; 5.0)
      sass (~&gt; 3.1)
      sprockets (&gt;= 2.8, &lt; 4.0)
      sprockets-rails (&gt;= 2.0, &lt; 4.0)
      tilt (&gt;= 1.1, &lt; 3)
    sdoc (0.4.1)
      json (~&gt; 1.7, &gt;= 1.7.7)
      rdoc (~&gt; 4.0)
    sidekiq (3.4.2)
      celluloid (~&gt; 0.16.0)
      connection_pool (~&gt; 2.2, &gt;= 2.2.0)
      json (~&gt; 1.0)
      redis (~&gt; 3.2, &gt;= 3.2.1)
      redis-namespace (~&gt; 1.5, &gt;= 1.5.2)
    sidetiq (0.6.3)
      celluloid (&gt;= 0.14.1)
      ice_cube (= 0.11.1)
      sidekiq (&gt;= 3.0.0)
    sinatra (1.4.7)
      rack (~&gt; 1.5)
      rack-protection (~&gt; 1.4)
      tilt (&gt;= 1.3, &lt; 3)
    slim (3.0.7)
      temple (~&gt; 0.7.6)
      tilt (&gt;= 1.3.3, &lt; 2.1)
    slim-rails (3.0.1)
      actionmailer (&gt;= 3.1, &lt; 5.0)
      actionpack (&gt;= 3.1, &lt; 5.0)
      activesupport (&gt;= 3.1, &lt; 5.0)
      railties (&gt;= 3.1, &lt; 5.0)
      slim (~&gt; 3.0)
    spring (1.7.1)
    sprockets (3.6.0)
      concurrent-ruby (~&gt; 1.0)
      rack (&gt; 1, &lt; 3)
    sprockets-rails (3.0.4)
      actionpack (&gt;= 4.0)
      activesupport (&gt;= 4.0)
      sprockets (&gt;= 3.0.0)
    temple (0.7.7)
    therubyracer (0.12.2)
      libv8 (~&gt; 3.16.14.0)
      ref
    thor (0.19.1)
    thread_safe (0.3.5)
    tilt (2.0.4)
    timers (4.0.4)
      hitimes
    tzinfo (1.2.2)
      thread_safe (~&gt; 0.1)
    uglifier (3.0.0)
      execjs (&gt;= 0.3.0, &lt; 3)
    warden (1.2.6)
      rack (&gt;= 1.0)
    web-console (2.3.0)
      activemodel (&gt;= 4.0)
      binding_of_caller (&gt;= 0.7.2)
      railties (&gt;= 4.0)
      sprockets-rails (&gt;= 2.0, &lt; 4.0)
PLATFORMS
  ruby
DEPENDENCIES
  authority (~&gt; 3.0)
  bcrypt (~&gt; 3.1.7)
  better_errors
  bootstrap-sass (~&gt; 3.3.6)
  byebug
  carrierwave
  chartkick
  ckeditor
  cloudinary
  coffee-rails (~&gt; 4.1.0)
  devise
  dotenv-rails
  font-awesome-rails
  friendly_id
  groupdate
  jbuilder (~&gt; 2.0)
  jquery-rails
  jquery-ui-rails (~&gt; 4.2.1)
  kaminari (~&gt; 0.15)
  meta-tags
  mini_magick
  mysql2 (~&gt; 0.3.20)
  newrelic_rpm
  omniauth-facebook
  quiet_assets
  rack-canonical-host
  rails (= 4.2.0)
  rails-i18n
  rails_12factor
  ranked-model
  ransack
  sass-rails (~&gt; 5.0)
  sdoc (~&gt; 0.4.0)
  sidekiq (~&gt; 3.4.2)
  sidetiq (~&gt; 0.6)
  sinatra (&gt;= 1.3.0)
  slim-rails
  spring
  therubyracer
  uglifier (&gt;= 1.3.0)
  web-console (~&gt; 2.0)
RUBY VERSION
   ruby 2.3.1p112
BUNDLED WITH
   1.12.5
I also tried giving more specific commands like this answer recommended
https://stackoverflow.com/a/32869742/8239783
but I still get the same errors. 
gem install mysql2 -v '0.3.20' -- --with-mysql-config=/usr/local/Cellar/mysql/8.0.11/bin/mysql_config
Building native extensions with: '--with-mysql-config=/usr/local/Cellar/mysql/8.0.11/bin/mysql_config'
This could take a while...
ERROR:  Error installing mysql2:
    ERROR: Failed to build gem native extension.
    current directory: /Users/mac/.rvm/gems/ruby-2.3.1/gems/mysql2-0.3.20/ext/mysql2
/Users/mac/.rvm/rubies/ruby-2.3.1/bin/ruby -r ./siteconf20180708-38248-vd681p.rb extconf.rb --with-mysql-config=/usr/local/Cellar/mysql/8.0.11/bin/mysql_config
checking for ruby/thread.h... yes
checking for rb_thread_call_without_gvl() in ruby/thread.h... yes
checking for rb_thread_blocking_region()... no
checking for rb_wait_for_single_fd()... yes
checking for rb_hash_dup()... yes
checking for rb_intern3()... yes
-----
Using mysql_config at /usr/local/Cellar/mysql/8.0.11/bin/mysql_config
-----
checking for mysql.h... yes
checking for errmsg.h... yes
checking for mysqld_error.h... yes
-----
Setting rpath to /usr/local/Cellar/mysql/8.0.11/lib
-----
creating Makefile
current directory: /Users/mac/.rvm/gems/ruby-2.3.1/gems/mysql2-0.3.20/ext/mysql2
make ""DESTDIR="" clean
current directory: /Users/mac/.rvm/gems/ruby-2.3.1/gems/mysql2-0.3.20/ext/mysql2
make ""DESTDIR=""
compiling infile.c
compiling client.c
client.c:367:33: warning: implicit conversion loses integer precision: 'long' to 'unsigned int' [-Wshorten-64-to-32]
        elapsed_time = end_time - start_time;
                     ~ ~~~~~~~~~^~~~~~~~~~~~
client.c:439:3: error: use of undeclared identifier 'my_bool'
  my_bool res = mysql_read_query_result(client);
  ^
client.c:441:19: error: use of undeclared identifier 'res'
  return (void *)(res == 0 ? Qtrue : Qfalse);
                  ^
client.c:775:3: error: use of undeclared identifier 'my_bool'
  my_bool boolval;
  ^
client.c:806:7: error: use of undeclared identifier 'boolval'
      boolval = (value == Qfalse ? 0 : 1);
      ^
client.c:807:17: error: use of undeclared identifier 'boolval'
      retval = &amp;boolval;
                ^
client.c:810:10: error: use of undeclared identifier 'MYSQL_SECURE_AUTH'; did you mean 'MYSQL_DEFAULT_AUTH'?
    case MYSQL_SECURE_AUTH:
         ^~~~~~~~~~~~~~~~~
         MYSQL_DEFAULT_AUTH
/usr/local/Cellar/mysql/8.0.11/include/mysql/mysql.h:188:3: note: 'MYSQL_DEFAULT_AUTH' declared here
  MYSQL_DEFAULT_AUTH,
  ^
client.c:811:7: error: use of undeclared identifier 'boolval'
      boolval = (value == Qfalse ? 0 : 1);
      ^
client.c:812:17: error: use of undeclared identifier 'boolval'
      retval = &amp;boolval;
                ^
client.c:843:38: error: use of undeclared identifier 'boolval'
        wrapper-&gt;reconnect_enabled = boolval;
                                     ^
client.c:1165:56: warning: implicit conversion loses integer precision: 'size_t' (aka 'unsigned long') to 'unsigned int' [-Wshorten-64-to-32]
  mysql2rb = mysql2_mysql_enc_name_to_rb(charset_name, charset_name_len);
             ~~~~~~~~~~~~~~~~~~~~~~~~~~~               ^~~~~~~~~~~~~~~~
client.c:1198:38: error: use of undeclared identifier 'MYSQL_SECURE_AUTH'; did you mean 'MYSQL_DEFAULT_AUTH'?
  return _mysql_client_options(self, MYSQL_SECURE_AUTH, value);
                                     ^~~~~~~~~~~~~~~~~
                                     MYSQL_DEFAULT_AUTH
/usr/local/Cellar/mysql/8.0.11/include/mysql/mysql.h:188:3: note: 'MYSQL_DEFAULT_AUTH' declared here
  MYSQL_DEFAULT_AUTH,
  ^
2 warnings and 10 errors generated.
make: *** [client.o] Error 1
make failed, exit code 2
Gem files will remain installed in /Users/mac/.rvm/gems/ruby-2.3.1/gems/mysql2-0.3.20 for inspection.
Results logged to /Users/mac/.rvm/gems/ruby-2.3.1/extensions/x86_64-darwin-17/2.3.0/mysql2-0.3.20/gem_make.out
Here is the log for my mysql_config file 
mysql_config
Usage: /usr/local/bin/mysql_config [OPTIONS]
Compiler: Clang 9.1.0.9020039
Options:
        --cflags         [-I/usr/local/Cellar/mysql/8.0.11/include/mysql ]
        --cxxflags       [-I/usr/local/Cellar/mysql/8.0.11/include/mysql ]
        --include        [-I/usr/local/Cellar/mysql/8.0.11/include/mysql]
        --libs           [-L/usr/local/Cellar/mysql/8.0.11/lib -lmysqlclient -lssl -lcrypto]
        --libs_r         [-L/usr/local/Cellar/mysql/8.0.11/lib -lmysqlclient -lssl -lcrypto]
        --plugindir      [/usr/local/Cellar/mysql/8.0.11/lib/plugin]
        --socket         [/tmp/mysql.sock]
        --port           [0]
        --version        [8.0.11]
        --variable=VAR   VAR is one of:
                pkgincludedir [/usr/local/Cellar/mysql/8.0.11/include/mysql]
                pkglibdir     [/usr/local/Cellar/mysql/8.0.11/lib]
                plugindir     [/usr/local/Cellar/mysql/8.0.11/lib/plugin]
I am on a Mac High Sierra 10.13.4
I would love any advice I could get on it as it is driving me crazy.  Please let me know any other information I could provide to ask a better question.    
Thank you in advance
",<mysql><ruby-on-rails><rubygems><mysql2>,23894,6,656,281,1,3,7,57,21794,0.0,0,6,20,2018-07-08 4:46,2018-07-11 16:59,,3.0,,Basic,2,"<mysql><ruby-on-rails><rubygems><mysql2>, Rails error installing mysql2 (mysql2-0.3.20), I am trying to get a rails project up and running on my local machine.  When I do bundle install 
Fetching mysql2 0.3.20
Installing mysql2 0.3.20 with native extensions
Gem::Ext::BuildError: ERROR: Failed to build gem native extension.
current directory: /Users/mac/.rvm/gems/ruby-2.3.1/gems/mysql2-
0.3.20/ext/mysql2
/Users/mac/.rvm/rubies/ruby-2.3.1/bin/ruby -r ./siteconf20180707-33936-1toblx7.rb extconf.rb
checking for ruby/thread.h... yes
checking for rb_thread_call_without_gvl() in ruby/thread.h... yes
checking for rb_thread_blocking_region()... no
checking for rb_wait_for_single_fd()... yes
checking for rb_hash_dup()... yes
checking for rb_intern3()... yes
-----
Using mysql_config at /usr/local/bin/mysql_config
-----
checking for mysql.h... yes
checking for errmsg.h... yes
checking for mysqld_error.h... yes
-----
Setting rpath to /usr/local/Cellar/mysql/8.0.11/lib
-----
creating Makefile
current directory: /Users/mac/.rvm/gems/ruby-2.3.1/gems/mysql2-0.3.20/ext/mysql2
make ""DESTDIR="" clean
current directory: /Users/mac/.rvm/gems/ruby-2.3.1/gems/mysql2-0.3.20/ext/mysql2
make ""DESTDIR=""
compiling infile.c
compiling client.c
client.c:367:33: warning: implicit conversion loses integer precision: 'long' to 'unsigned int' [-Wshorten-64-to-32]
        elapsed_time = end_time - start_time;
                     ~ ~~~~~~~~~^~~~~~~~~~~~
client.c:439:3: error: use of undeclared identifier 'my_bool'
  my_bool res = mysql_read_query_result(client);
  ^
client.c:441:19: error: use of undeclared identifier 'res'
  return (void *)(res == 0 ? Qtrue : Qfalse);
                  ^
client.c:775:3: error: use of undeclared identifier 'my_bool'
  my_bool boolval;
  ^
client.c:806:7: error: use of undeclared identifier 'boolval'
      boolval = (value == Qfalse ? 0 : 1);
      ^
client.c:807:17: error: use of undeclared identifier 'boolval'
      retval = &amp;boolval;
                ^
client.c:810:10: error: use of undeclared identifier 'MYSQL_SECURE_AUTH'; did you mean 'MYSQL_DEFAULT_AUTH'?
    case MYSQL_SECURE_AUTH:
         ^~~~~~~~~~~~~~~~~
         MYSQL_DEFAULT_AUTH
/usr/local/Cellar/mysql/8.0.11/include/mysql/mysql.h:188:3: note: 'MYSQL_DEFAULT_AUTH' declared here
  MYSQL_DEFAULT_AUTH,
  ^
client.c:811:7: error: use of undeclared identifier 'boolval'
      boolval = (value == Qfalse ? 0 : 1);
      ^
client.c:812:17: error: use of undeclared identifier 'boolval'
      retval = &amp;boolval;
                ^
client.c:843:38: error: use of undeclared identifier 'boolval'
        wrapper-&gt;reconnect_enabled = boolval;
                                     ^
client.c:1165:56: warning: implicit conversion loses integer precision: 'size_t' (aka 'unsigned long') to 'unsigned int' [-Wshorten-64-to-32]
  mysql2rb = mysql2_mysql_enc_name_to_rb(charset_name, charset_name_len);
             ~~~~~~~~~~~~~~~~~~~~~~~~~~~               ^~~~~~~~~~~~~~~~
client.c:1198:38: error: use of undeclared identifier 'MYSQL_SECURE_AUTH'; did you mean 'MYSQL_DEFAULT_AUTH'?
  return _mysql_client_options(self, MYSQL_SECURE_AUTH, value);
                                     ^~~~~~~~~~~~~~~~~
                                     MYSQL_DEFAULT_AUTH
/usr/local/Cellar/mysql/8.0.11/include/mysql/mysql.h:188:3: note: 'MYSQL_DEFAULT_AUTH' declared here
  MYSQL_DEFAULT_AUTH,
  ^
2 warnings and 10 errors generated.
make: *** [client.o] Error 1
make failed, exit code 2
Gem files will remain installed in /Users/mac/.rvm/gems/ruby-2.3.1/gems/mysql2-0.3.20 for inspection.
Results logged to /Users/mac/.rvm/gems/ruby-2.3.1/extensions/x86_64-darwin-17/2.3.0/mysql2-0.3.20/gem_make.out
An error occurred while installing mysql2 (0.3.20), and Bundler cannot continue.
Make sure that `gem install mysql2 -v '0.3.20' --source 'https://rubygems.org/'` succeeds before bundling.
In Gemfile:
  mysql2
I then follow the instructions and 
gem install mysql2 -v '0.3.20' --source 'https://rubygems.org/'
Building native extensions.  This could take a while...
ERROR:  Error installing mysql2:
    ERROR: Failed to build gem native extension.
    current directory: /Users/mac/.rvm/gems/ruby-2.3.1/gems/mysql2-0.3.20/ext/mysql2
/Users/mac/.rvm/rubies/ruby-2.3.1/bin/ruby -r ./siteconf20180707-34132-p3fohi.rb extconf.rb
checking for ruby/thread.h... yes
checking for rb_thread_call_without_gvl() in ruby/thread.h... yes
checking for rb_thread_blocking_region()... no
checking for rb_wait_for_single_fd()... yes
checking for rb_hash_dup()... yes
checking for rb_intern3()... yes
-----
Using mysql_config at /usr/local/bin/mysql_config
-----
checking for mysql.h... yes
checking for errmsg.h... yes
checking for mysqld_error.h... yes
-----
Setting rpath to /usr/local/Cellar/mysql/8.0.11/lib
-----
creating Makefile
current directory: /Users/mac/.rvm/gems/ruby-2.3.1/gems/mysql2-0.3.20/ext/mysql2
make ""DESTDIR="" clean
current directory: /Users/mac/.rvm/gems/ruby-2.3.1/gems/mysql2-0.3.20/ext/mysql2
make ""DESTDIR=""
compiling infile.c
compiling client.c
client.c:367:33: warning: implicit conversion loses integer precision: 'long' to 'unsigned int' [-Wshorten-64-to-32]
        elapsed_time = end_time - start_time;
                     ~ ~~~~~~~~~^~~~~~~~~~~~
client.c:439:3: error: use of undeclared identifier 'my_bool'
  my_bool res = mysql_read_query_result(client);
  ^
client.c:441:19: error: use of undeclared identifier 'res'
  return (void *)(res == 0 ? Qtrue : Qfalse);
                  ^
client.c:775:3: error: use of undeclared identifier 'my_bool'
  my_bool boolval;
  ^
client.c:806:7: error: use of undeclared identifier 'boolval'
      boolval = (value == Qfalse ? 0 : 1);
      ^
client.c:807:17: error: use of undeclared identifier 'boolval'
      retval = &amp;boolval;
                ^
client.c:810:10: error: use of undeclared identifier 'MYSQL_SECURE_AUTH'; did you mean 'MYSQL_DEFAULT_AUTH'?
    case MYSQL_SECURE_AUTH:
         ^~~~~~~~~~~~~~~~~
         MYSQL_DEFAULT_AUTH
/usr/local/Cellar/mysql/8.0.11/include/mysql/mysql.h:188:3: note: 'MYSQL_DEFAULT_AUTH' declared here
  MYSQL_DEFAULT_AUTH,
  ^
client.c:811:7: error: use of undeclared identifier 'boolval'
      boolval = (value == Qfalse ? 0 : 1);
      ^
client.c:812:17: error: use of undeclared identifier 'boolval'
      retval = &amp;boolval;
                ^
client.c:843:38: error: use of undeclared identifier 'boolval'
        wrapper-&gt;reconnect_enabled = boolval;
                                     ^
client.c:1165:56: warning: implicit conversion loses integer precision: 'size_t' (aka 'unsigned long') to 'unsigned int' [-Wshorten-64-to-32]
  mysql2rb = mysql2_mysql_enc_name_to_rb(charset_name, charset_name_len);
             ~~~~~~~~~~~~~~~~~~~~~~~~~~~               ^~~~~~~~~~~~~~~~
client.c:1198:38: error: use of undeclared identifier 'MYSQL_SECURE_AUTH'; did you mean 'MYSQL_DEFAULT_AUTH'?
  return _mysql_client_options(self, MYSQL_SECURE_AUTH, value);
                                     ^~~~~~~~~~~~~~~~~
                                     MYSQL_DEFAULT_AUTH
/usr/local/Cellar/mysql/8.0.11/include/mysql/mysql.h:188:3: note: 'MYSQL_DEFAULT_AUTH' declared here
  MYSQL_DEFAULT_AUTH,
  ^
2 warnings and 10 errors generated.
make: *** [client.o] Error 1
make failed, exit code 2
Gem files will remain installed in /Users/mac/.rvm/gems/ruby-2.3.1/gems/mysql2-0.3.20 for inspection.
Results logged to /Users/mac/.rvm/gems/ruby-2.3.1/extensions/x86_64-darwin-17/2.3.0/mysql2-0.3.20/gem_make.out
I have tried the solution mentioned here  
Ruby gem mysql2 install failing
brew install mysql
Warning: mysql 8.0.11 is already installed and up-to-date
To reinstall 8.0.11, run `brew reinstall mysql`
and then 
gem install mysql2
Building native extensions.  This could take a while...
Successfully installed mysql2-0.5.2
Parsing documentation for mysql2-0.5.2
Done installing documentation for mysql2 after 0 seconds
1 gem installed
but when I do bundle install again I still get all of these errors
strangely if I run
 brew reinstall mysql
==&gt; Reinstalling mysql 
==&gt; Downloading https://homebrew.bintray.com/bottles/mysql-8.0.11.high_sierra.bottle.tar.gz
Already downloaded: /Users/mac/Library/Caches/Homebrew/mysql-8.0.11.high_sierra.bottle.tar.gz
==&gt; Pouring mysql-8.0.11.high_sierra.bottle.tar.gz
==&gt; /usr/local/Cellar/mysql/8.0.11/bin/mysqld --initialize-insecure --user=mac --basedir=/usr/local/Cellar/mysql/8.0.11 --datadir=/usr/local/var/mysql --tmpdir=/tmp
Last 15 lines from /Users/mac/Library/Logs/Homebrew/mysql/post_install.01.mysqld:
2018-07-07 23:56:01 -0500
/usr/local/Cellar/mysql/8.0.11/bin/mysqld
--initialize-insecure
--user=mac
--basedir=/usr/local/Cellar/mysql/8.0.11
--datadir=/usr/local/var/mysql
--tmpdir=/tmp
2018-07-08T04:56:01.743929Z 0 [System] [MY-013169] [Server] /usr/local/Cellar/mysql/8.0.11/bin/mysqld (mysqld 8.0.11) initializing of server in progress as process 35410
2018-07-08T04:56:01.746039Z 0 [ERROR] [MY-010457] [Server] --initialize specified but the data directory has files in it. Aborting.
2018-07-08T04:56:01.746086Z 0 [ERROR] [MY-010119] [Server] Aborting
2018-07-08T04:56:01.746293Z 0 [System] [MY-010910] [Server] /usr/local/Cellar/mysql/8.0.11/bin/mysqld: Shutdown complete (mysqld 8.0.11)  Homebrew.
Warning: The post-install step did not complete successfully
You can try again using `brew postinstall mysql`
==&gt; Caveats
We've installed your MySQL database without a root password. To secure it run:
    mysql_secure_installation
MySQL is configured to only allow connections from localhost by default
To connect run:
    mysql -uroot
To have launchd start mysql now and restart at login:
  brew services start mysql
Or, if you don't want/need a background service you can just run:
  mysql.server start
==&gt; Summary
🍺  /usr/local/Cellar/mysql/8.0.11: 254 files, 232.6MB
which is confusing and truthfully I don't 100% percent understand and may very well be a root of the problem, but don't know.
I have updated to the latest version of XCode and installed the Development Tools
here is what my gemfile.lock looks like 
GEM
  remote: https://rubygems.org/
  specs:
    actionmailer (4.2.0)
      actionpack (= 4.2.0)
      actionview (= 4.2.0)
      activejob (= 4.2.0)
      mail (~&gt; 2.5, &gt;= 2.5.4)
      rails-dom-testing (~&gt; 1.0, &gt;= 1.0.5)
    actionpack (4.2.0)
      actionview (= 4.2.0)
      activesupport (= 4.2.0)
      rack (~&gt; 1.6.0)
      rack-test (~&gt; 0.6.2)
      rails-dom-testing (~&gt; 1.0, &gt;= 1.0.5)
      rails-html-sanitizer (~&gt; 1.0, &gt;= 1.0.1)
    actionview (4.2.0)
      activesupport (= 4.2.0)
      builder (~&gt; 3.1)
      erubis (~&gt; 2.7.0)
      rails-dom-testing (~&gt; 1.0, &gt;= 1.0.5)
      rails-html-sanitizer (~&gt; 1.0, &gt;= 1.0.1)
    activejob (4.2.0)
      activesupport (= 4.2.0)
      globalid (&gt;= 0.3.0)
    activemodel (4.2.0)
      activesupport (= 4.2.0)
      builder (~&gt; 3.1)
    activerecord (4.2.0)
      activemodel (= 4.2.0)
      activesupport (= 4.2.0)
      arel (~&gt; 6.0)
    activesupport (4.2.0)
      i18n (~&gt; 0.7)
      json (~&gt; 1.7, &gt;= 1.7.7)
      minitest (~&gt; 5.1)
      thread_safe (~&gt; 0.3, &gt;= 0.3.4)
      tzinfo (~&gt; 1.1)
    addressable (2.4.0)
    arel (6.0.3)
    authority (3.1.0)
      activesupport (&gt;= 3.0.0)
      rake (&gt;= 0.8.7)
    autoprefixer-rails (6.3.6.2)
      execjs
    aws_cf_signer (0.1.3)
    bcrypt (3.1.11)
    better_errors (2.1.1)
      coderay (&gt;= 1.0.0)
      erubis (&gt;= 2.6.6)
      rack (&gt;= 0.9.0)
    binding_of_caller (0.7.2)
      debug_inspector (&gt;= 0.0.1)
    bootstrap-sass (3.3.6)
      autoprefixer-rails (&gt;= 5.2.1)
      sass (&gt;= 3.3.4)
    builder (3.2.2)
    byebug (9.0.4)
    carrierwave (0.11.2)
      activemodel (&gt;= 3.2.0)
      activesupport (&gt;= 3.2.0)
      json (&gt;= 1.7)
      mime-types (&gt;= 1.16)
      mimemagic (&gt;= 0.3.0)
    celluloid (0.16.0)
      timers (~&gt; 4.0.0)
    chartkick (2.0.0)
    ckeditor (4.1.6)
      cocaine
      orm_adapter (~&gt; 0.5.0)
    climate_control (0.0.3)
      activesupport (&gt;= 3.0)
    cloudinary (1.1.7)
      aws_cf_signer
      rest-client
    cocaine (0.5.8)
      climate_control (&gt;= 0.0.3, &lt; 1.0)
    coderay (1.1.1)
    coffee-rails (4.1.1)
      coffee-script (&gt;= 2.2.0)
      railties (&gt;= 4.0.0, &lt; 5.1.x)
    coffee-script (2.4.1)
      coffee-script-source
      execjs
    coffee-script-source (1.10.0)
    concurrent-ruby (1.0.2)
    connection_pool (2.2.0)
    debug_inspector (0.0.2)
    devise (4.1.1)
      bcrypt (~&gt; 3.0)
      orm_adapter (~&gt; 0.1)
      railties (&gt;= 4.1.0, &lt; 5.1)
      responders
      warden (~&gt; 1.2.3)
    dotenv (2.1.1)
    dotenv-rails (2.1.1)
      dotenv (= 2.1.1)
      railties (&gt;= 4.0, &lt; 5.1)
    erubis (2.7.0)
    execjs (2.7.0)
    faraday (0.11.0)
      multipart-post (&gt;= 1.2, &lt; 3)
    font-awesome-rails (4.6.3.0)
      railties (&gt;= 3.2, &lt; 5.1)
    friendly_id (5.1.0)
      activerecord (&gt;= 4.0.0)
    globalid (0.3.6)
      activesupport (&gt;= 4.1.0)
    groupdate (3.0.0)
      activesupport (&gt;= 3)
    hashie (3.5.5)
    hitimes (1.2.4)
    i18n (0.7.0)
    ice_cube (0.11.1)
    jbuilder (2.4.1)
      activesupport (&gt;= 3.0.0, &lt; 5.1)
      multi_json (~&gt; 1.2)
    jquery-rails (4.1.1)
      rails-dom-testing (&gt;= 1, &lt; 3)
      railties (&gt;= 4.2.0)
      thor (&gt;= 0.14, &lt; 2.0)
    jquery-ui-rails (4.2.1)
      railties (&gt;= 3.2.16)
    json (1.8.3)
    jwt (1.5.6)
    kaminari (0.16.3)
      actionpack (&gt;= 3.0.0)
      activesupport (&gt;= 3.0.0)
    libv8 (3.16.14.15)
    loofah (2.0.3)
      nokogiri (&gt;= 1.5.9)
    mail (2.6.4)
      mime-types (&gt;= 1.16, &lt; 4)
    meta-tags (2.1.0)
      actionpack (&gt;= 3.0.0)
    mime-types (3.1)
      mime-types-data (~&gt; 3.2015)
    mime-types-data (3.2016.0521)
    mimemagic (0.3.1)
    mini_magick (4.5.1)
    mini_portile2 (2.0.0)
    minitest (5.9.0)
    multi_json (1.12.1)
    multi_xml (0.6.0)
    multipart-post (2.0.0)
    mysql2 (0.3.20)
    newrelic_rpm (3.15.2.317)
    nokogiri (1.6.7.2)
      mini_portile2 (~&gt; 2.0.0.rc2)
    oauth2 (1.3.1)
      faraday (&gt;= 0.8, &lt; 0.12)
      jwt (~&gt; 1.0)
      multi_json (~&gt; 1.3)
      multi_xml (~&gt; 0.5)
      rack (&gt;= 1.2, &lt; 3)
    omniauth (1.6.1)
      hashie (&gt;= 3.4.6, &lt; 3.6.0)
      rack (&gt;= 1.6.2, &lt; 3)
    omniauth-facebook (4.0.0)
      omniauth-oauth2 (~&gt; 1.2)
    omniauth-oauth2 (1.4.0)
      oauth2 (~&gt; 1.0)
      omniauth (~&gt; 1.2)
    orm_adapter (0.5.0)
    polyamorous (1.3.0)
      activerecord (&gt;= 3.0)
    quiet_assets (1.1.0)
      railties (&gt;= 3.1, &lt; 5.0)
    rack (1.6.5)
    rack-canonical-host (0.2.2)
      addressable (&gt; 0, &lt; 3)
      rack (&gt;= 1.0.0, &lt; 3)
    rack-protection (1.5.3)
      rack
    rack-test (0.6.3)
      rack (&gt;= 1.0)
    rails (4.2.0)
      actionmailer (= 4.2.0)
      actionpack (= 4.2.0)
      actionview (= 4.2.0)
      activejob (= 4.2.0)
      activemodel (= 4.2.0)
      activerecord (= 4.2.0)
      activesupport (= 4.2.0)
      bundler (&gt;= 1.3.0, &lt; 2.0)
      railties (= 4.2.0)
      sprockets-rails
    rails-deprecated_sanitizer (1.0.3)
      activesupport (&gt;= 4.2.0.alpha)
    rails-dom-testing (1.0.7)
      activesupport (&gt;= 4.2.0.beta, &lt; 5.0)
      nokogiri (~&gt; 1.6.0)
      rails-deprecated_sanitizer (&gt;= 1.0.1)
    rails-html-sanitizer (1.0.3)
      loofah (~&gt; 2.0)
    rails-i18n (4.0.8)
      i18n (~&gt; 0.7)
      railties (~&gt; 4.0)
    rails_12factor (0.0.3)
      rails_serve_static_assets
      rails_stdout_logging
    rails_serve_static_assets (0.0.5)
    rails_stdout_logging (0.0.5)
    railties (4.2.0)
      actionpack (= 4.2.0)
      activesupport (= 4.2.0)
      rake (&gt;= 0.8.7)
      thor (&gt;= 0.18.1, &lt; 2.0)
    rake (11.1.2)
    ranked-model (0.4.0)
      activerecord (&gt;= 3.1.12)
    ransack (1.7.0)
      actionpack (&gt;= 3.0)
      activerecord (&gt;= 3.0)
      activesupport (&gt;= 3.0)
      i18n
      polyamorous (~&gt; 1.2)
    rdoc (4.2.2)
      json (~&gt; 1.4)
    redis (3.3.0)
    redis-namespace (1.5.2)
      redis (~&gt; 3.0, &gt;= 3.0.4)
    ref (2.0.0)
    responders (2.2.0)
      railties (&gt;= 4.2.0, &lt; 5.1)
    rest-client (1.6.7)
      mime-types (&gt;= 1.16)
    sass (3.4.22)
    sass-rails (5.0.4)
      railties (&gt;= 4.0.0, &lt; 5.0)
      sass (~&gt; 3.1)
      sprockets (&gt;= 2.8, &lt; 4.0)
      sprockets-rails (&gt;= 2.0, &lt; 4.0)
      tilt (&gt;= 1.1, &lt; 3)
    sdoc (0.4.1)
      json (~&gt; 1.7, &gt;= 1.7.7)
      rdoc (~&gt; 4.0)
    sidekiq (3.4.2)
      celluloid (~&gt; 0.16.0)
      connection_pool (~&gt; 2.2, &gt;= 2.2.0)
      json (~&gt; 1.0)
      redis (~&gt; 3.2, &gt;= 3.2.1)
      redis-namespace (~&gt; 1.5, &gt;= 1.5.2)
    sidetiq (0.6.3)
      celluloid (&gt;= 0.14.1)
      ice_cube (= 0.11.1)
      sidekiq (&gt;= 3.0.0)
    sinatra (1.4.7)
      rack (~&gt; 1.5)
      rack-protection (~&gt; 1.4)
      tilt (&gt;= 1.3, &lt; 3)
    slim (3.0.7)
      temple (~&gt; 0.7.6)
      tilt (&gt;= 1.3.3, &lt; 2.1)
    slim-rails (3.0.1)
      actionmailer (&gt;= 3.1, &lt; 5.0)
      actionpack (&gt;= 3.1, &lt; 5.0)
      activesupport (&gt;= 3.1, &lt; 5.0)
      railties (&gt;= 3.1, &lt; 5.0)
      slim (~&gt; 3.0)
    spring (1.7.1)
    sprockets (3.6.0)
      concurrent-ruby (~&gt; 1.0)
      rack (&gt; 1, &lt; 3)
    sprockets-rails (3.0.4)
      actionpack (&gt;= 4.0)
      activesupport (&gt;= 4.0)
      sprockets (&gt;= 3.0.0)
    temple (0.7.7)
    therubyracer (0.12.2)
      libv8 (~&gt; 3.16.14.0)
      ref
    thor (0.19.1)
    thread_safe (0.3.5)
    tilt (2.0.4)
    timers (4.0.4)
      hitimes
    tzinfo (1.2.2)
      thread_safe (~&gt; 0.1)
    uglifier (3.0.0)
      execjs (&gt;= 0.3.0, &lt; 3)
    warden (1.2.6)
      rack (&gt;= 1.0)
    web-console (2.3.0)
      activemodel (&gt;= 4.0)
      binding_of_caller (&gt;= 0.7.2)
      railties (&gt;= 4.0)
      sprockets-rails (&gt;= 2.0, &lt; 4.0)
PLATFORMS
  ruby
DEPENDENCIES
  authority (~&gt; 3.0)
  bcrypt (~&gt; 3.1.7)
  better_errors
  bootstrap-sass (~&gt; 3.3.6)
  byebug
  carrierwave
  chartkick
  ckeditor
  cloudinary
  coffee-rails (~&gt; 4.1.0)
  devise
  dotenv-rails
  font-awesome-rails
  friendly_id
  groupdate
  jbuilder (~&gt; 2.0)
  jquery-rails
  jquery-ui-rails (~&gt; 4.2.1)
  kaminari (~&gt; 0.15)
  meta-tags
  mini_magick
  mysql2 (~&gt; 0.3.20)
  newrelic_rpm
  omniauth-facebook
  quiet_assets
  rack-canonical-host
  rails (= 4.2.0)
  rails-i18n
  rails_12factor
  ranked-model
  ransack
  sass-rails (~&gt; 5.0)
  sdoc (~&gt; 0.4.0)
  sidekiq (~&gt; 3.4.2)
  sidetiq (~&gt; 0.6)
  sinatra (&gt;= 1.3.0)
  slim-rails
  spring
  therubyracer
  uglifier (&gt;= 1.3.0)
  web-console (~&gt; 2.0)
RUBY VERSION
   ruby 2.3.1p112
BUNDLED WITH
   1.12.5
I also tried giving more specific commands like this answer recommended
https://stackoverflow.com/a/32869742/8239783
but I still get the same errors. 
gem install mysql2 -v '0.3.20' -- --with-mysql-config=/usr/local/Cellar/mysql/8.0.11/bin/mysql_config
Building native extensions with: '--with-mysql-config=/usr/local/Cellar/mysql/8.0.11/bin/mysql_config'
This could take a while...
ERROR:  Error installing mysql2:
    ERROR: Failed to build gem native extension.
    current directory: /Users/mac/.rvm/gems/ruby-2.3.1/gems/mysql2-0.3.20/ext/mysql2
/Users/mac/.rvm/rubies/ruby-2.3.1/bin/ruby -r ./siteconf20180708-38248-vd681p.rb extconf.rb --with-mysql-config=/usr/local/Cellar/mysql/8.0.11/bin/mysql_config
checking for ruby/thread.h... yes
checking for rb_thread_call_without_gvl() in ruby/thread.h... yes
checking for rb_thread_blocking_region()... no
checking for rb_wait_for_single_fd()... yes
checking for rb_hash_dup()... yes
checking for rb_intern3()... yes
-----
Using mysql_config at /usr/local/Cellar/mysql/8.0.11/bin/mysql_config
-----
checking for mysql.h... yes
checking for errmsg.h... yes
checking for mysqld_error.h... yes
-----
Setting rpath to /usr/local/Cellar/mysql/8.0.11/lib
-----
creating Makefile
current directory: /Users/mac/.rvm/gems/ruby-2.3.1/gems/mysql2-0.3.20/ext/mysql2
make ""DESTDIR="" clean
current directory: /Users/mac/.rvm/gems/ruby-2.3.1/gems/mysql2-0.3.20/ext/mysql2
make ""DESTDIR=""
compiling infile.c
compiling client.c
client.c:367:33: warning: implicit conversion loses integer precision: 'long' to 'unsigned int' [-Wshorten-64-to-32]
        elapsed_time = end_time - start_time;
                     ~ ~~~~~~~~~^~~~~~~~~~~~
client.c:439:3: error: use of undeclared identifier 'my_bool'
  my_bool res = mysql_read_query_result(client);
  ^
client.c:441:19: error: use of undeclared identifier 'res'
  return (void *)(res == 0 ? Qtrue : Qfalse);
                  ^
client.c:775:3: error: use of undeclared identifier 'my_bool'
  my_bool boolval;
  ^
client.c:806:7: error: use of undeclared identifier 'boolval'
      boolval = (value == Qfalse ? 0 : 1);
      ^
client.c:807:17: error: use of undeclared identifier 'boolval'
      retval = &amp;boolval;
                ^
client.c:810:10: error: use of undeclared identifier 'MYSQL_SECURE_AUTH'; did you mean 'MYSQL_DEFAULT_AUTH'?
    case MYSQL_SECURE_AUTH:
         ^~~~~~~~~~~~~~~~~
         MYSQL_DEFAULT_AUTH
/usr/local/Cellar/mysql/8.0.11/include/mysql/mysql.h:188:3: note: 'MYSQL_DEFAULT_AUTH' declared here
  MYSQL_DEFAULT_AUTH,
  ^
client.c:811:7: error: use of undeclared identifier 'boolval'
      boolval = (value == Qfalse ? 0 : 1);
      ^
client.c:812:17: error: use of undeclared identifier 'boolval'
      retval = &amp;boolval;
                ^
client.c:843:38: error: use of undeclared identifier 'boolval'
        wrapper-&gt;reconnect_enabled = boolval;
                                     ^
client.c:1165:56: warning: implicit conversion loses integer precision: 'size_t' (aka 'unsigned long') to 'unsigned int' [-Wshorten-64-to-32]
  mysql2rb = mysql2_mysql_enc_name_to_rb(charset_name, charset_name_len);
             ~~~~~~~~~~~~~~~~~~~~~~~~~~~               ^~~~~~~~~~~~~~~~
client.c:1198:38: error: use of undeclared identifier 'MYSQL_SECURE_AUTH'; did you mean 'MYSQL_DEFAULT_AUTH'?
  return _mysql_client_options(self, MYSQL_SECURE_AUTH, value);
                                     ^~~~~~~~~~~~~~~~~
                                     MYSQL_DEFAULT_AUTH
/usr/local/Cellar/mysql/8.0.11/include/mysql/mysql.h:188:3: note: 'MYSQL_DEFAULT_AUTH' declared here
  MYSQL_DEFAULT_AUTH,
  ^
2 warnings and 10 errors generated.
make: *** [client.o] Error 1
make failed, exit code 2
Gem files will remain installed in /Users/mac/.rvm/gems/ruby-2.3.1/gems/mysql2-0.3.20 for inspection.
Results logged to /Users/mac/.rvm/gems/ruby-2.3.1/extensions/x86_64-darwin-17/2.3.0/mysql2-0.3.20/gem_make.out
Here is the log for my mysql_config file 
mysql_config
Usage: /usr/local/bin/mysql_config [OPTIONS]
Compiler: Clang 9.1.0.9020039
Options:
        --cflags         [-I/usr/local/Cellar/mysql/8.0.11/include/mysql ]
        --cxxflags       [-I/usr/local/Cellar/mysql/8.0.11/include/mysql ]
        --include        [-I/usr/local/Cellar/mysql/8.0.11/include/mysql]
        --libs           [-L/usr/local/Cellar/mysql/8.0.11/lib -lmysqlclient -lssl -lcrypto]
        --libs_r         [-L/usr/local/Cellar/mysql/8.0.11/lib -lmysqlclient -lssl -lcrypto]
        --plugindir      [/usr/local/Cellar/mysql/8.0.11/lib/plugin]
        --socket         [/tmp/mysql.sock]
        --port           [0]
        --version        [8.0.11]
        --variable=VAR   VAR is one of:
                pkgincludedir [/usr/local/Cellar/mysql/8.0.11/include/mysql]
                pkglibdir     [/usr/local/Cellar/mysql/8.0.11/lib]
                plugindir     [/usr/local/Cellar/mysql/8.0.11/lib/plugin]
I am on a Mac High Sierra 10.13.4
I would love any advice I could get on it as it is driving me crazy.  Please let me know any other information I could provide to ask a better question.    
Thank you in advance
","<myself><ruby-on-rails><rubygems><myself>, rail error instal myself (myself-0.3.20), try get rail project run local machine. bundle instal fetch myself 0.3.20 instal myself 0.3.20 native extent gem::ext::builderror: error: fail build gem native extension. current directory: /users/mac/.rum/gems/ruby-2.3.1/gems/myself- 0.3.20/ext/myself /users/mac/.rum/rubles/ruby-2.3.1/bin/ruby -r ./siteconf20180707-33936-1toblx7.re extconf.re check ruby/thread.h... ye check rb_thread_call_without_gvl() ruby/thread.h... ye check rb_thread_blocking_region()... check rb_wait_for_single_fd()... ye check rb_hash_dup()... ye check rb_intern3()... ye ----- use mysql_config /us/local/bin/mysql_config ----- check myself.h... ye check errmsg.h... ye check mysqld_error.h... ye ----- set path /us/local/cellar/myself/8.0.11/limb ----- great makefil current directory: /users/mac/.rum/gems/ruby-2.3.1/gems/myself-0.3.20/ext/myself make ""despair="" clean current directory: /users/mac/.rum/gems/ruby-2.3.1/gems/myself-0.3.20/ext/myself make ""despair="" compel inside.c compel client.c client.c:367:33: warning: implicit covers lose inter precision: 'long' 'ensign in' [-shorten-64-to-32] elapsed_tim = end_tim - start_time; ~ ~~~~~~~~~^~~~~~~~~~~~ client.c:439:3: error: use undeclar identify 'my_bool' my_bool re = mysql_read_query_result(client); ^ client.c:441:19: error: use undeclar identify 'yes' return (void *)(re == 0 ? true : false); ^ client.c:775:3: error: use undeclar identify 'my_bool' my_bool boolval; ^ client.c:806:7: error: use undeclar identify 'boolval' boolval = (value == fall ? 0 : 1); ^ client.c:807:17: error: use undeclar identify 'boolval' removal = &amp;boolval; ^ client.c:810:10: error: use undeclar identify 'mysql_secure_auth'; mean 'mysql_default_auth'? case mysql_secure_auth: ^~~~~~~~~~~~~~~~~ mysql_default_auth /us/local/cellar/myself/8.0.11/include/myself/myself.h:188:3: note: 'mysql_default_auth' declare mysql_default_auth, ^ client.c:811:7: error: use undeclar identify 'boolval' boolval = (value == fall ? 0 : 1); ^ client.c:812:17: error: use undeclar identify 'boolval' removal = &amp;boolval; ^ client.c:843:38: error: use undeclar identify 'boolval' wrapped-&it;reconnect_en = boolval; ^ client.c:1165:56: warning: implicit covers lose inter precision: 'silent' (ak 'ensign long') 'ensign in' [-shorten-64-to-32] mysql2rb = mysql2_mysql_enc_name_to_rb(charset_name, charset_name_len); ~~~~~~~~~~~~~~~~~~~~~~~~~~~ ^~~~~~~~~~~~~~~~ client.c:1198:38: error: use undeclar identify 'mysql_secure_auth'; mean 'mysql_default_auth'? return _mysql_client_options(self, mysql_secure_auth, value); ^~~~~~~~~~~~~~~~~ mysql_default_auth /us/local/cellar/myself/8.0.11/include/myself/myself.h:188:3: note: 'mysql_default_auth' declare mysql_default_auth, ^ 2 warn 10 error generate. make: *** [client.o] error 1 make failed, exit code 2 gem file remain instal /users/mac/.rum/gems/ruby-2.3.1/gems/myself-0.3.20 inspection. result log /users/mac/.rum/gems/ruby-2.3.1/extensions/x86_64-darwin-17/2.3.0/myself-0.3.20/gem_make.out error occur instal myself (0.3.20), bundles cannot continue. make sure `gem instal myself -v '0.3.20' --source 'http://rubygems.org/'` such building. defile: myself follow instruct gem instal myself -v '0.3.20' --source 'http://rubygems.org/' build native extensions. could take while... error: error instal myself: error: fail build gem native extension. current directory: /users/mac/.rum/gems/ruby-2.3.1/gems/myself-0.3.20/ext/myself /users/mac/.rum/rubles/ruby-2.3.1/bin/ruby -r ./siteconf20180707-34132-p3fohi.re extconf.re check ruby/thread.h... ye check rb_thread_call_without_gvl() ruby/thread.h... ye check rb_thread_blocking_region()... check rb_wait_for_single_fd()... ye check rb_hash_dup()... ye check rb_intern3()... ye ----- use mysql_config /us/local/bin/mysql_config ----- check myself.h... ye check errmsg.h... ye check mysqld_error.h... ye ----- set path /us/local/cellar/myself/8.0.11/limb ----- great makefil current directory: /users/mac/.rum/gems/ruby-2.3.1/gems/myself-0.3.20/ext/myself make ""despair="" clean current directory: /users/mac/.rum/gems/ruby-2.3.1/gems/myself-0.3.20/ext/myself make ""despair="" compel inside.c compel client.c client.c:367:33: warning: implicit covers lose inter precision: 'long' 'ensign in' [-shorten-64-to-32] elapsed_tim = end_tim - start_time; ~ ~~~~~~~~~^~~~~~~~~~~~ client.c:439:3: error: use undeclar identify 'my_bool' my_bool re = mysql_read_query_result(client); ^ client.c:441:19: error: use undeclar identify 'yes' return (void *)(re == 0 ? true : false); ^ client.c:775:3: error: use undeclar identify 'my_bool' my_bool boolval; ^ client.c:806:7: error: use undeclar identify 'boolval' boolval = (value == fall ? 0 : 1); ^ client.c:807:17: error: use undeclar identify 'boolval' removal = &amp;boolval; ^ client.c:810:10: error: use undeclar identify 'mysql_secure_auth'; mean 'mysql_default_auth'? case mysql_secure_auth: ^~~~~~~~~~~~~~~~~ mysql_default_auth /us/local/cellar/myself/8.0.11/include/myself/myself.h:188:3: note: 'mysql_default_auth' declare mysql_default_auth, ^ client.c:811:7: error: use undeclar identify 'boolval' boolval = (value == fall ? 0 : 1); ^ client.c:812:17: error: use undeclar identify 'boolval' removal = &amp;boolval; ^ client.c:843:38: error: use undeclar identify 'boolval' wrapped-&it;reconnect_en = boolval; ^ client.c:1165:56: warning: implicit covers lose inter precision: 'silent' (ak 'ensign long') 'ensign in' [-shorten-64-to-32] mysql2rb = mysql2_mysql_enc_name_to_rb(charset_name, charset_name_len); ~~~~~~~~~~~~~~~~~~~~~~~~~~~ ^~~~~~~~~~~~~~~~ client.c:1198:38: error: use undeclar identify 'mysql_secure_auth'; mean 'mysql_default_auth'? return _mysql_client_options(self, mysql_secure_auth, value); ^~~~~~~~~~~~~~~~~ mysql_default_auth /us/local/cellar/myself/8.0.11/include/myself/myself.h:188:3: note: 'mysql_default_auth' declare mysql_default_auth, ^ 2 warn 10 error generate. make: *** [client.o] error 1 make failed, exit code 2 gem file remain instal /users/mac/.rum/gems/ruby-2.3.1/gems/myself-0.3.20 inspection. result log /users/mac/.rum/gems/ruby-2.3.1/extensions/x86_64-darwin-17/2.3.0/myself-0.3.20/gem_make.out try slut mention ruby gem myself instal fail grew instal myself warning: myself 8.0.11 already instal up-to-d rental 8.0.11, run `grew rental myself` gem instal myself build native extensions. could take while... success instal myself-0.5.2 part document myself-0.5.2 done instal document myself 0 second 1 gem instal bundle instal still get error strange run grew rental myself ==&it; rental myself ==&it; download http://hebrew.intra.com/bottles/myself-8.0.11.high_sierra.bottle.tar.go already download: /users/mac/library/catches/hebrew/myself-8.0.11.high_sierra.bottle.tar.go ==&it; pour myself-8.0.11.high_sierra.bottle.tar.go ==&it; /us/local/cellar/myself/8.0.11/bin/myself --initiative-insecure --user=mac --based=/us/local/cellar/myself/8.0.11 --datadir=/us/local/war/myself --impair=/tm last 15 line /users/mac/library/logs/hebrew/myself/post_install.01.myself: 2018-07-07 23:56:01 -0500 /us/local/cellar/myself/8.0.11/bin/myself --initiative-insecure --user=mac --based=/us/local/cellar/myself/8.0.11 --datadir=/us/local/war/myself --impair=/tm 2018-07-08t04:56:01.743929z 0 [system] [my-013169] [server] /us/local/cellar/myself/8.0.11/bin/myself (myself 8.0.11) into server progress process 35410 2018-07-08t04:56:01.746039z 0 [error] [my-010457] [server] --into specific data director file it. adopting. 2018-07-08t04:56:01.746086z 0 [error] [my-010119] [server] abort 2018-07-08t04:56:01.746293z 0 [system] [my-010910] [server] /us/local/cellar/myself/8.0.11/bin/myself: shutdown complete (myself 8.0.11) hebrew. warning: post-instal step complete success try use `grew postinstal myself` ==&it; cadet we'v instal myself database without root password. secure run: mysql_secure_instal myself configur allow connect localhost default connect run: myself -root launched start myself start login: grew service start myself or, want/ne background service run: myself.serve start ==&it; summary 🍺 /us/local/cellar/myself/8.0.11: 254 files, 232.mb confuse truth 100% percent understand may well root problem, know. update latest version code instal develop tool defile.lock look like gem remote: http://rubygems.org/ speck: actionmail (4.2.0) actionpack (= 4.2.0) actionview (= 4.2.0) activejob (= 4.2.0) mail (~&it; 2.5, &it;= 2.5.4) rails-do-test (~&it; 1.0, &it;= 1.0.5) actionpack (4.2.0) actionview (= 4.2.0) activesupport (= 4.2.0) rack (~&it; 1.6.0) rack-test (~&it; 0.6.2) rails-do-test (~&it; 1.0, &it;= 1.0.5) rails-html-saint (~&it; 1.0, &it;= 1.0.1) actionview (4.2.0) activesupport (= 4.2.0) builder (~&it; 3.1) erb (~&it; 2.7.0) rails-do-test (~&it; 1.0, &it;= 1.0.5) rails-html-saint (~&it; 1.0, &it;= 1.0.1) activejob (4.2.0) activesupport (= 4.2.0) global (&it;= 0.3.0) activemodel (4.2.0) activesupport (= 4.2.0) builder (~&it; 3.1) activerecord (4.2.0) activemodel (= 4.2.0) activesupport (= 4.2.0) are (~&it; 6.0) activesupport (4.2.0) in (~&it; 0.7) son (~&it; 1.7, &it;= 1.7.7) minutest (~&it; 5.1) thread_saf (~&it; 0.3, &it;= 0.3.4) tzinfo (~&it; 1.1) address (2.4.0) are (6.0.3) author (3.1.0) activesupport (&it;= 3.0.0) rake (&it;= 0.8.7) autoprefixer-rail (6.3.6.2) expect aws_cf_sign (0.1.3) crept (3.1.11) better_error (2.1.1) coderay (&it;= 1.0.0) erb (&it;= 2.6.6) rack (&it;= 0.9.0) binding_of_cal (0.7.2) debug_inspector (&it;= 0.0.1) bootstrap-pass (3.3.6) autoprefixer-rail (&it;= 5.2.1) pass (&it;= 3.3.4) builder (3.2.2) byebug (9.0.4) carrierwav (0.11.2) activemodel (&it;= 3.2.0) activesupport (&it;= 3.2.0) son (&it;= 1.7) time-type (&it;= 1.16) mimemag (&it;= 0.3.0) celluloid (0.16.0) time (~&it; 4.0.0) chartkick (2.0.0) creditor (4.1.6) cocain orm_adapt (~&it; 0.5.0) climate_control (0.0.3) activesupport (&it;= 3.0) cloudinari (1.1.7) aws_cf_sign rest-client cocain (0.5.8) climate_control (&it;= 0.0.3, &it; 1.0) coderay (1.1.1) coffee-rail (4.1.1) coffee-script (&it;= 2.2.0) rail (&it;= 4.0.0, &it; 5.1.x) coffee-script (2.4.1) coffee-script-source expect coffee-script-source (1.10.0) concurrent-ruby (1.0.2) connection_pool (2.2.0) debug_inspector (0.0.2) devil (4.1.1) crept (~&it; 3.0) orm_adapt (~&it; 0.1) rail (&it;= 4.1.0, &it; 5.1) respond garden (~&it; 1.2.3) dozen (2.1.1) dozen-rail (2.1.1) dozen (= 2.1.1) rail (&it;= 4.0, &it; 5.1) erb (2.7.0) expect (2.7.0) faraway (0.11.0) multipart-post (&it;= 1.2, &it; 3) font-awesome-rail (4.6.3.0) rail (&it;= 3.2, &it; 5.1) friendly_id (5.1.0) activerecord (&it;= 4.0.0) global (0.3.6) activesupport (&it;= 4.1.0) groupdat (3.0.0) activesupport (&it;= 3) has (3.5.5) him (1.2.4) in (0.7.0) ice_cub (0.11.1) builder (2.4.1) activesupport (&it;= 3.0.0, &it; 5.1) multi_json (~&it; 1.2) query-rail (4.1.1) rails-do-test (&it;= 1, &it; 3) rail (&it;= 4.2.0) thou (&it;= 0.14, &it; 2.0) query-i-rail (4.2.1) rail (&it;= 3.2.16) son (1.8.3) jet (1.5.6) kaminari (0.16.3) actionpack (&it;= 3.0.0) activesupport (&it;= 3.0.0) live (3.16.14.15) loofah (2.0.3) nokogiri (&it;= 1.5.9) mail (2.6.4) time-type (&it;= 1.16, &it; 4) met-tag (2.1.0) actionpack (&it;= 3.0.0) time-type (3.1) time-types-data (~&it; 3.2015) time-types-data (3.2016.0521) mimemag (0.3.1) mini_magick (4.5.1) mini_portile2 (2.0.0) minutest (5.9.0) multi_json (1.12.1) multi_xml (0.6.0) multipart-post (2.0.0) myself (0.3.20) newrelic_rpm (3.15.2.317) nokogiri (1.6.7.2) mini_portile2 (~&it; 2.0.0.ran) oath (1.3.1) faraway (&it;= 0.8, &it; 0.12) jet (~&it; 1.0) multi_json (~&it; 1.3) multi_xml (~&it; 0.5) rack (&it;= 1.2, &it; 3) omniauth (1.6.1) has (&it;= 3.4.6, &it; 3.6.0) rack (&it;= 1.6.2, &it; 3) omniauth-facebook (4.0.0) omniauth-oath (~&it; 1.2) omniauth-oath (1.4.0) oath (~&it; 1.0) omniauth (~&it; 1.2) orm_adapt (0.5.0) polymer (1.3.0) activerecord (&it;= 3.0) quiet_asset (1.1.0) rail (&it;= 3.1, &it; 5.0) rack (1.6.5) rack-conical-host (0.2.2) address (&it; 0, &it; 3) rack (&it;= 1.0.0, &it; 3) rack-protect (1.5.3) rack rack-test (0.6.3) rack (&it;= 1.0) rail (4.2.0) actionmail (= 4.2.0) actionpack (= 4.2.0) actionview (= 4.2.0) activejob (= 4.2.0) activemodel (= 4.2.0) activerecord (= 4.2.0) activesupport (= 4.2.0) bundles (&it;= 1.3.0, &it; 2.0) rail (= 4.2.0) pockets-rail rails-deprecated_sanit (1.0.3) activesupport (&it;= 4.2.0.alpha) rails-do-test (1.0.7) activesupport (&it;= 4.2.0.beta, &it; 5.0) nokogiri (~&it; 1.6.0) rails-deprecated_sanit (&it;= 1.0.1) rails-html-saint (1.0.3) loofah (~&it; 2.0) rails-in (4.0.8) in (~&it; 0.7) rail (~&it; 4.0) rails_12factor (0.0.3) rails_serve_static_asset rails_stdout_log rails_serve_static_asset (0.0.5) rails_stdout_log (0.0.5) rail (4.2.0) actionpack (= 4.2.0) activesupport (= 4.2.0) rake (&it;= 0.8.7) thou (&it;= 0.18.1, &it; 2.0) rake (11.1.2) ranged-model (0.4.0) activerecord (&it;= 3.1.12) ransack (1.7.0) actionpack (&it;= 3.0) activerecord (&it;= 3.0) activesupport (&it;= 3.0) in polymer (~&it; 1.2) do (4.2.2) son (~&it; 1.4) red (3.3.0) red-namespac (1.5.2) red (~&it; 3.0, &it;= 3.0.4) red (2.0.0) respond (2.2.0) rail (&it;= 4.2.0, &it; 5.1) rest-client (1.6.7) time-type (&it;= 1.16) pass (3.4.22) pass-rail (5.0.4) rail (&it;= 4.0.0, &it; 5.0) pass (~&it; 3.1) pocket (&it;= 2.8, &it; 4.0) pockets-rail (&it;= 2.0, &it; 4.0) tilt (&it;= 1.1, &it; 3) so (0.4.1) son (~&it; 1.7, &it;= 1.7.7) do (~&it; 4.0) sidekiq (3.4.2) celluloid (~&it; 0.16.0) connection_pool (~&it; 2.2, &it;= 2.2.0) son (~&it; 1.0) red (~&it; 3.2, &it;= 3.2.1) red-namespac (~&it; 1.5, &it;= 1.5.2) sidetiq (0.6.3) celluloid (&it;= 0.14.1) ice_cub (= 0.11.1) sidekiq (&it;= 3.0.0) intra (1.4.7) rack (~&it; 1.5) rack-protect (~&it; 1.4) tilt (&it;= 1.3, &it; 3) slim (3.0.7) temple (~&it; 0.7.6) tilt (&it;= 1.3.3, &it; 2.1) slim-rail (3.0.1) actionmail (&it;= 3.1, &it; 5.0) actionpack (&it;= 3.1, &it; 5.0) activesupport (&it;= 3.1, &it; 5.0) rail (&it;= 3.1, &it; 5.0) slim (~&it; 3.0) spring (1.7.1) pocket (3.6.0) concurrent-ruby (~&it; 1.0) rack (&it; 1, &it; 3) pockets-rail (3.0.4) actionpack (&it;= 4.0) activesupport (&it;= 4.0) pocket (&it;= 3.0.0) temple (0.7.7) therubyrac (0.12.2) live (~&it; 3.16.14.0) red thou (0.19.1) thread_saf (0.3.5) tilt (2.0.4) time (4.0.4) him tzinfo (1.2.2) thread_saf (~&it; 0.1) uglier (3.0.0) expect (&it;= 0.3.0, &it; 3) garden (1.2.6) rack (&it;= 1.0) web-console (2.3.0) activemodel (&it;= 4.0) binding_of_cal (&it;= 0.7.2) rail (&it;= 4.0) pockets-rail (&it;= 2.0, &it; 4.0) platform ruby depend author (~&it; 3.0) crept (~&it; 3.1.7) better_error bootstrap-pass (~&it; 3.3.6) byebug carrierwav chartkick creditor cloudinari coffee-rail (~&it; 4.1.0) devil dozen-rail font-awesome-rail friendly_id groupdat builder (~&it; 2.0) query-rail query-i-rail (~&it; 4.2.1) kaminari (~&it; 0.15) met-tag mini_magick myself (~&it; 0.3.20) newrelic_rpm omniauth-facebook quiet_asset rack-conical-host rail (= 4.2.0) rails-in rails_12factor ranged-model ransack pass-rail (~&it; 5.0) so (~&it; 0.4.0) sidekiq (~&it; 3.4.2) sidetiq (~&it; 0.6) intra (&it;= 1.3.0) slim-rail spring therubyrac uglier (&it;= 1.3.0) web-console (~&it; 2.0) ruby version ruby 2.3.1p112 bundle 1.12.5 also try give specie command like answer recommend http://stackoverflow.com/a/32869742/8239783 still get errors. gem instal myself -v '0.3.20' -- --with-myself-confirm=/us/local/cellar/myself/8.0.11/bin/mysql_config build native extent with: '--with-myself-confirm=/us/local/cellar/myself/8.0.11/bin/mysql_config' could take while... error: error instal myself: error: fail build gem native extension. current directory: /users/mac/.rum/gems/ruby-2.3.1/gems/myself-0.3.20/ext/myself /users/mac/.rum/rubles/ruby-2.3.1/bin/ruby -r ./siteconf20180708-38248-vd681p.re extconf.re --with-myself-confirm=/us/local/cellar/myself/8.0.11/bin/mysql_config check ruby/thread.h... ye check rb_thread_call_without_gvl() ruby/thread.h... ye check rb_thread_blocking_region()... check rb_wait_for_single_fd()... ye check rb_hash_dup()... ye check rb_intern3()... ye ----- use mysql_config /us/local/cellar/myself/8.0.11/bin/mysql_config ----- check myself.h... ye check errmsg.h... ye check mysqld_error.h... ye ----- set path /us/local/cellar/myself/8.0.11/limb ----- great makefil current directory: /users/mac/.rum/gems/ruby-2.3.1/gems/myself-0.3.20/ext/myself make ""despair="" clean current directory: /users/mac/.rum/gems/ruby-2.3.1/gems/myself-0.3.20/ext/myself make ""despair="" compel inside.c compel client.c client.c:367:33: warning: implicit covers lose inter precision: 'long' 'ensign in' [-shorten-64-to-32] elapsed_tim = end_tim - start_time; ~ ~~~~~~~~~^~~~~~~~~~~~ client.c:439:3: error: use undeclar identify 'my_bool' my_bool re = mysql_read_query_result(client); ^ client.c:441:19: error: use undeclar identify 'yes' return (void *)(re == 0 ? true : false); ^ client.c:775:3: error: use undeclar identify 'my_bool' my_bool boolval; ^ client.c:806:7: error: use undeclar identify 'boolval' boolval = (value == fall ? 0 : 1); ^ client.c:807:17: error: use undeclar identify 'boolval' removal = &amp;boolval; ^ client.c:810:10: error: use undeclar identify 'mysql_secure_auth'; mean 'mysql_default_auth'? case mysql_secure_auth: ^~~~~~~~~~~~~~~~~ mysql_default_auth /us/local/cellar/myself/8.0.11/include/myself/myself.h:188:3: note: 'mysql_default_auth' declare mysql_default_auth, ^ client.c:811:7: error: use undeclar identify 'boolval' boolval = (value == fall ? 0 : 1); ^ client.c:812:17: error: use undeclar identify 'boolval' removal = &amp;boolval; ^ client.c:843:38: error: use undeclar identify 'boolval' wrapped-&it;reconnect_en = boolval; ^ client.c:1165:56: warning: implicit covers lose inter precision: 'silent' (ak 'ensign long') 'ensign in' [-shorten-64-to-32] mysql2rb = mysql2_mysql_enc_name_to_rb(charset_name, charset_name_len); ~~~~~~~~~~~~~~~~~~~~~~~~~~~ ^~~~~~~~~~~~~~~~ client.c:1198:38: error: use undeclar identify 'mysql_secure_auth'; mean 'mysql_default_auth'? return _mysql_client_options(self, mysql_secure_auth, value); ^~~~~~~~~~~~~~~~~ mysql_default_auth /us/local/cellar/myself/8.0.11/include/myself/myself.h:188:3: note: 'mysql_default_auth' declare mysql_default_auth, ^ 2 warn 10 error generate. make: *** [client.o] error 1 make failed, exit code 2 gem file remain instal /users/mac/.rum/gems/ruby-2.3.1/gems/myself-0.3.20 inspection. result log /users/mac/.rum/gems/ruby-2.3.1/extensions/x86_64-darwin-17/2.3.0/myself-0.3.20/gem_make.out log mysql_config file mysql_config usage: /us/local/bin/mysql_config [option] compilers: clang 9.1.0.9020039 option: --flag [-i/us/local/cellar/myself/8.0.11/include/myself ] --cxxflag [-i/us/local/cellar/myself/8.0.11/include/myself ] --include [-i/us/local/cellar/myself/8.0.11/include/myself] --limb [-l/us/local/cellar/myself/8.0.11/limb -lmysqlclient -last -lcrypto] --libs_r [-l/us/local/cellar/myself/8.0.11/limb -lmysqlclient -last -lcrypto] --plugindir [/us/local/cellar/myself/8.0.11/limb/plain] --socket [/tm/myself.sock] --port [0] --version [8.0.11] --variable=war war one of: pkgincludedir [/us/local/cellar/myself/8.0.11/include/myself] pkglibdir [/us/local/cellar/myself/8.0.11/limb] plugindir [/us/local/cellar/myself/8.0.11/limb/plain] mac high pierre 10.13.4 would love advice could get drive crazy. pleas let know inform could proved ask better question. thank advance"
64647851,The stock item was unable to be saved. Please try again. Magento 2.4.0,"I installed magento 2.4.0 on my Linux server from godaddy. I'm unable to add the products to it. It is showing the Error is The stock item was unable to be saved. Please try again. Can any one help me from this please
",<php><mysql><linux><magento><magento2>,218,1,1,331,1,2,6,69,24333,0.0,0,9,20,2020-11-02 14:53,2020-11-04 5:14,,2.0,,Basic,14,"<php><mysql><linux><magento><magento2>, The stock item was unable to be saved. Please try again. Magento 2.4.0, I installed magento 2.4.0 on my Linux server from godaddy. I'm unable to add the products to it. It is showing the Error is The stock item was unable to be saved. Please try again. Can any one help me from this please
","<pp><myself><line><agents><magento2>, stock item unable saved. pleas try again. agents 2.4.0, instal agents 2.4.0 line server daddy. i'm unable add product it. show error stock item unable saved. pleas try again. one help pleas"
56554159,TypeError: Object of type 'datetime' is not JSON serializable (with serialize function),"I'm  I getting this TypeError: Object of type 'datetime' is not JSON serializable error, even though I have a specific serialize function described in my model.
This is my code:
Flask route (rendered by React):
menus.py
@menus_bp.route('/menus', methods=['GET', 'POST'])
def menus():
    response_object = {
        'status': 'fail',
        'message': 'Invalid payload.'
        }
    try:
        user = User.query.filter_by(id=1).first()
        if user.menu == []:
            return edit_menu()
        else:
            template = render_template('menus.html')
            response_object = {
                'status': 'success',
                'message': 'success',
                'data': [{""restaurant"": user.restaurant,
                          ""menu"": menu,
                          ""content"": template}] # template passed to React
                }
            # db method
            Create_Menu(user=user)
        return jsonify(response_object), 200
    except (exc.IntegrityError, ValueError):
        db.session.rollback()
        return jsonify(response_object), 400
methods.py
def Create_Menu(user):
    menu = Menu(user=user)
    db.session.add(menu)
    db.session.commit()
    return {""status"": True,
            ""menu"": menu}
and finally the Menu model, which has a serialize() function:
class Menu(db.Model):
    __tablename__='menu'
    """"""
    Model for storing menus. 
    """"""   
    id = db.Column(db.Integer, primary_key=True)
    created = db.Column(db.DateTime, default=func.now(), nullable=False)       
    user_id = db.Column(db.Integer, db.ForeignKey('users.id'))
    def __init__(self, user):
        self.user = user
    def serialize(self):
       return { 'id' : self.id,
                'created': self.created,
                'coffees' : [ item.serialize() for item in self.coffees]}
But I'm getting the following traceback:
TypeError: Object of type 'datetime' is not JSON serializable
File ""/usr/lib/python3.6/site-packages/flask/app.py"", line 2309, in __call__
return self.wsgi_app(environ, start_response)
File ""/usr/lib/python3.6/site-packages/flask/app.py"", line 2295, in wsgi_app
response = self.handle_exception(e)
File ""/usr/lib/python3.6/site-packages/flask_restful/__init__.py"", line 269, in error_router
return original_handler(e)
File ""/usr/lib/python3.6/site-packages/flask_cors/extension.py"", line 161, in wrapped_function
return cors_after_request(app.make_response(f(*args, **kwargs)))
File ""/usr/lib/python3.6/site-packages/flask/app.py"", line 1741, in handle_exception
reraise(exc_type, exc_value, tb)
File ""/usr/lib/python3.6/site-packages/flask/_compat.py"", line 34, in reraise
raise value.with_traceback(tb)
File ""/usr/lib/python3.6/site-packages/flask/app.py"", line 2292, in wsgi_app
response = self.full_dispatch_request()
File ""/usr/lib/python3.6/site-packages/flask/app.py"", line 1815, in full_dispatch_request
rv = self.handle_user_exception(e)
File ""/usr/lib/python3.6/site-packages/flask_restful/__init__.py"", line 269, in error_router
return original_handler(e)
File ""/usr/lib/python3.6/site-packages/flask_cors/extension.py"", line 161, in wrapped_function
return cors_after_request(app.make_response(f(*args, **kwargs)))
File ""/usr/lib/python3.6/site-packages/flask/app.py"", line 1718, in handle_user_exception
reraise(exc_type, exc_value, tb)
File ""/usr/lib/python3.6/site-packages/flask/_compat.py"", line 34, in reraise
raise value.with_traceback(tb)
File ""/usr/lib/python3.6/site-packages/flask/app.py"", line 1813, in full_dispatch_request
rv = self.dispatch_request()
File ""/usr/lib/python3.6/site-packages/flask_debugtoolbar/__init__.py"", line 125, in dispatch_request
return view_func(**req.view_args)
File ""/usr/lib/python3.6/site-packages/flask_restful/__init__.py"", line 462, in wrapper
return self.make_response(data, code, headers=headers)
File ""/usr/lib/python3.6/site-packages/flask_restful/__init__.py"", line 491, in make_response
resp = self.representations[mediatype](data, *args, **kwargs)
File ""/usr/lib/python3.6/site-packages/flask_restful/representations/json.py"", line 21, in output_json
dumped = dumps(data, **settings) + ""\n""
File ""/usr/lib/python3.6/json/__init__.py"", line 238, in dumps
**kw).encode(obj)
File ""/usr/lib/python3.6/json/encoder.py"", line 201, in encode
chunks = list(chunks)
File ""/usr/lib/python3.6/json/encoder.py"", line 430, in _iterencode
yield from _iterencode_dict(o, _current_indent_level)
File ""/usr/lib/python3.6/json/encoder.py"", line 404, in _iterencode_dict
yield from chunks
File ""/usr/lib/python3.6/json/encoder.py"", line 404, in _iterencode_dict
yield from chunks
File ""/usr/lib/python3.6/json/encoder.py"", line 325, in _iterencode_list
yield from chunks
File ""/usr/lib/python3.6/json/encoder.py"", line 404, in _iterencode_dict
yield from chunks
File ""/usr/lib/python3.6/json/encoder.py"", line 325, in _iterencode_list
yield from chunks
File ""/usr/lib/python3.6/json/encoder.py"", line 404, in _iterencode_dict
yield from chunks
File ""/usr/lib/python3.6/json/encoder.py"", line 437, in _iterencode
o = _default(o)
File ""/usr/lib/python3.6/json/encoder.py"", line 180, in default
o.__class__.__name__)
TypeError: Object of type 'datetime' is not JSON serializable
It used to work when I was redering templates with Flask at backend, but now with frontend requets, it breaks with the erro above.
what is wrong now? why does not my serialize function work anymore? 
",<python><json><flask><serialization><sqlalchemy>,5392,0,112,9734,30,103,203,52,30001,0.0,1849,3,20,2019-06-12 3:08,2019-06-12 12:45,2019-06-12 12:45,0.0,0.0,Intermediate,15,"<python><json><flask><serialization><sqlalchemy>, TypeError: Object of type 'datetime' is not JSON serializable (with serialize function), I'm  I getting this TypeError: Object of type 'datetime' is not JSON serializable error, even though I have a specific serialize function described in my model.
This is my code:
Flask route (rendered by React):
menus.py
@menus_bp.route('/menus', methods=['GET', 'POST'])
def menus():
    response_object = {
        'status': 'fail',
        'message': 'Invalid payload.'
        }
    try:
        user = User.query.filter_by(id=1).first()
        if user.menu == []:
            return edit_menu()
        else:
            template = render_template('menus.html')
            response_object = {
                'status': 'success',
                'message': 'success',
                'data': [{""restaurant"": user.restaurant,
                          ""menu"": menu,
                          ""content"": template}] # template passed to React
                }
            # db method
            Create_Menu(user=user)
        return jsonify(response_object), 200
    except (exc.IntegrityError, ValueError):
        db.session.rollback()
        return jsonify(response_object), 400
methods.py
def Create_Menu(user):
    menu = Menu(user=user)
    db.session.add(menu)
    db.session.commit()
    return {""status"": True,
            ""menu"": menu}
and finally the Menu model, which has a serialize() function:
class Menu(db.Model):
    __tablename__='menu'
    """"""
    Model for storing menus. 
    """"""   
    id = db.Column(db.Integer, primary_key=True)
    created = db.Column(db.DateTime, default=func.now(), nullable=False)       
    user_id = db.Column(db.Integer, db.ForeignKey('users.id'))
    def __init__(self, user):
        self.user = user
    def serialize(self):
       return { 'id' : self.id,
                'created': self.created,
                'coffees' : [ item.serialize() for item in self.coffees]}
But I'm getting the following traceback:
TypeError: Object of type 'datetime' is not JSON serializable
File ""/usr/lib/python3.6/site-packages/flask/app.py"", line 2309, in __call__
return self.wsgi_app(environ, start_response)
File ""/usr/lib/python3.6/site-packages/flask/app.py"", line 2295, in wsgi_app
response = self.handle_exception(e)
File ""/usr/lib/python3.6/site-packages/flask_restful/__init__.py"", line 269, in error_router
return original_handler(e)
File ""/usr/lib/python3.6/site-packages/flask_cors/extension.py"", line 161, in wrapped_function
return cors_after_request(app.make_response(f(*args, **kwargs)))
File ""/usr/lib/python3.6/site-packages/flask/app.py"", line 1741, in handle_exception
reraise(exc_type, exc_value, tb)
File ""/usr/lib/python3.6/site-packages/flask/_compat.py"", line 34, in reraise
raise value.with_traceback(tb)
File ""/usr/lib/python3.6/site-packages/flask/app.py"", line 2292, in wsgi_app
response = self.full_dispatch_request()
File ""/usr/lib/python3.6/site-packages/flask/app.py"", line 1815, in full_dispatch_request
rv = self.handle_user_exception(e)
File ""/usr/lib/python3.6/site-packages/flask_restful/__init__.py"", line 269, in error_router
return original_handler(e)
File ""/usr/lib/python3.6/site-packages/flask_cors/extension.py"", line 161, in wrapped_function
return cors_after_request(app.make_response(f(*args, **kwargs)))
File ""/usr/lib/python3.6/site-packages/flask/app.py"", line 1718, in handle_user_exception
reraise(exc_type, exc_value, tb)
File ""/usr/lib/python3.6/site-packages/flask/_compat.py"", line 34, in reraise
raise value.with_traceback(tb)
File ""/usr/lib/python3.6/site-packages/flask/app.py"", line 1813, in full_dispatch_request
rv = self.dispatch_request()
File ""/usr/lib/python3.6/site-packages/flask_debugtoolbar/__init__.py"", line 125, in dispatch_request
return view_func(**req.view_args)
File ""/usr/lib/python3.6/site-packages/flask_restful/__init__.py"", line 462, in wrapper
return self.make_response(data, code, headers=headers)
File ""/usr/lib/python3.6/site-packages/flask_restful/__init__.py"", line 491, in make_response
resp = self.representations[mediatype](data, *args, **kwargs)
File ""/usr/lib/python3.6/site-packages/flask_restful/representations/json.py"", line 21, in output_json
dumped = dumps(data, **settings) + ""\n""
File ""/usr/lib/python3.6/json/__init__.py"", line 238, in dumps
**kw).encode(obj)
File ""/usr/lib/python3.6/json/encoder.py"", line 201, in encode
chunks = list(chunks)
File ""/usr/lib/python3.6/json/encoder.py"", line 430, in _iterencode
yield from _iterencode_dict(o, _current_indent_level)
File ""/usr/lib/python3.6/json/encoder.py"", line 404, in _iterencode_dict
yield from chunks
File ""/usr/lib/python3.6/json/encoder.py"", line 404, in _iterencode_dict
yield from chunks
File ""/usr/lib/python3.6/json/encoder.py"", line 325, in _iterencode_list
yield from chunks
File ""/usr/lib/python3.6/json/encoder.py"", line 404, in _iterencode_dict
yield from chunks
File ""/usr/lib/python3.6/json/encoder.py"", line 325, in _iterencode_list
yield from chunks
File ""/usr/lib/python3.6/json/encoder.py"", line 404, in _iterencode_dict
yield from chunks
File ""/usr/lib/python3.6/json/encoder.py"", line 437, in _iterencode
o = _default(o)
File ""/usr/lib/python3.6/json/encoder.py"", line 180, in default
o.__class__.__name__)
TypeError: Object of type 'datetime' is not JSON serializable
It used to work when I was redering templates with Flask at backend, but now with frontend requets, it breaks with the erro above.
what is wrong now? why does not my serialize function work anymore? 
","<patron><son><flask><serialization><sqlalchemy>, typeerror: object type 'daytime' son serializ (with aerial function), i'm get typeerror: object type 'daytime' son serializ error, even though specie aerial function describe model. code: flask rout (render react): venus.i @menus_bp.route('/venus', methods=['get', 'post']) def venus(): response_object = { 'status': 'fail', 'message': 'invalid payload.' } try: user = user.query.filter_by(id=1).first() user.menu == []: return edit_menu() else: temple = render_template('venus.html') response_object = { 'status': 'success', 'message': 'success', 'data': [{""restaurant"": user.restaurant, ""menu"": menu, ""content"": temple}] # temple pass react } # do method create_menu(user=user) return jsonify(response_object), 200 except (etc.integrityerror, valueerror): do.session.rollback() return jsonify(response_object), 400 methods.i def create_menu(user): menu = menu(user=user) do.session.add(menu) do.session.commit() return {""status"": true, ""menu"": menu} final menu model, serialize() function: class menu(do.model): __tablename__='menu' """""" model store venus. """""" id = do.column(do.inter, primary_key=true) great = do.column(do.daytime, default=fun.now(), syllable=false) user_id = do.column(do.inter, do.foreigner('users.id')) def __init__(self, user): self.us = user def serialize(self): return { 'id' : self.id, 'created': self.created, 'coffee' : [ item.serialize() item self.coffee]} i'm get follow traceback: typeerror: object type 'daytime' son serializ file ""/us/limb/python3.6/site-packages/flask/pp.by"", line 2309, __call__ return self.wsgi_app(environs, start_response) file ""/us/limb/python3.6/site-packages/flask/pp.by"", line 2295, wsgi_app response = self.handle_exception(e) file ""/us/limb/python3.6/site-packages/flask_restful/__init__.by"", line 269, error_rout return original_handler(e) file ""/us/limb/python3.6/site-packages/flask_cors/extension.by"", line 161, wrapped_funct return cors_after_request(pp.make_response(f(*arms, **wars))) file ""/us/limb/python3.6/site-packages/flask/pp.by"", line 1741, handle_except raise(exc_type, exc_value, to) file ""/us/limb/python3.6/site-packages/flask/compact.by"", line 34, remain rays value.with_traceback(to) file ""/us/limb/python3.6/site-packages/flask/pp.by"", line 2292, wsgi_app response = self.full_dispatch_request() file ""/us/limb/python3.6/site-packages/flask/pp.by"", line 1815, full_dispatch_request re = self.handle_user_exception(e) file ""/us/limb/python3.6/site-packages/flask_restful/__init__.by"", line 269, error_rout return original_handler(e) file ""/us/limb/python3.6/site-packages/flask_cors/extension.by"", line 161, wrapped_funct return cors_after_request(pp.make_response(f(*arms, **wars))) file ""/us/limb/python3.6/site-packages/flask/pp.by"", line 1718, handle_user_except raise(exc_type, exc_value, to) file ""/us/limb/python3.6/site-packages/flask/compact.by"", line 34, remain rays value.with_traceback(to) file ""/us/limb/python3.6/site-packages/flask/pp.by"", line 1813, full_dispatch_request re = self.dispatch_request() file ""/us/limb/python3.6/site-packages/flask_debugtoolbar/__init__.by"", line 125, dispatch_request return view_func(**red.view_args) file ""/us/limb/python3.6/site-packages/flask_restful/__init__.by"", line 462, wrapped return self.make_response(data, code, leaders=leaders) file ""/us/limb/python3.6/site-packages/flask_restful/__init__.by"", line 491, make_respons rest = self.representations[mediate](data, *arms, **wars) file ""/us/limb/python3.6/site-packages/flask_restful/representations/son.by"", line 21, output_json dump = dumps(data, **settings) + ""\n"" file ""/us/limb/python3.6/son/__init__.by"", line 238, dump **w).income(obs) file ""/us/limb/python3.6/son/uncover.by"", line 201, end chink = list(chinks) file ""/us/limb/python3.6/son/uncover.by"", line 430, _iterencod yield _iterencode_dict(o, _current_indent_level) file ""/us/limb/python3.6/son/uncover.by"", line 404, _iterencode_dict yield chink file ""/us/limb/python3.6/son/uncover.by"", line 404, _iterencode_dict yield chink file ""/us/limb/python3.6/son/uncover.by"", line 325, _iterencode_list yield chink file ""/us/limb/python3.6/son/uncover.by"", line 404, _iterencode_dict yield chink file ""/us/limb/python3.6/son/uncover.by"", line 325, _iterencode_list yield chink file ""/us/limb/python3.6/son/uncover.by"", line 404, _iterencode_dict yield chink file ""/us/limb/python3.6/son/uncover.by"", line 437, _iterencod = default(o) file ""/us/limb/python3.6/son/uncover.by"", line 180, default o.__class__.__name__) typeerror: object type 'daytime' son serializ use work render temple flask backed, fronted request, break error above. wrong now? aerial function work anymore?"
50172067,SqlConnection Error if EXE is executed from network path,"
  First of all: everything you will read in this post happens only if Windows 10 April 2018 update is installed. No problem before installation and after update uninstallation.
After installing Windows 10 1803 update, all my VB program (VB6, .NET and WPF) running from network mapped drive or UNC path can't connect to SQL server, no problem if the same executable is placed and executed from local drive (tested on 2 pc in the same network):
Remote SQL server, exe on local drive: OK
Same remote SQL server, same exe on mapped network drive (with full read/write access): ERROR
This is the error (maybe not significat to solve this problem):
  A network-related or instance-specific error occurred while establishing a connection to SQL Server. The server was not found or was not accessible. Verify that the instance name is correct and that SQL Server is configured to allow remote connections. (provider: SQL Network Interfaces, error: 26 - Error Locating Server/Instance Specified).
Simple VB.NET code to reproduce the problem (place the code in a simple form with a button in the button_click event, set values to connect to the SQL server, compile, save the exe file on a network path and execute it):
Dim myConnectionString As String
Dim mySqlConnectionStringBuilder As New SqlConnectionStringBuilder()
mySqlConnectionStringBuilder.DataSource = myServer
mySqlConnectionStringBuilder.InitialCatalog = myDatabase
mySqlConnectionStringBuilder.UserID = myUtente
mySqlConnectionStringBuilder.Password = myPassword
myConnectionString = mySqlConnectionStringBuilder.ConnectionString
Dim mySqlConnection As New SqlConnection(myConnectionString)
mySqlConnection.Open()  &lt;- error
Exception:
System.Data.SqlClient.SqlException (0x80131904): Si è verificato un errore di rete o specifico dell'istanza mentre si cercava di stabilire una connessione con SQL Server. Il server non è stato trovato o non è accessibile. Verificare che il nome dell'istanza sia corretto e che SQL Server sia configurato in modo da consentire connessioni remote. (provider: SQL Network Interfaces, error: 26 - Errore nell'individuazione del server/dell'istanza specificata)
   in System.Data.SqlClient.SqlInternalConnectionTds..ctor(DbConnectionPoolIdentity identity, SqlConnectionString connectionOptions, SqlCredential credential, Object providerInfo, String newPassword, SecureString newSecurePassword, Boolean redirectedUserInstance, SqlConnectionString userConnectionOptions, SessionData reconnectSessionData, DbConnectionPool pool, String accessToken, Boolean applyTransientFaultHandling, SqlAuthenticationProviderManager sqlAuthProviderManager)
   in System.Data.SqlClient.SqlConnectionFactory.CreateConnection(DbConnectionOptions options, DbConnectionPoolKey poolKey, Object poolGroupProviderInfo, DbConnectionPool pool, DbConnection owningConnection, DbConnectionOptions userOptions)
   in System.Data.ProviderBase.DbConnectionFactory.CreatePooledConnection(DbConnectionPool pool, DbConnection owningObject, DbConnectionOptions options, DbConnectionPoolKey poolKey, DbConnectionOptions userOptions)
   in System.Data.ProviderBase.DbConnectionPool.CreateObject(DbConnection owningObject, DbConnectionOptions userOptions, DbConnectionInternal oldConnection)
   in System.Data.ProviderBase.DbConnectionPool.UserCreateRequest(DbConnection owningObject, DbConnectionOptions userOptions, DbConnectionInternal oldConnection)
   in System.Data.ProviderBase.DbConnectionPool.TryGetConnection(DbConnection owningObject, UInt32 waitForMultipleObjectsTimeout, Boolean allowCreate, Boolean onlyOneCheckConnection, DbConnectionOptions userOptions, DbConnectionInternal&amp; connection)
   in System.Data.ProviderBase.DbConnectionPool.TryGetConnection(DbConnection owningObject, TaskCompletionSource`1 retry, DbConnectionOptions userOptions, DbConnectionInternal&amp; connection)
   in System.Data.ProviderBase.DbConnectionFactory.TryGetConnection(DbConnection owningConnection, TaskCompletionSource`1 retry, DbConnectionOptions userOptions, DbConnectionInternal oldConnection, DbConnectionInternal&amp; connection)
   in System.Data.ProviderBase.DbConnectionInternal.TryOpenConnectionInternal(DbConnection outerConnection, DbConnectionFactory connectionFactory, TaskCompletionSource`1 retry, DbConnectionOptions userOptions)
   in System.Data.ProviderBase.DbConnectionClosed.TryOpenConnection(DbConnection outerConnection, DbConnectionFactory connectionFactory, TaskCompletionSource`1 retry, DbConnectionOptions userOptions)
   in System.Data.SqlClient.SqlConnection.TryOpenInner(TaskCompletionSource`1 retry)
   in System.Data.SqlClient.SqlConnection.TryOpen(TaskCompletionSource`1 retry)
   in System.Data.SqlClient.SqlConnection.Open()
   in RiepilogoOreTimer.RiepilogoOreTimerWindow.ConnessioneOK()
ClientConnectionId:00000000-0000-0000-0000-000000000000
Error Number:-1,State:0,Class:20
Any ideas?
Update:
If I uninstall the April 2018 update the issue go away and the program works fine even if executed on a network drive, but this can't be the solution...
Update 08/05/2018:
I noticed that April 2018 update brought some changes in security:
  Windows 10, version 1803 provides additional protections:
  New Attack surface reduction rules 
  Controlled folder access can now block disk sectors
Could it be the cause of the issue?
I'm not a security manager so I can't say if this can cause my problem
Update 09/05/2018: I found this information in this post:
  Windows 10 update 1803 does not open network connections on
  executables files on SMBv1 share (as Windows Server 2003)
but I don't know what SMBv1 is... somebody can help me?
",<sql-server><vb.net><windows-10>,5616,2,27,372,0,2,13,65,4324,0.0,1,4,20,2018-05-04 9:49,2018-05-08 21:08,2018-05-09 10:47,4.0,5.0,Advanced,37,"<sql-server><vb.net><windows-10>, SqlConnection Error if EXE is executed from network path, 
  First of all: everything you will read in this post happens only if Windows 10 April 2018 update is installed. No problem before installation and after update uninstallation.
After installing Windows 10 1803 update, all my VB program (VB6, .NET and WPF) running from network mapped drive or UNC path can't connect to SQL server, no problem if the same executable is placed and executed from local drive (tested on 2 pc in the same network):
Remote SQL server, exe on local drive: OK
Same remote SQL server, same exe on mapped network drive (with full read/write access): ERROR
This is the error (maybe not significat to solve this problem):
  A network-related or instance-specific error occurred while establishing a connection to SQL Server. The server was not found or was not accessible. Verify that the instance name is correct and that SQL Server is configured to allow remote connections. (provider: SQL Network Interfaces, error: 26 - Error Locating Server/Instance Specified).
Simple VB.NET code to reproduce the problem (place the code in a simple form with a button in the button_click event, set values to connect to the SQL server, compile, save the exe file on a network path and execute it):
Dim myConnectionString As String
Dim mySqlConnectionStringBuilder As New SqlConnectionStringBuilder()
mySqlConnectionStringBuilder.DataSource = myServer
mySqlConnectionStringBuilder.InitialCatalog = myDatabase
mySqlConnectionStringBuilder.UserID = myUtente
mySqlConnectionStringBuilder.Password = myPassword
myConnectionString = mySqlConnectionStringBuilder.ConnectionString
Dim mySqlConnection As New SqlConnection(myConnectionString)
mySqlConnection.Open()  &lt;- error
Exception:
System.Data.SqlClient.SqlException (0x80131904): Si è verificato un errore di rete o specifico dell'istanza mentre si cercava di stabilire una connessione con SQL Server. Il server non è stato trovato o non è accessibile. Verificare che il nome dell'istanza sia corretto e che SQL Server sia configurato in modo da consentire connessioni remote. (provider: SQL Network Interfaces, error: 26 - Errore nell'individuazione del server/dell'istanza specificata)
   in System.Data.SqlClient.SqlInternalConnectionTds..ctor(DbConnectionPoolIdentity identity, SqlConnectionString connectionOptions, SqlCredential credential, Object providerInfo, String newPassword, SecureString newSecurePassword, Boolean redirectedUserInstance, SqlConnectionString userConnectionOptions, SessionData reconnectSessionData, DbConnectionPool pool, String accessToken, Boolean applyTransientFaultHandling, SqlAuthenticationProviderManager sqlAuthProviderManager)
   in System.Data.SqlClient.SqlConnectionFactory.CreateConnection(DbConnectionOptions options, DbConnectionPoolKey poolKey, Object poolGroupProviderInfo, DbConnectionPool pool, DbConnection owningConnection, DbConnectionOptions userOptions)
   in System.Data.ProviderBase.DbConnectionFactory.CreatePooledConnection(DbConnectionPool pool, DbConnection owningObject, DbConnectionOptions options, DbConnectionPoolKey poolKey, DbConnectionOptions userOptions)
   in System.Data.ProviderBase.DbConnectionPool.CreateObject(DbConnection owningObject, DbConnectionOptions userOptions, DbConnectionInternal oldConnection)
   in System.Data.ProviderBase.DbConnectionPool.UserCreateRequest(DbConnection owningObject, DbConnectionOptions userOptions, DbConnectionInternal oldConnection)
   in System.Data.ProviderBase.DbConnectionPool.TryGetConnection(DbConnection owningObject, UInt32 waitForMultipleObjectsTimeout, Boolean allowCreate, Boolean onlyOneCheckConnection, DbConnectionOptions userOptions, DbConnectionInternal&amp; connection)
   in System.Data.ProviderBase.DbConnectionPool.TryGetConnection(DbConnection owningObject, TaskCompletionSource`1 retry, DbConnectionOptions userOptions, DbConnectionInternal&amp; connection)
   in System.Data.ProviderBase.DbConnectionFactory.TryGetConnection(DbConnection owningConnection, TaskCompletionSource`1 retry, DbConnectionOptions userOptions, DbConnectionInternal oldConnection, DbConnectionInternal&amp; connection)
   in System.Data.ProviderBase.DbConnectionInternal.TryOpenConnectionInternal(DbConnection outerConnection, DbConnectionFactory connectionFactory, TaskCompletionSource`1 retry, DbConnectionOptions userOptions)
   in System.Data.ProviderBase.DbConnectionClosed.TryOpenConnection(DbConnection outerConnection, DbConnectionFactory connectionFactory, TaskCompletionSource`1 retry, DbConnectionOptions userOptions)
   in System.Data.SqlClient.SqlConnection.TryOpenInner(TaskCompletionSource`1 retry)
   in System.Data.SqlClient.SqlConnection.TryOpen(TaskCompletionSource`1 retry)
   in System.Data.SqlClient.SqlConnection.Open()
   in RiepilogoOreTimer.RiepilogoOreTimerWindow.ConnessioneOK()
ClientConnectionId:00000000-0000-0000-0000-000000000000
Error Number:-1,State:0,Class:20
Any ideas?
Update:
If I uninstall the April 2018 update the issue go away and the program works fine even if executed on a network drive, but this can't be the solution...
Update 08/05/2018:
I noticed that April 2018 update brought some changes in security:
  Windows 10, version 1803 provides additional protections:
  New Attack surface reduction rules 
  Controlled folder access can now block disk sectors
Could it be the cause of the issue?
I'm not a security manager so I can't say if this can cause my problem
Update 09/05/2018: I found this information in this post:
  Windows 10 update 1803 does not open network connections on
  executables files on SMBv1 share (as Windows Server 2003)
but I don't know what SMBv1 is... somebody can help me?
","<sal-server><ve.net><windows-10>, sqlconnect error eye execute network path, first all: every read post happen window 10 april 2018 update installed. problem instal update installation. instal window 10 1803 update, ve program (by, .net of) run network map drive un path can't connect sal server, problem execute place execute local drive (test 2 pp network): remote sal server, eye local drive: ok remote sal server, eye map network drive (with full read/writ access): error error (may significant sole problem): network-red instance-specie error occur establish connect sal server. server found accessible. verify instant name correct sal server configur allow remote connections. (provider: sal network interface, error: 26 - error local server/inst specified). simple ve.net code reproduce problem (place code simple form button button_click event, set value connect sal server, compile, save eye file network path execute it): dim myconnectionstr string dim mysqlconnectionstringbuild new sqlconnectionstringbuilder() mysqlconnectionstringbuilder.datasourc = myself mysqlconnectionstringbuilder.initialcatalog = mydatabas mysqlconnectionstringbuilder.used = myutent mysqlconnectionstringbuilder.password = password myconnectionstr = mysqlconnectionstringbuilder.connections dim mysqlconnect new sqlconnection(myconnectionstring) mysqlconnection.open() &it;- error exception: system.data.sqlclient.sqlexcept (0x80131904): si è verificato un error di rete specific well'stanza entr si cercava di stability un confession con sal server. il server non è state tomato non è accessible. verificar the il some well'stanza sir correct e the sal server sir configuration mood da consent confession remote. (provider: sal network interface, error: 26 - error well'individuazion del server/well'stanza specificata) system.data.sqlclient.sqlinternalconnectiontds..actor(dbconnectionpoolident identity, sqlconnectionstr connectionoptions, sqlcredenti credentials, object providerinfo, string newpassword, securer newsecurepassword, woolen redirecteduserinstance, sqlconnectionstr userconnectionoptions, sessiondata reconnectsessiondata, dbconnectionpool pool, string accesstoken, woolen applytransientfaulthandling, sqlauthenticationprovidermanag sqlauthprovidermanager) system.data.sqlclient.sqlconnectionfactory.createconnection(dbconnectionopt option, dbconnectionpoolkey poolkey, object poolgroupproviderinfo, dbconnectionpool pool, connect owningconnection, dbconnectionopt useroptions) system.data.providerbase.dbconnectionfactory.createpooledconnection(dbconnectionpool pool, connect owningobject, dbconnectionopt option, dbconnectionpoolkey poolkey, dbconnectionopt useroptions) system.data.providerbase.dbconnectionpool.createobject(connect owningobject, dbconnectionopt useroptions, dbconnectionintern oldconnection) system.data.providerbase.dbconnectionpool.usercreaterequest(connect owningobject, dbconnectionopt useroptions, dbconnectionintern oldconnection) system.data.providerbase.dbconnectionpool.trygetconnection(connect owningobject, uint32 waitformultipleobjectstimeout, woolen allowcreate, woolen onlyonecheckconnection, dbconnectionopt useroptions, dbconnectioninternal&amp; connection) system.data.providerbase.dbconnectionpool.trygetconnection(connect owningobject, taskcompletionsource`1 retro, dbconnectionopt useroptions, dbconnectioninternal&amp; connection) system.data.providerbase.dbconnectionfactory.trygetconnection(connect owningconnection, taskcompletionsource`1 retro, dbconnectionopt useroptions, dbconnectionintern oldconnection, dbconnectioninternal&amp; connection) system.data.providerbase.dbconnectioninternal.tryopenconnectioninternal(connect outerconnection, dbconnectionfactori connectionfactory, taskcompletionsource`1 retro, dbconnectionopt useroptions) system.data.providerbase.dbconnectionclosed.tryopenconnection(connect outerconnection, dbconnectionfactori connectionfactory, taskcompletionsource`1 retro, dbconnectionopt useroptions) system.data.sqlclient.sqlconnection.tryopeninner(taskcompletionsource`1 retro) system.data.sqlclient.sqlconnection.trooper(taskcompletionsource`1 retro) system.data.sqlclient.sqlconnection.open() riepilogooretimer.riepilogooretimerwindow.connessioneok() clientconnectionid:00000000-0000-0000-0000-000000000000 error number:-1,state:0,class:20 ideas? update: instal april 2018 update issue go away program work fine even execute network drive, can't solution... update 08/05/2018: notice april 2018 update brought change security: window 10, version 1803 proved admit protection: new attack surface reduce rule control older access block disk sector could cause issue? i'm secure manage can't say cause problem update 09/05/2018: found inform post: window 10 update 1803 open network connect execute file smbv1 share (a window server 2003) know smbv1 is... somebody help me?"
49323419,manually create replication slot for publication in PostgreSQL 10,"I am trying to get a stream of updates for certain tables from my PostgreSQL database. The regular way of getting all updates looks like this:
You create a logical replication slot
pg_create_logical_replication_slot('my_slot', 'wal2json');
And either connect to it using pg_recvlogical or making special SQL queries. This allows you to get all the actions from the database in json (if you used wal2json plugin or similar) and then do whatever you want with that data.
But in PostgreSQL 10 we have Publication/Subscription mechanism which allows us to replicate selected tables only. This is very handy because a lot of useless data is not being sent. The process looks like this:
First, you create a publication
CREATE PUBLICATION foo FOR TABLE herp, derp;
Then you subscribe to that publication from another database
CREATE SUBSCRIPTION mysub CONNECTION &lt;connection stuff&gt; PUBLICATION foo;
This creates a replication slot on a master database under the hood and starts listening to updates and commit them to the same tables on a second database. This is fine if your job was to replicate some tables, but want to get a raw stream for my stuff.
As I mentioned, the CREATE SUBSCRIPTION query is creating a replication slot on the master database under the hood, but how can I create one manually without the subscription and a second database? Here the docs say:
  To make this work, create the replication slot separately (using the function pg_create_logical_replication_slot with the plugin name pgoutput)
According to the docs, this is possible, but pg_create_logical_replication_slot only creates a regular replication slot. Is the pgoutput plugin responsible for all the magic? If yes, then it becomes impossible to use other plugins like wal2json with publications.
What am I missing here?
",<postgresql><replication><postgresql-10>,1804,2,8,988,2,10,25,66,18753,0.0,164,2,20,2018-03-16 14:42,2019-06-21 12:00,,462.0,,Advanced,39,"<postgresql><replication><postgresql-10>, manually create replication slot for publication in PostgreSQL 10, I am trying to get a stream of updates for certain tables from my PostgreSQL database. The regular way of getting all updates looks like this:
You create a logical replication slot
pg_create_logical_replication_slot('my_slot', 'wal2json');
And either connect to it using pg_recvlogical or making special SQL queries. This allows you to get all the actions from the database in json (if you used wal2json plugin or similar) and then do whatever you want with that data.
But in PostgreSQL 10 we have Publication/Subscription mechanism which allows us to replicate selected tables only. This is very handy because a lot of useless data is not being sent. The process looks like this:
First, you create a publication
CREATE PUBLICATION foo FOR TABLE herp, derp;
Then you subscribe to that publication from another database
CREATE SUBSCRIPTION mysub CONNECTION &lt;connection stuff&gt; PUBLICATION foo;
This creates a replication slot on a master database under the hood and starts listening to updates and commit them to the same tables on a second database. This is fine if your job was to replicate some tables, but want to get a raw stream for my stuff.
As I mentioned, the CREATE SUBSCRIPTION query is creating a replication slot on the master database under the hood, but how can I create one manually without the subscription and a second database? Here the docs say:
  To make this work, create the replication slot separately (using the function pg_create_logical_replication_slot with the plugin name pgoutput)
According to the docs, this is possible, but pg_create_logical_replication_slot only creates a regular replication slot. Is the pgoutput plugin responsible for all the magic? If yes, then it becomes impossible to use other plugins like wal2json with publications.
What am I missing here?
","<postgresql><application><postgresql-10>, manual great relic slot public postgresql 10, try get stream update certain table postgresql database. regular way get update look like this: great logic relic slot pg_create_logical_replication_slot('my_slot', 'wal2json'); either connect use pg_recvlog make special sal queried. allow get action database son (if use wal2json plain similar) what want data. postgresql 10 publication/subscribe mean allow us relic select table only. hand lot useless data sent. process look like this: first, great public great public foo table her, deep; subscribe public not database great subscribe sub connect &it;connect stuff&it; public foo; great relic slot master database hood start listen update commit table second database. fine job relic tables, want get raw stream stuff. mentioned, great subscribe query great relic slot master database hood, great one manual without subscribe second database? do say: make work, great relic slot spear (use function pg_create_logical_replication_slot plain name output) accord docs, possible, pg_create_logical_replication_slot great regular relic slot. output plain response magic? yes, become impose use plain like wal2json publications. miss here?"
54598531,What determines if rails includes id: :serial in a table definition?,"I'm working with an existing rails app, using postgresql. Its schema.rb file has id: :serial for many, but not all, tables:
create_table ""foos"", id: :serial, force: :cascade do |t|
When I run rails db:migrate:reset, id: :serial is removed. We are all on the same version of postgres, but different OSes. I haven't exhaustively tested the behavior between machines, but I think there is a difference between machines.
The rails version is the same as it was when the project started.
The project did start with sqlite3. When I switch to that and regenerate the file, same behavior.
What could cause this option to be removed in my environment?
here's some code that is probably relevant:
https://github.com/rails/rails/blob/b2eb1d1c55a59fee1e6c4cba7030d8ceb524267c/activerecord/lib/active_record/connection_adapters/postgresql/column.rb#L15-L21
https://github.com/rails/rails/blob/b2eb1d1c55a59fee1e6c4cba7030d8ceb524267c/activerecord/lib/active_record/connection_adapters/postgresql/schema_dumper.rb#L26-L42
update
I just tried rails db:migrate:reset on colleague's machines, and I was wrong! their environments also remove id: :serial.
I looked closer at recent migrations from a colleague, and the most recent one did not create id: :serial in schema.rb either.
",<ruby-on-rails><postgresql><rails-migrations>,1264,4,7,22715,29,156,228,62,8117,0.0,1154,2,20,2019-02-08 18:48,2019-02-14 4:56,2019-02-14 16:24,6.0,6.0,Basic,8,"<ruby-on-rails><postgresql><rails-migrations>, What determines if rails includes id: :serial in a table definition?, I'm working with an existing rails app, using postgresql. Its schema.rb file has id: :serial for many, but not all, tables:
create_table ""foos"", id: :serial, force: :cascade do |t|
When I run rails db:migrate:reset, id: :serial is removed. We are all on the same version of postgres, but different OSes. I haven't exhaustively tested the behavior between machines, but I think there is a difference between machines.
The rails version is the same as it was when the project started.
The project did start with sqlite3. When I switch to that and regenerate the file, same behavior.
What could cause this option to be removed in my environment?
here's some code that is probably relevant:
https://github.com/rails/rails/blob/b2eb1d1c55a59fee1e6c4cba7030d8ceb524267c/activerecord/lib/active_record/connection_adapters/postgresql/column.rb#L15-L21
https://github.com/rails/rails/blob/b2eb1d1c55a59fee1e6c4cba7030d8ceb524267c/activerecord/lib/active_record/connection_adapters/postgresql/schema_dumper.rb#L26-L42
update
I just tried rails db:migrate:reset on colleague's machines, and I was wrong! their environments also remove id: :serial.
I looked closer at recent migrations from a colleague, and the most recent one did not create id: :serial in schema.rb either.
","<ruby-on-rails><postgresql><rails-migrations>, determine rail include id: :aerial table definition?, i'm work exist rail pp, use postgresql. scheme.re file id: :aerial many, all, tables: greatest ""foot"", id: :aerial, force: :cascade |t| run rail do:migrate:rest, id: :aerial removed. version postures, differ ones. exhaust test behavior machines, think differ machines. rail version project started. project start sqlite3. switch keener file, behavior. could cause option remove environment? here' code probably relevant: http://github.com/rails/rails/blow/b2eb1d1c55a59fee1e6c4cba7030d8ceb524267c/activerecord/limb/active_record/connection_adapters/postgresql/column.re#let-let http://github.com/rails/rails/blow/b2eb1d1c55a59fee1e6c4cba7030d8ceb524267c/activerecord/limb/active_record/connection_adapters/postgresql/schema_dumper.re#let-let update try rail do:migrate:rest colleague' machines, wrong! environs also remove id: :aerial. look closer recent migrate colleague, recent one great id: :aerial scheme.re either."
56742757,Why is Azure SQL database so expensive?,"For a small personal coding project I recently created a SQL database in Azure. For the past weeks I have been hardly using the database, out of 2 GB available space I have been using only 13 MB.
However, the database costs me 6,70 EUR per day and I don't understand why this is the case. Read a few topics/posts stating that the costs with similar use should be around 5-7 EUR per month, not per day.
This is the configuration for the database:
No elastic pool
General purpose, Gen5, 2 vCores
West Europe
Does anyone have an idea about what could be causing the costs per month to be so high? 
",<sql><azure><azure-sql-database>,595,0,0,1033,2,12,21,47,13493,0.0,132,7,20,2019-06-24 19:24,2019-06-24 19:33,2019-06-25 2:32,0.0,1.0,Advanced,39,"<sql><azure><azure-sql-database>, Why is Azure SQL database so expensive?, For a small personal coding project I recently created a SQL database in Azure. For the past weeks I have been hardly using the database, out of 2 GB available space I have been using only 13 MB.
However, the database costs me 6,70 EUR per day and I don't understand why this is the case. Read a few topics/posts stating that the costs with similar use should be around 5-7 EUR per month, not per day.
This is the configuration for the database:
No elastic pool
General purpose, Gen5, 2 vCores
West Europe
Does anyone have an idea about what could be causing the costs per month to be so high? 
","<sal><azure><azure-sal-database>, azur sal database expensive?, small person code project recent great sal database azure. past week hardly use database, 2 go avail space use 13 mb. however, database cost 6,70 our per day understand case. read topics/post state cost similar use around 5-7 our per month, per day. configur database: last pool genet purpose, genu, 2 score west europe anyone idea could cause cost per month high?"
49387428,Which MySQL connector do I use: mysql-connector-java-5.1.46.jar or mysql-connector-java-5.1.46-bin.jar What is the difference?,"I am preparing to use jdbc for the first time and am in the process of installing the jdbc driver for MySQL.
However, it is unclear to me which of these files to move to the WEB_INF/lib folder in Eclipse.  They both seem to contain the same content and are included together in the downloaded zip file for the MySQL connector.
I have searched everywhere but have been unable to find any documentation to explain which of these files to use.
",<java><mysql><jdbc><mysql-connector>,441,0,0,2364,1,19,24,51,8481,0.0,108,1,20,2018-03-20 14:52,2018-03-20 15:38,2018-03-20 15:38,0.0,0.0,Intermediate,19,"<java><mysql><jdbc><mysql-connector>, Which MySQL connector do I use: mysql-connector-java-5.1.46.jar or mysql-connector-java-5.1.46-bin.jar What is the difference?, I am preparing to use jdbc for the first time and am in the process of installing the jdbc driver for MySQL.
However, it is unclear to me which of these files to move to the WEB_INF/lib folder in Eclipse.  They both seem to contain the same content and are included together in the downloaded zip file for the MySQL connector.
I have searched everywhere but have been unable to find any documentation to explain which of these files to use.
","<cava><myself><job><myself-connection>, myself connection use: myself-connection-cava-5.1.46.jar myself-connection-cava-5.1.46-bin.jar difference?, prepare use job first time process instal job driver myself. however, unclear file move webbing/limb older ellipse. seem contain content include together download zip file myself connection. search everywhere unable find document explain file use."
56808425,SQLAlchemy (psycopg2.ProgrammingError) can't adapt type 'dict',"Couldn't find a solution on the web for my problem.
I am trying to insert this pandas df to a Postgresql table using SQLAlchemy 
Pandas 0.24.2 
sqlalchemy 1.3.3
python 3.7
Relevant part of my code is below:
engine = create_engine('postgresql://user:pass@host:5432/db')
file = open('GameRoundMessageBlackjackSample.json', 'r', encoding='utf-8')
json_dict = json.load(file)
df = json_normalize(json_dict, record_path='cards', meta=['bet', 'dealerId', 'dealerName', 'gameOutcome', 'gameRoundDuration', 'gameRoundId', 'gameType', 'tableId', 'win'])
df = df[['win', 'betAmount', 'bets']]
df.to_sql('test_netent_data', engine, if_exists='append')
When I try to load this table to sql without the column 'bets' everyting works as expected. But when I include it i get the following error:
sqlalchemy.exc.ProgrammingError: (psycopg2.ProgrammingError) can't adapt 
type 'dict'
[SQL: INSERT INTO test_netent_data (index, win, ""betAmount"", bets) VALUES (%(index)s, %(win)s, %(betAmount)s, %(bets)s)]
[parameters: ({'index': 0, 'win': '2000.00', 'betAmount': '1212112', 'bets': [{'name': '1', 'amount': '1212112'}]}, {'index': 1, 'win': '2000.00', 'betAmount': '1212000', 'bets': [{'name': '1', 'amount': '1212000'}]}, {'index': 2, 'win': '2000.00', 'betAmount': '1212112', 'bets': [{'name': '1', 'amount': '1212112'}]}, {'index': 3, 'win': '2000.00', 'betAmount': '1212000', 'bets': [{'name': '1', 'amount': '1212000'}]}, {'index': 4, 'win': '2000.00', 'betAmount': '1212112', 'bets': [{'name': '1', 'amount': '1212112'}]}, {'index': 5, 'win': '2000.00', 'betAmount': '1212000', 'bets': [{'name': '1', 'amount': '1212000'}]}, {'index': 6, 'win': '2000.00', 'betAmount': '1212112', 'bets': [{'name': '1', 'amount': '1212112'}]}, {'index': 7, 'win': '2000.00', 'betAmount': '1212000', 'bets': [{'name': '1', 'amount': '1212000'}]})]
(Background on this error at: http://sqlalche.me/e/f405)
I have checked the type of this column but it is (type object) no different from other columns. Ive also tried to convert it to string and got a bunch of other errors.
I believe there should be a simple solution which I can't get my head around.
",<json><python-3.x><pandas><postgresql><sqlalchemy>,2123,2,13,269,1,2,11,74,50387,0.0,13,4,20,2019-06-28 14:04,2019-06-28 14:55,2019-06-28 14:55,0.0,0.0,Advanced,33,"<json><python-3.x><pandas><postgresql><sqlalchemy>, SQLAlchemy (psycopg2.ProgrammingError) can't adapt type 'dict', Couldn't find a solution on the web for my problem.
I am trying to insert this pandas df to a Postgresql table using SQLAlchemy 
Pandas 0.24.2 
sqlalchemy 1.3.3
python 3.7
Relevant part of my code is below:
engine = create_engine('postgresql://user:pass@host:5432/db')
file = open('GameRoundMessageBlackjackSample.json', 'r', encoding='utf-8')
json_dict = json.load(file)
df = json_normalize(json_dict, record_path='cards', meta=['bet', 'dealerId', 'dealerName', 'gameOutcome', 'gameRoundDuration', 'gameRoundId', 'gameType', 'tableId', 'win'])
df = df[['win', 'betAmount', 'bets']]
df.to_sql('test_netent_data', engine, if_exists='append')
When I try to load this table to sql without the column 'bets' everyting works as expected. But when I include it i get the following error:
sqlalchemy.exc.ProgrammingError: (psycopg2.ProgrammingError) can't adapt 
type 'dict'
[SQL: INSERT INTO test_netent_data (index, win, ""betAmount"", bets) VALUES (%(index)s, %(win)s, %(betAmount)s, %(bets)s)]
[parameters: ({'index': 0, 'win': '2000.00', 'betAmount': '1212112', 'bets': [{'name': '1', 'amount': '1212112'}]}, {'index': 1, 'win': '2000.00', 'betAmount': '1212000', 'bets': [{'name': '1', 'amount': '1212000'}]}, {'index': 2, 'win': '2000.00', 'betAmount': '1212112', 'bets': [{'name': '1', 'amount': '1212112'}]}, {'index': 3, 'win': '2000.00', 'betAmount': '1212000', 'bets': [{'name': '1', 'amount': '1212000'}]}, {'index': 4, 'win': '2000.00', 'betAmount': '1212112', 'bets': [{'name': '1', 'amount': '1212112'}]}, {'index': 5, 'win': '2000.00', 'betAmount': '1212000', 'bets': [{'name': '1', 'amount': '1212000'}]}, {'index': 6, 'win': '2000.00', 'betAmount': '1212112', 'bets': [{'name': '1', 'amount': '1212112'}]}, {'index': 7, 'win': '2000.00', 'betAmount': '1212000', 'bets': [{'name': '1', 'amount': '1212000'}]})]
(Background on this error at: http://sqlalche.me/e/f405)
I have checked the type of this column but it is (type object) no different from other columns. Ive also tried to convert it to string and got a bunch of other errors.
I believe there should be a simple solution which I can't get my head around.
","<son><patron-3.x><hands><postgresql><sqlalchemy>, sqlalchemi (psycopg2.programmingerror) can't adapt type 'duct', find slut web problem. try insert and of postgresql table use sqlalchemi and 0.24.2 sqlalchemi 1.3.3 patron 3.7 rule part code below: engine = create_engine('postgresql://user:pass@host:5432/do') file = open('gameroundmessageblackjacksample.son', 'r', encoding='utf-8') json_dict = son.load(file) of = json_normalize(json_dict, record_path='cards', met=['bet', 'dealer', 'dealername', 'gameoutcome', 'gameroundduration', 'gameroundid', 'gametype', 'table', 'win']) of = of[['win', 'betamount', 'bets']] of.tonsil('test_netent_data', engine, if_exists='happened') try load table sal without column 'bets' every work expected. include get follow error: sqlalchemy.etc.programmingerror: (psycopg2.programmingerror) can't adapt type 'duct' [sal: insert test_netent_data (index, win, ""betamount"", bets) value (%(index)s, %(win)s, %(betamount)s, %(bets)s)] [parameter: ({'index': 0, 'win': '2000.00', 'betamount': '1212112', 'bets': [{'name': '1', 'amount': '1212112'}]}, {'index': 1, 'win': '2000.00', 'betamount': '1212000', 'bets': [{'name': '1', 'amount': '1212000'}]}, {'index': 2, 'win': '2000.00', 'betamount': '1212112', 'bets': [{'name': '1', 'amount': '1212112'}]}, {'index': 3, 'win': '2000.00', 'betamount': '1212000', 'bets': [{'name': '1', 'amount': '1212000'}]}, {'index': 4, 'win': '2000.00', 'betamount': '1212112', 'bets': [{'name': '1', 'amount': '1212112'}]}, {'index': 5, 'win': '2000.00', 'betamount': '1212000', 'bets': [{'name': '1', 'amount': '1212000'}]}, {'index': 6, 'win': '2000.00', 'betamount': '1212112', 'bets': [{'name': '1', 'amount': '1212112'}]}, {'index': 7, 'win': '2000.00', 'betamount': '1212000', 'bets': [{'name': '1', 'amount': '1212000'}]})] (background error at: http://sqlalche.me/e/f405) check type column (type object) differ columns. give also try convert string got bunch errors. believe simple slut can't get head around."
50711207,How to set sql dialect in IntelliJ,"I'm working with IntelliJ 2017. I want to set the SQL dialect for an sql file. After I created the file, there is a message at the top saying the SQL dialect for the file is not set. When I click on the ""Change Dialect to.."" link, it opens an SQL Dialects menu. On the right, there is a pulldown link to select the dialect, but the pull down menu is empty. I went into Preferences > Languages and Frameworks > SQL Dialects to try to add some, but that menu is also empty and I can't seem to modify any of the fields. 
How do I add SQL dialects to IntelliJ, so I can select one for this file? Below is a photo of the menu I get when I select ""Change Dialect to..."" in the sql file 
Below is a photo of the menu I get from Perferences > Languages and Frameworks > SQL Dialects. I can't edit any of the fields.
",<sql><intellij-idea>,808,2,0,267,1,5,13,68,23063,0.0,0,1,20,2018-06-06 1:53,2018-06-06 5:11,,0.0,,Intermediate,20,"<sql><intellij-idea>, How to set sql dialect in IntelliJ, I'm working with IntelliJ 2017. I want to set the SQL dialect for an sql file. After I created the file, there is a message at the top saying the SQL dialect for the file is not set. When I click on the ""Change Dialect to.."" link, it opens an SQL Dialects menu. On the right, there is a pulldown link to select the dialect, but the pull down menu is empty. I went into Preferences > Languages and Frameworks > SQL Dialects to try to add some, but that menu is also empty and I can't seem to modify any of the fields. 
How do I add SQL dialects to IntelliJ, so I can select one for this file? Below is a photo of the menu I get when I select ""Change Dialect to..."" in the sql file 
Below is a photo of the menu I get from Perferences > Languages and Frameworks > SQL Dialects. I can't edit any of the fields.
","<sal><intellij-idea>, set sal dialect intellij, i'm work intellij 2017. want set sal dialect sal file. great file, message top say sal dialect file set. click ""change dialect to.."" link, open sal dialect menu. right, pulldown link select dialect, pull menu empty. went prefer > language framework > sal dialect try add some, menu also empty can't seem modify fields. add sal dialect intellij, select one file? photo menu get select ""change dialect to..."" sal file photo menu get prefer > language framework > sal dialect. can't edit fields."
49291428,Error: could not determine PostgreSQL version from '10.3' - Django on Heroku,"I tried to push from local env to Heroku master. No new requirements from the previous commit. However, I received an Error which saying the system could not determine PostgreSQL version from ""10.3"".
Here is my requirements list:
amqp==1.4.9
anyjson==0.3.3
appdirs==1.4.3
awscli==1.11.89
billiard==3.3.0.23
boto==2.46.1
botocore==1.5.52
celery==3.1.25
Collectfast==0.5.2
colorama==0.3.7
dj-database-url==0.4.2
Django==1.11.1
django-celery==3.2.1
django-recaptcha==1.3.0
django-redis-cache==1.7.1
django-storages==1.5.2
django-storages-redux==1.3.2
docutils==0.13.1
gunicorn==19.7.0
honcho==0.5.0
jmespath==0.9.2
kombu==3.0.37
olefile==0.44
packaging==16.8
Pillow==4.3.0
psycopg2==2.6.2
pyasn1==0.2.3
pyparsing==2.2.0
python-dateutil==2.6.0
pytz==2018.3
PyYAML==3.12
redis==2.10.5
reportlab==3.4.0
rsa==3.4.2
s3transfer==0.1.10
selenium==3.4.0
six==1.10.0
vine==1.1.4
virtualenv==15.1.0
virtualenvwrapper-win==1.2.1
whitenoise==3.3.0
and below is the error in the build log.
Collecting amqp==1.4.9 (from -r /tmp/build_28bcf3a327daae7657433628289c1501/requirements.txt (line 1))
         Downloading amqp-1.4.9-py2.py3-none-any.whl (51kB)
       Collecting anyjson==0.3.3 (from -r /tmp/build_28bcf3a327daae7657433628289c1501/requirements.txt (line 2))
         Downloading anyjson-0.3.3.tar.gz
       Collecting appdirs==1.4.3 (from -r /tmp/build_28bcf3a327daae7657433628289c1501/requirements.txt (line 3))
         Downloading appdirs-1.4.3-py2.py3-none-any.whl
       Collecting awscli==1.11.89 (from -r /tmp/build_28bcf3a327daae7657433628289c1501/requirements.txt (line 4))
         Downloading awscli-1.11.89-py2.py3-none-any.whl (1.2MB)
       Collecting billiard==3.3.0.23 (from -r /tmp/build_28bcf3a327daae7657433628289c1501/requirements.txt (line 5))
         Downloading billiard-3.3.0.23.tar.gz (151kB)
       Collecting boto==2.46.1 (from -r /tmp/build_28bcf3a327daae7657433628289c1501/requirements.txt (line 6))
         Downloading boto-2.46.1-py2.py3-none-any.whl (1.4MB)
       Collecting botocore==1.5.52 (from -r /tmp/build_28bcf3a327daae7657433628289c1501/requirements.txt (line 7))
         Downloading botocore-1.5.52-py2.py3-none-any.whl (3.5MB)
       Collecting celery==3.1.25 (from -r /tmp/build_28bcf3a327daae7657433628289c1501/requirements.txt (line 8))
         Downloading celery-3.1.25-py2.py3-none-any.whl (526kB)
       Collecting Collectfast==0.5.2 (from -r /tmp/build_28bcf3a327daae7657433628289c1501/requirements.txt (line 9))
         Downloading Collectfast-0.5.2-py3-none-any.whl
       Collecting colorama==0.3.7 (from -r /tmp/build_28bcf3a327daae7657433628289c1501/requirements.txt (line 10))
         Downloading colorama-0.3.7-py2.py3-none-any.whl
       Collecting dj-database-url==0.4.2 (from -r /tmp/build_28bcf3a327daae7657433628289c1501/requirements.txt (line 11))
         Downloading dj_database_url-0.4.2-py2.py3-none-any.whl
       Collecting Django==1.11.1 (from -r /tmp/build_28bcf3a327daae7657433628289c1501/requirements.txt (line 12))
         Downloading Django-1.11.1-py2.py3-none-any.whl (6.9MB)
       Collecting django-celery==3.2.1 (from -r /tmp/build_28bcf3a327daae7657433628289c1501/requirements.txt (line 13))
         Downloading django-celery-3.2.1.tar.gz (91kB)
       Collecting django-recaptcha==1.3.0 (from -r /tmp/build_28bcf3a327daae7657433628289c1501/requirements.txt (line 14))
         Downloading django-recaptcha-1.3.0.tar.gz
       Collecting django-redis-cache==1.7.1 (from -r /tmp/build_28bcf3a327daae7657433628289c1501/requirements.txt (line 15))
         Downloading django-redis-cache-1.7.1.tar.gz
       Collecting django-storages==1.5.2 (from -r /tmp/build_28bcf3a327daae7657433628289c1501/requirements.txt (line 16))
         Downloading django_storages-1.5.2-py2.py3-none-any.whl (51kB)
       Collecting django-storages-redux==1.3.2 (from -r /tmp/build_28bcf3a327daae7657433628289c1501/requirements.txt (line 17))
         Downloading django_storages_redux-1.3.2-py2.py3-none-any.whl (41kB)
       Collecting docutils==0.13.1 (from -r /tmp/build_28bcf3a327daae7657433628289c1501/requirements.txt (line 18))
         Downloading docutils-0.13.1-py3-none-any.whl (536kB)
       Collecting gunicorn==19.7.0 (from -r /tmp/build_28bcf3a327daae7657433628289c1501/requirements.txt (line 19))
         Downloading gunicorn-19.7.0-py2.py3-none-any.whl (112kB)
       Collecting honcho==0.5.0 (from -r /tmp/build_28bcf3a327daae7657433628289c1501/requirements.txt (line 20))
         Downloading honcho-0.5.0.tar.gz
       Collecting jmespath==0.9.2 (from -r /tmp/build_28bcf3a327daae7657433628289c1501/requirements.txt (line 21))
         Downloading jmespath-0.9.2-py2.py3-none-any.whl
       Collecting kombu==3.0.37 (from -r /tmp/build_28bcf3a327daae7657433628289c1501/requirements.txt (line 22))
         Downloading kombu-3.0.37-py2.py3-none-any.whl (240kB)
       Collecting olefile==0.44 (from -r /tmp/build_28bcf3a327daae7657433628289c1501/requirements.txt (line 23))
         Downloading olefile-0.44.zip (74kB)
       Collecting packaging==16.8 (from -r /tmp/build_28bcf3a327daae7657433628289c1501/requirements.txt (line 24))
         Downloading packaging-16.8-py2.py3-none-any.whl
       Collecting Pillow==4.3.0 (from -r /tmp/build_28bcf3a327daae7657433628289c1501/requirements.txt (line 25))
         Downloading Pillow-4.3.0-cp35-cp35m-manylinux1_x86_64.whl (5.8MB)
       Collecting psycopg2==2.6.2 (from -r /tmp/build_28bcf3a327daae7657433628289c1501/requirements.txt (line 26))
         Downloading psycopg2-2.6.2.tar.gz (376kB)
           Complete output from command python setup.py egg_info:
           running egg_info
           creating pip-egg-info/psycopg2.egg-info
           writing pip-egg-info/psycopg2.egg-info/PKG-INFO
           writing top-level names to pip-egg-info/psycopg2.egg-info/top_level.txt
           writing dependency_links to pip-egg-info/psycopg2.egg-info/dependency_links.txt
           writing manifest file 'pip-egg-info/psycopg2.egg-info/SOURCES.txt'
           Error: could not determine PostgreSQL version from '10.3'
           ----------------------------------------
       Command ""python setup.py egg_info"" failed with error code 1 in /tmp/pip-build-24iic71n/psycopg2/
 !     Push rejected, failed to compile Python app.
 !     Push failed
Has anyone ever get through this?
",<django><git><postgresql><heroku><psycopg2>,6308,0,106,253,1,2,9,52,20608,0.0,43,1,20,2018-03-15 4:08,2018-03-15 5:38,2018-03-15 5:38,0.0,0.0,Intermediate,17,"<django><git><postgresql><heroku><psycopg2>, Error: could not determine PostgreSQL version from '10.3' - Django on Heroku, I tried to push from local env to Heroku master. No new requirements from the previous commit. However, I received an Error which saying the system could not determine PostgreSQL version from ""10.3"".
Here is my requirements list:
amqp==1.4.9
anyjson==0.3.3
appdirs==1.4.3
awscli==1.11.89
billiard==3.3.0.23
boto==2.46.1
botocore==1.5.52
celery==3.1.25
Collectfast==0.5.2
colorama==0.3.7
dj-database-url==0.4.2
Django==1.11.1
django-celery==3.2.1
django-recaptcha==1.3.0
django-redis-cache==1.7.1
django-storages==1.5.2
django-storages-redux==1.3.2
docutils==0.13.1
gunicorn==19.7.0
honcho==0.5.0
jmespath==0.9.2
kombu==3.0.37
olefile==0.44
packaging==16.8
Pillow==4.3.0
psycopg2==2.6.2
pyasn1==0.2.3
pyparsing==2.2.0
python-dateutil==2.6.0
pytz==2018.3
PyYAML==3.12
redis==2.10.5
reportlab==3.4.0
rsa==3.4.2
s3transfer==0.1.10
selenium==3.4.0
six==1.10.0
vine==1.1.4
virtualenv==15.1.0
virtualenvwrapper-win==1.2.1
whitenoise==3.3.0
and below is the error in the build log.
Collecting amqp==1.4.9 (from -r /tmp/build_28bcf3a327daae7657433628289c1501/requirements.txt (line 1))
         Downloading amqp-1.4.9-py2.py3-none-any.whl (51kB)
       Collecting anyjson==0.3.3 (from -r /tmp/build_28bcf3a327daae7657433628289c1501/requirements.txt (line 2))
         Downloading anyjson-0.3.3.tar.gz
       Collecting appdirs==1.4.3 (from -r /tmp/build_28bcf3a327daae7657433628289c1501/requirements.txt (line 3))
         Downloading appdirs-1.4.3-py2.py3-none-any.whl
       Collecting awscli==1.11.89 (from -r /tmp/build_28bcf3a327daae7657433628289c1501/requirements.txt (line 4))
         Downloading awscli-1.11.89-py2.py3-none-any.whl (1.2MB)
       Collecting billiard==3.3.0.23 (from -r /tmp/build_28bcf3a327daae7657433628289c1501/requirements.txt (line 5))
         Downloading billiard-3.3.0.23.tar.gz (151kB)
       Collecting boto==2.46.1 (from -r /tmp/build_28bcf3a327daae7657433628289c1501/requirements.txt (line 6))
         Downloading boto-2.46.1-py2.py3-none-any.whl (1.4MB)
       Collecting botocore==1.5.52 (from -r /tmp/build_28bcf3a327daae7657433628289c1501/requirements.txt (line 7))
         Downloading botocore-1.5.52-py2.py3-none-any.whl (3.5MB)
       Collecting celery==3.1.25 (from -r /tmp/build_28bcf3a327daae7657433628289c1501/requirements.txt (line 8))
         Downloading celery-3.1.25-py2.py3-none-any.whl (526kB)
       Collecting Collectfast==0.5.2 (from -r /tmp/build_28bcf3a327daae7657433628289c1501/requirements.txt (line 9))
         Downloading Collectfast-0.5.2-py3-none-any.whl
       Collecting colorama==0.3.7 (from -r /tmp/build_28bcf3a327daae7657433628289c1501/requirements.txt (line 10))
         Downloading colorama-0.3.7-py2.py3-none-any.whl
       Collecting dj-database-url==0.4.2 (from -r /tmp/build_28bcf3a327daae7657433628289c1501/requirements.txt (line 11))
         Downloading dj_database_url-0.4.2-py2.py3-none-any.whl
       Collecting Django==1.11.1 (from -r /tmp/build_28bcf3a327daae7657433628289c1501/requirements.txt (line 12))
         Downloading Django-1.11.1-py2.py3-none-any.whl (6.9MB)
       Collecting django-celery==3.2.1 (from -r /tmp/build_28bcf3a327daae7657433628289c1501/requirements.txt (line 13))
         Downloading django-celery-3.2.1.tar.gz (91kB)
       Collecting django-recaptcha==1.3.0 (from -r /tmp/build_28bcf3a327daae7657433628289c1501/requirements.txt (line 14))
         Downloading django-recaptcha-1.3.0.tar.gz
       Collecting django-redis-cache==1.7.1 (from -r /tmp/build_28bcf3a327daae7657433628289c1501/requirements.txt (line 15))
         Downloading django-redis-cache-1.7.1.tar.gz
       Collecting django-storages==1.5.2 (from -r /tmp/build_28bcf3a327daae7657433628289c1501/requirements.txt (line 16))
         Downloading django_storages-1.5.2-py2.py3-none-any.whl (51kB)
       Collecting django-storages-redux==1.3.2 (from -r /tmp/build_28bcf3a327daae7657433628289c1501/requirements.txt (line 17))
         Downloading django_storages_redux-1.3.2-py2.py3-none-any.whl (41kB)
       Collecting docutils==0.13.1 (from -r /tmp/build_28bcf3a327daae7657433628289c1501/requirements.txt (line 18))
         Downloading docutils-0.13.1-py3-none-any.whl (536kB)
       Collecting gunicorn==19.7.0 (from -r /tmp/build_28bcf3a327daae7657433628289c1501/requirements.txt (line 19))
         Downloading gunicorn-19.7.0-py2.py3-none-any.whl (112kB)
       Collecting honcho==0.5.0 (from -r /tmp/build_28bcf3a327daae7657433628289c1501/requirements.txt (line 20))
         Downloading honcho-0.5.0.tar.gz
       Collecting jmespath==0.9.2 (from -r /tmp/build_28bcf3a327daae7657433628289c1501/requirements.txt (line 21))
         Downloading jmespath-0.9.2-py2.py3-none-any.whl
       Collecting kombu==3.0.37 (from -r /tmp/build_28bcf3a327daae7657433628289c1501/requirements.txt (line 22))
         Downloading kombu-3.0.37-py2.py3-none-any.whl (240kB)
       Collecting olefile==0.44 (from -r /tmp/build_28bcf3a327daae7657433628289c1501/requirements.txt (line 23))
         Downloading olefile-0.44.zip (74kB)
       Collecting packaging==16.8 (from -r /tmp/build_28bcf3a327daae7657433628289c1501/requirements.txt (line 24))
         Downloading packaging-16.8-py2.py3-none-any.whl
       Collecting Pillow==4.3.0 (from -r /tmp/build_28bcf3a327daae7657433628289c1501/requirements.txt (line 25))
         Downloading Pillow-4.3.0-cp35-cp35m-manylinux1_x86_64.whl (5.8MB)
       Collecting psycopg2==2.6.2 (from -r /tmp/build_28bcf3a327daae7657433628289c1501/requirements.txt (line 26))
         Downloading psycopg2-2.6.2.tar.gz (376kB)
           Complete output from command python setup.py egg_info:
           running egg_info
           creating pip-egg-info/psycopg2.egg-info
           writing pip-egg-info/psycopg2.egg-info/PKG-INFO
           writing top-level names to pip-egg-info/psycopg2.egg-info/top_level.txt
           writing dependency_links to pip-egg-info/psycopg2.egg-info/dependency_links.txt
           writing manifest file 'pip-egg-info/psycopg2.egg-info/SOURCES.txt'
           Error: could not determine PostgreSQL version from '10.3'
           ----------------------------------------
       Command ""python setup.py egg_info"" failed with error code 1 in /tmp/pip-build-24iic71n/psycopg2/
 !     Push rejected, failed to compile Python app.
 !     Push failed
Has anyone ever get through this?
","<django><git><postgresql><hero><psycopg2>, error: could determine postgresql version '10.3' - django hero, try push local end hero master. new require previous commit. however, receive error say system could determine postgresql version ""10.3"". require list: amp==1.4.9 anyjson==0.3.3 appears==1.4.3 ascii==1.11.89 belliard==3.3.0.23 both==2.46.1 botocore==1.5.52 every==3.1.25 collectfast==0.5.2 colorado==0.3.7 do-database-curl==0.4.2 django==1.11.1 django-every==3.2.1 django-recaptcha==1.3.0 django-red-ache==1.7.1 django-storage==1.5.2 django-storage-red==1.3.2 docutils==0.13.1 unicorn==19.7.0 hoch==0.5.0 jmespath==0.9.2 comb==3.0.37 defile==0.44 packing==16.8 pillow==4.3.0 psycopg2==2.6.2 pyasn1==0.2.3 pyparsing==2.2.0 patron-dateutil==2.6.0 put==2018.3 pyyaml==3.12 red==2.10.5 reportlab==3.4.0 sa==3.4.2 transfer==0.1.10 selenium==3.4.0 six==1.10.0 vine==1.1.4 virtualenv==15.1.0 virtualenvwrapper-win==1.2.1 whitenoise==3.3.0 error build log. collect amp==1.4.9 (from -r /tm/build_28bcf3a327daae7657433628289c1501/requirements.txt (line 1)) download amp-1.4.9-by.by-none-any.who (51kb) collect anyjson==0.3.3 (from -r /tm/build_28bcf3a327daae7657433628289c1501/requirements.txt (line 2)) download anyjson-0.3.3.tar.go collect appears==1.4.3 (from -r /tm/build_28bcf3a327daae7657433628289c1501/requirements.txt (line 3)) download appears-1.4.3-by.by-none-any.who collect ascii==1.11.89 (from -r /tm/build_28bcf3a327daae7657433628289c1501/requirements.txt (line 4)) download ascii-1.11.89-by.by-none-any.who (1.mb) collect belliard==3.3.0.23 (from -r /tm/build_28bcf3a327daae7657433628289c1501/requirements.txt (line 5)) download belliard-3.3.0.23.tar.go (151kb) collect both==2.46.1 (from -r /tm/build_28bcf3a327daae7657433628289c1501/requirements.txt (line 6)) download both-2.46.1-by.by-none-any.who (1.mb) collect botocore==1.5.52 (from -r /tm/build_28bcf3a327daae7657433628289c1501/requirements.txt (line 7)) download botocore-1.5.52-by.by-none-any.who (3.mb) collect every==3.1.25 (from -r /tm/build_28bcf3a327daae7657433628289c1501/requirements.txt (line 8)) download every-3.1.25-by.by-none-any.who (526kb) collect collectfast==0.5.2 (from -r /tm/build_28bcf3a327daae7657433628289c1501/requirements.txt (line 9)) download collectfast-0.5.2-by-none-any.who collect colorado==0.3.7 (from -r /tm/build_28bcf3a327daae7657433628289c1501/requirements.txt (line 10)) download colorado-0.3.7-by.by-none-any.who collect do-database-curl==0.4.2 (from -r /tm/build_28bcf3a327daae7657433628289c1501/requirements.txt (line 11)) download dj_database_url-0.4.2-by.by-none-any.who collect django==1.11.1 (from -r /tm/build_28bcf3a327daae7657433628289c1501/requirements.txt (line 12)) download django-1.11.1-by.by-none-any.who (6.mb) collect django-every==3.2.1 (from -r /tm/build_28bcf3a327daae7657433628289c1501/requirements.txt (line 13)) download django-every-3.2.1.tar.go (91kb) collect django-recaptcha==1.3.0 (from -r /tm/build_28bcf3a327daae7657433628289c1501/requirements.txt (line 14)) download django-recaptcha-1.3.0.tar.go collect django-red-ache==1.7.1 (from -r /tm/build_28bcf3a327daae7657433628289c1501/requirements.txt (line 15)) download django-red-ache-1.7.1.tar.go collect django-storage==1.5.2 (from -r /tm/build_28bcf3a327daae7657433628289c1501/requirements.txt (line 16)) download django_storages-1.5.2-by.by-none-any.who (51kb) collect django-storage-red==1.3.2 (from -r /tm/build_28bcf3a327daae7657433628289c1501/requirements.txt (line 17)) download django_storages_redux-1.3.2-by.by-none-any.who (41kb) collect docutils==0.13.1 (from -r /tm/build_28bcf3a327daae7657433628289c1501/requirements.txt (line 18)) download docutils-0.13.1-by-none-any.who (536kb) collect unicorn==19.7.0 (from -r /tm/build_28bcf3a327daae7657433628289c1501/requirements.txt (line 19)) download unicorn-19.7.0-by.by-none-any.who (112kb) collect hoch==0.5.0 (from -r /tm/build_28bcf3a327daae7657433628289c1501/requirements.txt (line 20)) download hoch-0.5.0.tar.go collect jmespath==0.9.2 (from -r /tm/build_28bcf3a327daae7657433628289c1501/requirements.txt (line 21)) download jmespath-0.9.2-by.by-none-any.who collect comb==3.0.37 (from -r /tm/build_28bcf3a327daae7657433628289c1501/requirements.txt (line 22)) download comb-3.0.37-by.by-none-any.who (240kb) collect defile==0.44 (from -r /tm/build_28bcf3a327daae7657433628289c1501/requirements.txt (line 23)) download defile-0.44.zip (74kb) collect packing==16.8 (from -r /tm/build_28bcf3a327daae7657433628289c1501/requirements.txt (line 24)) download packing-16.8-by.by-none-any.who collect pillow==4.3.0 (from -r /tm/build_28bcf3a327daae7657433628289c1501/requirements.txt (line 25)) download pillow-4.3.0-cp35-cp35m-manylinux1_x86_64.who (5.mb) collect psycopg2==2.6.2 (from -r /tm/build_28bcf3a327daae7657433628289c1501/requirements.txt (line 26)) download psycopg2-2.6.2.tar.go (376kb) complete output command patron set.i egg_info: run egg_info great pp-egg-into/psycopg2.egg-into write pp-egg-into/psycopg2.egg-into/pig-into write top-level name pp-egg-into/psycopg2.egg-into/top_level.txt write dependency_link pp-egg-into/psycopg2.egg-into/dependency_links.txt write manifest file 'pp-egg-into/psycopg2.egg-into/sources.txt' error: could determine postgresql version '10.3' ---------------------------------------- command ""patron set.i egg_info"" fail error code 1 /tm/pp-build-24iic71n/psycopg2/ ! push rejected, fail compel patron pp. ! push fail anyone ever get this?"
61981787,"Is there a rule that forbids to name its entity class ""User"" when working with PostgreSQL and Spring Boot?","guys. I'm having a problem with a Spring boot 2.3.0  and PostgreSQL 12 project. I have an entity class I called User whose code is as follows:
@Entity
@NoArgsConstructor
@Data
@AllArgsConstructor
@Builder
public class User {
    @Id @GeneratedValue(strategy = GenerationType.IDENTITY)
    private Long id;
    private String username;
    private String email;
    private String firstName;
    private String lastName;
    private int age;
}
And my application.properties file looks like this:
spring.jpa.hibernate.ddl-auto=create-drop
spring.jpa.hibernate.show-sql=true
spring.datasource.url=jdbc:postgresql://localhost:5432/dbname
spring.datasource.username=postgres
spring.datasource.password=*********
The concern is that when I execute my project I get a mistake like this:
org.hibernate.tool.schema.spi.CommandAcceptanceException: Error executing DDL ""drop table if exists user cascade"" via JDBC Statement
    at org.hibernate.tool.schema.internal.exec.GenerationTargetToDatabase.accept(GenerationTargetToDatabase.java:67) ~[hibernate-core-5.4.15.Final.jar:5.4.15.Final]
    at org.hibernate.tool.schema.internal.SchemaDropperImpl.applySqlString(SchemaDropperImpl.java:375) [hibernate-core-5.4.15.Final.jar:5.4.15.Final]
    at org.hibernate.tool.schema.internal.SchemaDropperImpl.applySqlStrings(SchemaDropperImpl.java:359) [hibernate-core-5.4.15.Final.jar:5.4.15.Final]
    at org.hibernate.tool.schema.internal.SchemaDropperImpl.dropFromMetadata(SchemaDropperImpl.java:241) [hibernate-core-5.4.15.Final.jar:5.4.15.Final]
    at org.hibernate.tool.schema.internal.SchemaDropperImpl.performDrop(SchemaDropperImpl.java:154) [hibernate-core-5.4.15.Final.jar:5.4.15.Final]
    at org.hibernate.tool.schema.internal.SchemaDropperImpl.doDrop(SchemaDropperImpl.java:126) [hibernate-core-5.4.15.Final.jar:5.4.15.Final]
    at org.hibernate.tool.schema.internal.SchemaDropperImpl.doDrop(SchemaDropperImpl.java:112) [hibernate-core-5.4.15.Final.jar:5.4.15.Final]
    at org.hibernate.tool.schema.spi.SchemaManagementToolCoordinator.performDatabaseAction(SchemaManagementToolCoordinator.java:145) [hibernate-core-5.4.15.Final.jar:5.4.15.Final]
    at org.hibernate.tool.schema.spi.SchemaManagementToolCoordinator.process(SchemaManagementToolCoordinator.java:73) [hibernate-core-5.4.15.Final.jar:5.4.15.Final]
    at org.hibernate.internal.SessionFactoryImpl.&lt;init&gt;(SessionFactoryImpl.java:314) [hibernate-core-5.4.15.Final.jar:5.4.15.Final]
    at org.hibernate.boot.internal.SessionFactoryBuilderImpl.build(SessionFactoryBuilderImpl.java:468) [hibernate-core-5.4.15.Final.jar:5.4.15.Final]
    at org.hibernate.jpa.boot.internal.EntityManagerFactoryBuilderImpl.build(EntityManagerFactoryBuilderImpl.java:1249) [hibernate-core-5.4.15.Final.jar:5.4.15.Final]
    at org.springframework.orm.jpa.vendor.SpringHibernateJpaPersistenceProvider.createContainerEntityManagerFactory(SpringHibernateJpaPersistenceProvider.java:58) [spring-orm-5.2.6.RELEASE.jar:5.2.6.RELEASE]
    at org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean.createNativeEntityManagerFactory(LocalContainerEntityManagerFactoryBean.java:365) [spring-orm-5.2.6.RELEASE.jar:5.2.6.RELEASE]
    at org.springframework.orm.jpa.AbstractEntityManagerFactoryBean.buildNativeEntityManagerFactory(AbstractEntityManagerFactoryBean.java:391) [spring-orm-5.2.6.RELEASE.jar:5.2.6.RELEASE]
    at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[na:1.8.0_252]
    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[na:1.8.0_252]
    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[na:1.8.0_252]
    at java.lang.Thread.run(Thread.java:748) ~[na:1.8.0_252]
Caused by: org.postgresql.util.PSQLException: ERREUR: erreur de syntaxe sur ou près de « user »
  Position : 22
    at org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2533) ~[postgresql-42.2.12.jar:42.2.12]
    at org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2268) ~[postgresql-42.2.12.jar:42.2.12]
    at org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:313) ~[postgresql-42.2.12.jar:42.2.12]
    at org.postgresql.jdbc.PgStatement.executeInternal(PgStatement.java:448) ~[postgresql-42.2.12.jar:42.2.12]
    at org.postgresql.jdbc.PgStatement.execute(PgStatement.java:369) ~[postgresql-42.2.12.jar:42.2.12]
    at org.postgresql.jdbc.PgStatement.executeWithFlags(PgStatement.java:310) ~[postgresql-42.2.12.jar:42.2.12]
    at org.postgresql.jdbc.PgStatement.executeCachedSql(PgStatement.java:296) ~[postgresql-42.2.12.jar:42.2.12]
    at org.postgresql.jdbc.PgStatement.executeWithFlags(PgStatement.java:273) ~[postgresql-42.2.12.jar:42.2.12]
    at org.postgresql.jdbc.PgStatement.execute(PgStatement.java:268) ~[postgresql-42.2.12.jar:42.2.12]
    at com.zaxxer.hikari.pool.ProxyStatement.execute(ProxyStatement.java:95) ~[HikariCP-3.4.5.jar:na]
    at com.zaxxer.hikari.pool.HikariProxyStatement.execute(HikariProxyStatement.java) ~[HikariCP-3.4.5.jar:na]
    at org.hibernate.tool.schema.internal.exec.GenerationTargetToDatabase.accept(GenerationTargetToDatabase.java:54) ~[hibernate-core-5.4.15.Final.jar:5.4.15.Final]
    ... 18 common frames omitted
2020-05-24 06:16:33.429  WARN 13636 --- [         task-1] o.h.t.s.i.ExceptionHandlerLoggedImpl     : GenerationTarget encountered exception accepting command : Error executing DDL ""create table user (id int8 generated by default as identity, age int4 not null, email varchar(255), first_name varchar(255), last_name varchar(255), username varchar(255), primary key (id))"" via JDBC Statement
org.hibernate.tool.schema.spi.CommandAcceptanceException: Error executing DDL ""create table user (id int8 generated by default as identity, age int4 not null, email varchar(255), first_name varchar(255), last_name varchar(255), username varchar(255), primary key (id))"" via JDBC Statement
    at org.hibernate.tool.schema.internal.exec.GenerationTargetToDatabase.accept(GenerationTargetToDatabase.java:67) ~[hibernate-core-5.4.15.Final.jar:5.4.15.Final]
    at org.hibernate.tool.schema.internal.SchemaCreatorImpl.applySqlString(SchemaCreatorImpl.java:439) [hibernate-core-5.4.15.Final.jar:5.4.15.Final]
    at org.hibernate.tool.schema.internal.SchemaCreatorImpl.applySqlStrings(SchemaCreatorImpl.java:423) [hibernate-core-5.4.15.Final.jar:5.4.15.Final]
    at org.hibernate.tool.schema.internal.SchemaCreatorImpl.createFromMetadata(SchemaCreatorImpl.java:314) [hibernate-core-5.4.15.Final.jar:5.4.15.Final]
    at org.hibernate.tool.schema.internal.SchemaCreatorImpl.performCreation(SchemaCreatorImpl.java:166) [hibernate-core-5.4.15.Final.jar:5.4.15.Final]
    at org.hibernate.tool.schema.internal.SchemaCreatorImpl.doCreation(SchemaCreatorImpl.java:135) [hibernate-core-5.4.15.Final.jar:5.4.15.Final]
    at org.hibernate.tool.schema.internal.SchemaCreatorImpl.doCreation(SchemaCreatorImpl.java:121) [hibernate-core-5.4.15.Final.jar:5.4.15.Final]
    at org.hibernate.tool.schema.spi.SchemaManagementToolCoordinator.performDatabaseAction(SchemaManagementToolCoordinator.java:156) [hibernate-core-5.4.15.Final.jar:5.4.15.Final]
    at org.hibernate.tool.schema.spi.SchemaManagementToolCoordinator.process(SchemaManagementToolCoordinator.java:73) [hibernate-core-5.4.15.Final.jar:5.4.15.Final]
    at org.hibernate.internal.SessionFactoryImpl.&lt;init&gt;(SessionFactoryImpl.java:314) [hibernate-core-5.4.15.Final.jar:5.4.15.Final]
    at org.hibernate.boot.internal.SessionFactoryBuilderImpl.build(SessionFactoryBuilderImpl.java:468) [hibernate-core-5.4.15.Final.jar:5.4.15.Final]
    at org.hibernate.jpa.boot.internal.EntityManagerFactoryBuilderImpl.build(EntityManagerFactoryBuilderImpl.java:1249) [hibernate-core-5.4.15.Final.jar:5.4.15.Final]
    at org.springframework.orm.jpa.vendor.SpringHibernateJpaPersistenceProvider.createContainerEntityManagerFactory(SpringHibernateJpaPersistenceProvider.java:58) [spring-orm-5.2.6.RELEASE.jar:5.2.6.RELEASE]
    at org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean.createNativeEntityManagerFactory(LocalContainerEntityManagerFactoryBean.java:365) [spring-orm-5.2.6.RELEASE.jar:5.2.6.RELEASE]
    at org.springframework.orm.jpa.AbstractEntityManagerFactoryBean.buildNativeEntityManagerFactory(AbstractEntityManagerFactoryBean.java:391) [spring-orm-5.2.6.RELEASE.jar:5.2.6.RELEASE]
    at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[na:1.8.0_252]
    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[na:1.8.0_252]
    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[na:1.8.0_252]
    at java.lang.Thread.run(Thread.java:748) ~[na:1.8.0_252]
Caused by: org.postgresql.util.PSQLException: ERREUR: erreur de syntaxe sur ou près de « user »
  Position : 14
    at org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2533) ~[postgresql-42.2.12.jar:42.2.12]
    at org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2268) ~[postgresql-42.2.12.jar:42.2.12]
    at org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:313) ~[postgresql-42.2.12.jar:42.2.12]
    at org.postgresql.jdbc.PgStatement.executeInternal(PgStatement.java:448) ~[postgresql-42.2.12.jar:42.2.12]
    at org.postgresql.jdbc.PgStatement.execute(PgStatement.java:369) ~[postgresql-42.2.12.jar:42.2.12]
    at org.postgresql.jdbc.PgStatement.executeWithFlags(PgStatement.java:310) ~[postgresql-42.2.12.jar:42.2.12]
    at org.postgresql.jdbc.PgStatement.executeCachedSql(PgStatement.java:296) ~[postgresql-42.2.12.jar:42.2.12]
    at org.postgresql.jdbc.PgStatement.executeWithFlags(PgStatement.java:273) ~[postgresql-42.2.12.jar:42.2.12]
    at org.postgresql.jdbc.PgStatement.execute(PgStatement.java:268) ~[postgresql-42.2.12.jar:42.2.12]
    at com.zaxxer.hikari.pool.ProxyStatement.execute(ProxyStatement.java:95) ~[HikariCP-3.4.5.jar:na]
    at com.zaxxer.hikari.pool.HikariProxyStatement.execute(HikariProxyStatement.java) ~[HikariCP-3.4.5.jar:na]
    at org.hibernate.tool.schema.internal.exec.GenerationTargetToDatabase.accept(GenerationTargetToDatabase.java:54) ~[hibernate-core-5.4.15.Final.jar:5.4.15.Final]
    ... 18 common frames omitted
However when I change the name of my class e.g. to Person 
@Entity
@NoArgsConstructor
@Data
@AllArgsConstructor
@Builder
public class Person {
    @Id @GeneratedValue(strategy = GenerationType.IDENTITY)
    private Long id;
    private String username;
    private String email;
    private String firstName;
    private String lastName;
    private int age;
}
I don't get any errors. Could someone help me with this in the following way or at least explain me what is wrong with the entity class User.
I would also like to add that when in doubt I tested this code with MySQL as an alternative to PostgreSQL and got no errors.
",<java><postgresql><hibernate><spring-boot><jpa>,10925,0,106,193,1,1,4,50,12911,0.0,0,3,19,2020-05-24 4:52,2020-05-24 5:07,2020-05-24 5:07,0.0,0.0,Intermediate,19,"<java><postgresql><hibernate><spring-boot><jpa>, Is there a rule that forbids to name its entity class ""User"" when working with PostgreSQL and Spring Boot?, guys. I'm having a problem with a Spring boot 2.3.0  and PostgreSQL 12 project. I have an entity class I called User whose code is as follows:
@Entity
@NoArgsConstructor
@Data
@AllArgsConstructor
@Builder
public class User {
    @Id @GeneratedValue(strategy = GenerationType.IDENTITY)
    private Long id;
    private String username;
    private String email;
    private String firstName;
    private String lastName;
    private int age;
}
And my application.properties file looks like this:
spring.jpa.hibernate.ddl-auto=create-drop
spring.jpa.hibernate.show-sql=true
spring.datasource.url=jdbc:postgresql://localhost:5432/dbname
spring.datasource.username=postgres
spring.datasource.password=*********
The concern is that when I execute my project I get a mistake like this:
org.hibernate.tool.schema.spi.CommandAcceptanceException: Error executing DDL ""drop table if exists user cascade"" via JDBC Statement
    at org.hibernate.tool.schema.internal.exec.GenerationTargetToDatabase.accept(GenerationTargetToDatabase.java:67) ~[hibernate-core-5.4.15.Final.jar:5.4.15.Final]
    at org.hibernate.tool.schema.internal.SchemaDropperImpl.applySqlString(SchemaDropperImpl.java:375) [hibernate-core-5.4.15.Final.jar:5.4.15.Final]
    at org.hibernate.tool.schema.internal.SchemaDropperImpl.applySqlStrings(SchemaDropperImpl.java:359) [hibernate-core-5.4.15.Final.jar:5.4.15.Final]
    at org.hibernate.tool.schema.internal.SchemaDropperImpl.dropFromMetadata(SchemaDropperImpl.java:241) [hibernate-core-5.4.15.Final.jar:5.4.15.Final]
    at org.hibernate.tool.schema.internal.SchemaDropperImpl.performDrop(SchemaDropperImpl.java:154) [hibernate-core-5.4.15.Final.jar:5.4.15.Final]
    at org.hibernate.tool.schema.internal.SchemaDropperImpl.doDrop(SchemaDropperImpl.java:126) [hibernate-core-5.4.15.Final.jar:5.4.15.Final]
    at org.hibernate.tool.schema.internal.SchemaDropperImpl.doDrop(SchemaDropperImpl.java:112) [hibernate-core-5.4.15.Final.jar:5.4.15.Final]
    at org.hibernate.tool.schema.spi.SchemaManagementToolCoordinator.performDatabaseAction(SchemaManagementToolCoordinator.java:145) [hibernate-core-5.4.15.Final.jar:5.4.15.Final]
    at org.hibernate.tool.schema.spi.SchemaManagementToolCoordinator.process(SchemaManagementToolCoordinator.java:73) [hibernate-core-5.4.15.Final.jar:5.4.15.Final]
    at org.hibernate.internal.SessionFactoryImpl.&lt;init&gt;(SessionFactoryImpl.java:314) [hibernate-core-5.4.15.Final.jar:5.4.15.Final]
    at org.hibernate.boot.internal.SessionFactoryBuilderImpl.build(SessionFactoryBuilderImpl.java:468) [hibernate-core-5.4.15.Final.jar:5.4.15.Final]
    at org.hibernate.jpa.boot.internal.EntityManagerFactoryBuilderImpl.build(EntityManagerFactoryBuilderImpl.java:1249) [hibernate-core-5.4.15.Final.jar:5.4.15.Final]
    at org.springframework.orm.jpa.vendor.SpringHibernateJpaPersistenceProvider.createContainerEntityManagerFactory(SpringHibernateJpaPersistenceProvider.java:58) [spring-orm-5.2.6.RELEASE.jar:5.2.6.RELEASE]
    at org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean.createNativeEntityManagerFactory(LocalContainerEntityManagerFactoryBean.java:365) [spring-orm-5.2.6.RELEASE.jar:5.2.6.RELEASE]
    at org.springframework.orm.jpa.AbstractEntityManagerFactoryBean.buildNativeEntityManagerFactory(AbstractEntityManagerFactoryBean.java:391) [spring-orm-5.2.6.RELEASE.jar:5.2.6.RELEASE]
    at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[na:1.8.0_252]
    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[na:1.8.0_252]
    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[na:1.8.0_252]
    at java.lang.Thread.run(Thread.java:748) ~[na:1.8.0_252]
Caused by: org.postgresql.util.PSQLException: ERREUR: erreur de syntaxe sur ou près de « user »
  Position : 22
    at org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2533) ~[postgresql-42.2.12.jar:42.2.12]
    at org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2268) ~[postgresql-42.2.12.jar:42.2.12]
    at org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:313) ~[postgresql-42.2.12.jar:42.2.12]
    at org.postgresql.jdbc.PgStatement.executeInternal(PgStatement.java:448) ~[postgresql-42.2.12.jar:42.2.12]
    at org.postgresql.jdbc.PgStatement.execute(PgStatement.java:369) ~[postgresql-42.2.12.jar:42.2.12]
    at org.postgresql.jdbc.PgStatement.executeWithFlags(PgStatement.java:310) ~[postgresql-42.2.12.jar:42.2.12]
    at org.postgresql.jdbc.PgStatement.executeCachedSql(PgStatement.java:296) ~[postgresql-42.2.12.jar:42.2.12]
    at org.postgresql.jdbc.PgStatement.executeWithFlags(PgStatement.java:273) ~[postgresql-42.2.12.jar:42.2.12]
    at org.postgresql.jdbc.PgStatement.execute(PgStatement.java:268) ~[postgresql-42.2.12.jar:42.2.12]
    at com.zaxxer.hikari.pool.ProxyStatement.execute(ProxyStatement.java:95) ~[HikariCP-3.4.5.jar:na]
    at com.zaxxer.hikari.pool.HikariProxyStatement.execute(HikariProxyStatement.java) ~[HikariCP-3.4.5.jar:na]
    at org.hibernate.tool.schema.internal.exec.GenerationTargetToDatabase.accept(GenerationTargetToDatabase.java:54) ~[hibernate-core-5.4.15.Final.jar:5.4.15.Final]
    ... 18 common frames omitted
2020-05-24 06:16:33.429  WARN 13636 --- [         task-1] o.h.t.s.i.ExceptionHandlerLoggedImpl     : GenerationTarget encountered exception accepting command : Error executing DDL ""create table user (id int8 generated by default as identity, age int4 not null, email varchar(255), first_name varchar(255), last_name varchar(255), username varchar(255), primary key (id))"" via JDBC Statement
org.hibernate.tool.schema.spi.CommandAcceptanceException: Error executing DDL ""create table user (id int8 generated by default as identity, age int4 not null, email varchar(255), first_name varchar(255), last_name varchar(255), username varchar(255), primary key (id))"" via JDBC Statement
    at org.hibernate.tool.schema.internal.exec.GenerationTargetToDatabase.accept(GenerationTargetToDatabase.java:67) ~[hibernate-core-5.4.15.Final.jar:5.4.15.Final]
    at org.hibernate.tool.schema.internal.SchemaCreatorImpl.applySqlString(SchemaCreatorImpl.java:439) [hibernate-core-5.4.15.Final.jar:5.4.15.Final]
    at org.hibernate.tool.schema.internal.SchemaCreatorImpl.applySqlStrings(SchemaCreatorImpl.java:423) [hibernate-core-5.4.15.Final.jar:5.4.15.Final]
    at org.hibernate.tool.schema.internal.SchemaCreatorImpl.createFromMetadata(SchemaCreatorImpl.java:314) [hibernate-core-5.4.15.Final.jar:5.4.15.Final]
    at org.hibernate.tool.schema.internal.SchemaCreatorImpl.performCreation(SchemaCreatorImpl.java:166) [hibernate-core-5.4.15.Final.jar:5.4.15.Final]
    at org.hibernate.tool.schema.internal.SchemaCreatorImpl.doCreation(SchemaCreatorImpl.java:135) [hibernate-core-5.4.15.Final.jar:5.4.15.Final]
    at org.hibernate.tool.schema.internal.SchemaCreatorImpl.doCreation(SchemaCreatorImpl.java:121) [hibernate-core-5.4.15.Final.jar:5.4.15.Final]
    at org.hibernate.tool.schema.spi.SchemaManagementToolCoordinator.performDatabaseAction(SchemaManagementToolCoordinator.java:156) [hibernate-core-5.4.15.Final.jar:5.4.15.Final]
    at org.hibernate.tool.schema.spi.SchemaManagementToolCoordinator.process(SchemaManagementToolCoordinator.java:73) [hibernate-core-5.4.15.Final.jar:5.4.15.Final]
    at org.hibernate.internal.SessionFactoryImpl.&lt;init&gt;(SessionFactoryImpl.java:314) [hibernate-core-5.4.15.Final.jar:5.4.15.Final]
    at org.hibernate.boot.internal.SessionFactoryBuilderImpl.build(SessionFactoryBuilderImpl.java:468) [hibernate-core-5.4.15.Final.jar:5.4.15.Final]
    at org.hibernate.jpa.boot.internal.EntityManagerFactoryBuilderImpl.build(EntityManagerFactoryBuilderImpl.java:1249) [hibernate-core-5.4.15.Final.jar:5.4.15.Final]
    at org.springframework.orm.jpa.vendor.SpringHibernateJpaPersistenceProvider.createContainerEntityManagerFactory(SpringHibernateJpaPersistenceProvider.java:58) [spring-orm-5.2.6.RELEASE.jar:5.2.6.RELEASE]
    at org.springframework.orm.jpa.LocalContainerEntityManagerFactoryBean.createNativeEntityManagerFactory(LocalContainerEntityManagerFactoryBean.java:365) [spring-orm-5.2.6.RELEASE.jar:5.2.6.RELEASE]
    at org.springframework.orm.jpa.AbstractEntityManagerFactoryBean.buildNativeEntityManagerFactory(AbstractEntityManagerFactoryBean.java:391) [spring-orm-5.2.6.RELEASE.jar:5.2.6.RELEASE]
    at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[na:1.8.0_252]
    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[na:1.8.0_252]
    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[na:1.8.0_252]
    at java.lang.Thread.run(Thread.java:748) ~[na:1.8.0_252]
Caused by: org.postgresql.util.PSQLException: ERREUR: erreur de syntaxe sur ou près de « user »
  Position : 14
    at org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2533) ~[postgresql-42.2.12.jar:42.2.12]
    at org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2268) ~[postgresql-42.2.12.jar:42.2.12]
    at org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:313) ~[postgresql-42.2.12.jar:42.2.12]
    at org.postgresql.jdbc.PgStatement.executeInternal(PgStatement.java:448) ~[postgresql-42.2.12.jar:42.2.12]
    at org.postgresql.jdbc.PgStatement.execute(PgStatement.java:369) ~[postgresql-42.2.12.jar:42.2.12]
    at org.postgresql.jdbc.PgStatement.executeWithFlags(PgStatement.java:310) ~[postgresql-42.2.12.jar:42.2.12]
    at org.postgresql.jdbc.PgStatement.executeCachedSql(PgStatement.java:296) ~[postgresql-42.2.12.jar:42.2.12]
    at org.postgresql.jdbc.PgStatement.executeWithFlags(PgStatement.java:273) ~[postgresql-42.2.12.jar:42.2.12]
    at org.postgresql.jdbc.PgStatement.execute(PgStatement.java:268) ~[postgresql-42.2.12.jar:42.2.12]
    at com.zaxxer.hikari.pool.ProxyStatement.execute(ProxyStatement.java:95) ~[HikariCP-3.4.5.jar:na]
    at com.zaxxer.hikari.pool.HikariProxyStatement.execute(HikariProxyStatement.java) ~[HikariCP-3.4.5.jar:na]
    at org.hibernate.tool.schema.internal.exec.GenerationTargetToDatabase.accept(GenerationTargetToDatabase.java:54) ~[hibernate-core-5.4.15.Final.jar:5.4.15.Final]
    ... 18 common frames omitted
However when I change the name of my class e.g. to Person 
@Entity
@NoArgsConstructor
@Data
@AllArgsConstructor
@Builder
public class Person {
    @Id @GeneratedValue(strategy = GenerationType.IDENTITY)
    private Long id;
    private String username;
    private String email;
    private String firstName;
    private String lastName;
    private int age;
}
I don't get any errors. Could someone help me with this in the following way or at least explain me what is wrong with the entity class User.
I would also like to add that when in doubt I tested this code with MySQL as an alternative to PostgreSQL and got no errors.
","<cava><postgresql><liberate><spring-boot><pa>, rule forbid name entity class ""user"" work postgresql spring boot?, guns. i'm problem spring boot 2.3.0 postgresql 12 project. entity class call user whose code follows: @entity @noargsconstructor @data @allargsconstructor @builder public class user { @id @generatedvalue(strategic = generationtype.identity) privat long id; privat string surname; privat string email; privat string firstname; privat string lastname; privat in age; } application.property file look like this: spring.pa.liberate.del-auto=create-drop spring.pa.liberate.show-sal=true spring.datasource.curl=job:postgresql://localhost:5432/dream spring.datasource.surname=poster spring.datasource.password=********* concern execute project get mistake like this: org.liberate.tool.scheme.spy.commandacceptanceexception: error execute del ""drop table exist user cascade"" via job statement org.liberate.tool.scheme.internal.even.generationtargettodatabase.accept(generationtargettodatabase.cava:67) ~[liberate-core-5.4.15.final.jar:5.4.15.final] org.liberate.tool.scheme.internal.schemadropperimpl.applysqlstring(schemadropperimpl.cava:375) [liberate-core-5.4.15.final.jar:5.4.15.final] org.liberate.tool.scheme.internal.schemadropperimpl.applysqlstrings(schemadropperimpl.cava:359) [liberate-core-5.4.15.final.jar:5.4.15.final] org.liberate.tool.scheme.internal.schemadropperimpl.dropfrommetadata(schemadropperimpl.cava:241) [liberate-core-5.4.15.final.jar:5.4.15.final] org.liberate.tool.scheme.internal.schemadropperimpl.performdrop(schemadropperimpl.cava:154) [liberate-core-5.4.15.final.jar:5.4.15.final] org.liberate.tool.scheme.internal.schemadropperimpl.drop(schemadropperimpl.cava:126) [liberate-core-5.4.15.final.jar:5.4.15.final] org.liberate.tool.scheme.internal.schemadropperimpl.drop(schemadropperimpl.cava:112) [liberate-core-5.4.15.final.jar:5.4.15.final] org.liberate.tool.scheme.spy.schemamanagementtoolcoordinator.performdatabaseaction(schemamanagementtoolcoordinator.cava:145) [liberate-core-5.4.15.final.jar:5.4.15.final] org.liberate.tool.scheme.spy.schemamanagementtoolcoordinator.process(schemamanagementtoolcoordinator.cava:73) [liberate-core-5.4.15.final.jar:5.4.15.final] org.liberate.internal.sessionfactoryimpl.&it;knit&it;(sessionfactoryimpl.cava:314) [liberate-core-5.4.15.final.jar:5.4.15.final] org.liberate.boot.internal.sessionfactorybuilderimpl.build(sessionfactorybuilderimpl.cava:468) [liberate-core-5.4.15.final.jar:5.4.15.final] org.liberate.pa.boot.internal.entitymanagerfactorybuilderimpl.build(entitymanagerfactorybuilderimpl.cava:1249) [liberate-core-5.4.15.final.jar:5.4.15.final] org.springframework.or.pa.vendor.springhibernatejpapersistenceprovider.createcontainerentitymanagerfactory(springhibernatejpapersistenceprovider.cava:58) [spring-or-5.2.6.release.jar:5.2.6.release] org.springframework.or.pa.localcontainerentitymanagerfactorybean.createnativeentitymanagerfactory(localcontainerentitymanagerfactorybean.cava:365) [spring-or-5.2.6.release.jar:5.2.6.release] org.springframework.or.pa.abstractentitymanagerfactorybean.buildnativeentitymanagerfactory(abstractentitymanagerfactorybean.cava:391) [spring-or-5.2.6.release.jar:5.2.6.release] cava.until.concurrent.futuretask.run(futuretask.cava:266) ~[na:1.8.0_252] cava.until.concurrent.threadpoolexecutor.runworker(threadpoolexecutor.cava:1149) ~[na:1.8.0_252] cava.until.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.cava:624) ~[na:1.8.0_252] cava.long.thread.run(thread.cava:748) ~[na:1.8.0_252] cause by: org.postgresql.until.psqlexception: error: error de santa sur ou pre de « user » post : 22 org.postgresql.core.ve.queryexecutorimpl.receiveerrorresponse(queryexecutorimpl.cava:2533) ~[postgresql-42.2.12.jar:42.2.12] org.postgresql.core.ve.queryexecutorimpl.processresults(queryexecutorimpl.cava:2268) ~[postgresql-42.2.12.jar:42.2.12] org.postgresql.core.ve.queryexecutorimpl.execute(queryexecutorimpl.cava:313) ~[postgresql-42.2.12.jar:42.2.12] org.postgresql.job.statement.executeinternal(statement.cava:448) ~[postgresql-42.2.12.jar:42.2.12] org.postgresql.job.statement.execute(statement.cava:369) ~[postgresql-42.2.12.jar:42.2.12] org.postgresql.job.statement.executewithflags(statement.cava:310) ~[postgresql-42.2.12.jar:42.2.12] org.postgresql.job.statement.executecachedsql(statement.cava:296) ~[postgresql-42.2.12.jar:42.2.12] org.postgresql.job.statement.executewithflags(statement.cava:273) ~[postgresql-42.2.12.jar:42.2.12] org.postgresql.job.statement.execute(statement.cava:268) ~[postgresql-42.2.12.jar:42.2.12] com.baxter.kari.pool.proxystatement.execute(proxystatement.cava:95) ~[hikaricp-3.4.5.jar:na] com.baxter.kari.pool.hikariproxystatement.execute(hikariproxystatement.cava) ~[hikaricp-3.4.5.jar:na] org.liberate.tool.scheme.internal.even.generationtargettodatabase.accept(generationtargettodatabase.cava:54) ~[liberate-core-5.4.15.final.jar:5.4.15.final] ... 18 common frame omit 2020-05-24 06:16:33.429 warn 13636 --- [ task-1] o.h.t.s.i.exceptionhandlerloggedimpl : generationtarget count except accept command : error execute del ""great table user (id into genet default identity, age into null, email varchar(255), first_nam varchar(255), last_nam varchar(255), usernam varchar(255), primary key (id))"" via job statement org.liberate.tool.scheme.spy.commandacceptanceexception: error execute del ""great table user (id into genet default identity, age into null, email varchar(255), first_nam varchar(255), last_nam varchar(255), usernam varchar(255), primary key (id))"" via job statement org.liberate.tool.scheme.internal.even.generationtargettodatabase.accept(generationtargettodatabase.cava:67) ~[liberate-core-5.4.15.final.jar:5.4.15.final] org.liberate.tool.scheme.internal.schemacreatorimpl.applysqlstring(schemacreatorimpl.cava:439) [liberate-core-5.4.15.final.jar:5.4.15.final] org.liberate.tool.scheme.internal.schemacreatorimpl.applysqlstrings(schemacreatorimpl.cava:423) [liberate-core-5.4.15.final.jar:5.4.15.final] org.liberate.tool.scheme.internal.schemacreatorimpl.createfrommetadata(schemacreatorimpl.cava:314) [liberate-core-5.4.15.final.jar:5.4.15.final] org.liberate.tool.scheme.internal.schemacreatorimpl.performcreation(schemacreatorimpl.cava:166) [liberate-core-5.4.15.final.jar:5.4.15.final] org.liberate.tool.scheme.internal.schemacreatorimpl.creation(schemacreatorimpl.cava:135) [liberate-core-5.4.15.final.jar:5.4.15.final] org.liberate.tool.scheme.internal.schemacreatorimpl.creation(schemacreatorimpl.cava:121) [liberate-core-5.4.15.final.jar:5.4.15.final] org.liberate.tool.scheme.spy.schemamanagementtoolcoordinator.performdatabaseaction(schemamanagementtoolcoordinator.cava:156) [liberate-core-5.4.15.final.jar:5.4.15.final] org.liberate.tool.scheme.spy.schemamanagementtoolcoordinator.process(schemamanagementtoolcoordinator.cava:73) [liberate-core-5.4.15.final.jar:5.4.15.final] org.liberate.internal.sessionfactoryimpl.&it;knit&it;(sessionfactoryimpl.cava:314) [liberate-core-5.4.15.final.jar:5.4.15.final] org.liberate.boot.internal.sessionfactorybuilderimpl.build(sessionfactorybuilderimpl.cava:468) [liberate-core-5.4.15.final.jar:5.4.15.final] org.liberate.pa.boot.internal.entitymanagerfactorybuilderimpl.build(entitymanagerfactorybuilderimpl.cava:1249) [liberate-core-5.4.15.final.jar:5.4.15.final] org.springframework.or.pa.vendor.springhibernatejpapersistenceprovider.createcontainerentitymanagerfactory(springhibernatejpapersistenceprovider.cava:58) [spring-or-5.2.6.release.jar:5.2.6.release] org.springframework.or.pa.localcontainerentitymanagerfactorybean.createnativeentitymanagerfactory(localcontainerentitymanagerfactorybean.cava:365) [spring-or-5.2.6.release.jar:5.2.6.release] org.springframework.or.pa.abstractentitymanagerfactorybean.buildnativeentitymanagerfactory(abstractentitymanagerfactorybean.cava:391) [spring-or-5.2.6.release.jar:5.2.6.release] cava.until.concurrent.futuretask.run(futuretask.cava:266) ~[na:1.8.0_252] cava.until.concurrent.threadpoolexecutor.runworker(threadpoolexecutor.cava:1149) ~[na:1.8.0_252] cava.until.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.cava:624) ~[na:1.8.0_252] cava.long.thread.run(thread.cava:748) ~[na:1.8.0_252] cause by: org.postgresql.until.psqlexception: error: error de santa sur ou pre de « user » post : 14 org.postgresql.core.ve.queryexecutorimpl.receiveerrorresponse(queryexecutorimpl.cava:2533) ~[postgresql-42.2.12.jar:42.2.12] org.postgresql.core.ve.queryexecutorimpl.processresults(queryexecutorimpl.cava:2268) ~[postgresql-42.2.12.jar:42.2.12] org.postgresql.core.ve.queryexecutorimpl.execute(queryexecutorimpl.cava:313) ~[postgresql-42.2.12.jar:42.2.12] org.postgresql.job.statement.executeinternal(statement.cava:448) ~[postgresql-42.2.12.jar:42.2.12] org.postgresql.job.statement.execute(statement.cava:369) ~[postgresql-42.2.12.jar:42.2.12] org.postgresql.job.statement.executewithflags(statement.cava:310) ~[postgresql-42.2.12.jar:42.2.12] org.postgresql.job.statement.executecachedsql(statement.cava:296) ~[postgresql-42.2.12.jar:42.2.12] org.postgresql.job.statement.executewithflags(statement.cava:273) ~[postgresql-42.2.12.jar:42.2.12] org.postgresql.job.statement.execute(statement.cava:268) ~[postgresql-42.2.12.jar:42.2.12] com.baxter.kari.pool.proxystatement.execute(proxystatement.cava:95) ~[hikaricp-3.4.5.jar:na] com.baxter.kari.pool.hikariproxystatement.execute(hikariproxystatement.cava) ~[hikaricp-3.4.5.jar:na] org.liberate.tool.scheme.internal.even.generationtargettodatabase.accept(generationtargettodatabase.cava:54) ~[liberate-core-5.4.15.final.jar:5.4.15.final] ... 18 common frame omit howe change name class e.g. person @entity @noargsconstructor @data @allargsconstructor @builder public class person { @id @generatedvalue(strategic = generationtype.identity) privat long id; privat string surname; privat string email; privat string firstname; privat string lastname; privat in age; } get errors. could someone help follow way least explain wrong entity class user. would also like add doubt test code myself alter postgresql got errors."
