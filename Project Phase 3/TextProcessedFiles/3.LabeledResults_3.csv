QuestionId,QuestionTitle,QuestionBody,QuestionTags,QuestionBodyLength,URLImageCount,LOC,UserReputation,UserGoldBadges,UserSilverBadges,UserBronzeBadges,QuestionAcceptRate,QuestionViewCount,QuestionFavoriteCount,UserUpVoteCount,QuestionAnswersCount,QuestionScore,QuestionCreationDate,FirstAnswerCreationDate,AcceptedAnswerCreationDate,FirstAnswerIntervalDays,AcceptedAnswerIntervalDays,QuestionLabel,QuestionLabelDefinition
51916630,MongoDB mongoose Deprecation Warning,"While querying the documents by using collection.find I started getting following warning in my console
  DeprecationWarning: collection.find option [fields] is deprecated and
  will be removed in a later version
Why am I seeing this and how do I fix this? (Possible alternatives)
EDIT: Query Added
Session
        .find({ sessionCode: '18JANMON', completed: false })
        .limit(10)
        .sort({time: 1})
        .select({time: 1, sessionCode: 1});
Mongoose version 5.2.9
",<javascript><node.js><mongodb><mongoose><nosql>,479,0,6,4537,11,46,83,58,42623,0.0,512,14,44,2018-08-19 10:14,2018-08-19 14:43,2018-08-19 14:43,0.0,0.0,Advanced,38
54601529,Efficiently mapping one-to-many many-to-many database to struct in Golang,"Question
When dealing with a one-to-many or many-to-many SQL relationship in Golang, what is the best (efficient, recommended, ""Go-like"") way of mapping the rows to a struct?
Taking the example setup below I have tried to detail some approaches with Pros and Cons of each but was wondering what the community recommends.
Requirements
Works with PostgreSQL (can be generic but not include MySQL/Oracle specific features)
Efficiency - No brute forcing every combination
No ORM - Ideally using only database/sql and jmoiron/sqlx
Example
For sake of clarity I have removed error handling
Models
type Tag struct {
  ID int
  Name string
}
type Item struct {
  ID int
  Tags []Tag
}
Database
CREATE TABLE item (
  id                      INT GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY
);
CREATE TABLE tag (
  id                      INT GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
  name                    VARCHAR(160),
  item_id                 INT REFERENCES item(id)
);
Approach 1 - Select all Items, then select tags per item
var items []Item
sqlxdb.Select(&amp;items, ""SELECT * FROM item"")
for i, item := range items {
  var tags []Tag
  sqlxdb.Select(&amp;tags, ""SELECT * FROM tag WHERE item_id = $1"", item.ID)
  items[i].Tags = tags
}
Pros
Simple
Easy to understand
Cons
Inefficient with the number of database queries increasing proportional with number of items
Approach 2 - Construct SQL join and loop through rows manually
var itemTags = make(map[int][]Tag)
var items = []Item{}
rows, _ := sqlxdb.Queryx(""SELECT i.id, t.id, t.name FROM item AS i JOIN tag AS t ON t.item_id = i.id"")
for rows.Next() {
  var (
    itemID  int
    tagID   int
    tagName string
  )
  rows.Scan(&amp;itemID, &amp;tagID, &amp;tagName)
  if tags, ok := itemTags[itemID]; ok {
    itemTags[itemID] = append(tags, Tag{ID: tagID, Name: tagName,})
  } else {
    itemTags[itemID] = []Tag{Tag{ID: tagID, Name: tagName,}}
  }
}
for itemID, tags := range itemTags {
  items = append(Item{
    ID: itemID,
    Tags: tags,
  })
}
Pros
A single database call and cursor that can be looped through without eating too much memory
Cons
Complicated and harder to develop with multiple joins and many attributes on the struct
Not too performant; more memory usage and processing time vs. more network calls
Failed approach 3 - sqlx struct scanning
Despite failing I want to include this approach as I find it to be my current aim of efficiency paired with development simplicity. My hope was by explicitly setting the db tag on each struct field sqlx could do some advanced struct scanning 
var items []Item
sqlxdb.Select(&amp;items, ""SELECT i.id AS item_id, t.id AS tag_id, t.name AS tag_name FROM item AS i JOIN tag AS t ON t.item_id = i.id"")
Unfortunately this errors out as missing destination name tag_id in *[]Item leading me to believe the StructScan is not advanced enough to recursively loop through rows (no criticism - it is a complicated scenario)
Possible approach 4 - PostgreSQL array aggregators and GROUP BY
While I am sure this will not work I have included this untested option to see if it could be improved upon so it may work.
var items = []Item{}
sqlxdb.Select(&amp;items, ""SELECT i.id as item_id, array_agg(t.*) as tags FROM item AS i JOIN tag AS t ON t.item_id = i.id GROUP BY i.id"")
When I have some time I will try and run some experiments here. 
",<sql><go><struct><sqlx>,3346,0,60,14702,6,48,62,53,18469,0.0,65,5,44,2019-02-08 23:17,2019-02-09 21:31,2019-02-10 9:26,1.0,2.0,Intermediate,22
53975234,Instance of 'SQLAlchemy' has no 'Column' member (no-member),"I'm currently trying to implement steam login into website. But I'm unable to get pass this error within the code. I've created the database object but it keeps showing the error I mentioned earlier. I'm not sure whether SQLAlchemy has changed or what since I used it.
from flask import Flask
from flask_sqlalchemy import SQLAlchemy
app = Flask(__name__)
db = SQLAlchemy(app)
class User(db.Model):
    id = db.Column(db.Integer, primary_key=True)
The message emitted by pylint is
E1101: Instance of 'SQLAlchemy' has no 'Column' member (no-member)
",<python><python-3.x><flask><sqlalchemy><pylint>,547,0,10,535,1,5,8,75,42567,0.0,0,6,43,2018-12-30 4:15,2019-02-28 14:45,,60.0,,Basic,13
51933421,System.Data.SQLite vs Microsoft.Data.Sqlite,"What are the differences between System.Data.SQLite and Microsoft.Data.Sqlite?
I understand that System.Data.SQLite is older and got .NETStandard support after Microsoft.Data.Sqlite, but now both of them support .NETStandard 2.
What are the advantages of one over the other?
",<.net><sqlite><system.data.sqlite>,275,0,0,601,1,5,11,49,21127,0.0,5,4,43,2018-08-20 14:54,2018-08-26 10:57,2018-08-26 10:57,6.0,6.0,Intermediate,19
49984267,java.sql.SQLException: Unknown system variable 'query_cache_size',"I have a app running with JDBC and get data from MySQL, but I can't build it because of this error : 
java.sql.SQLException: Unknown system variable 'query_cache_size'
at com.mysql.jdbc.SQLError.createSQLException(SQLError.java:964) ~[mysql-connector-java-5.1.41.jar:5.1.41]
    at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:3973) ~[mysql-connector-java-5.1.41.jar:5.1.41]
    at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:3909) ~[mysql-connector-java-5.1.41.jar:5.1.41]
    at com.mysql.jdbc.MysqlIO.sendCommand(MysqlIO.java:2527) ~[mysql-connector-java-5.1.41.jar:5.1.41]
    at com.mysql.jdbc.MysqlIO.sqlQueryDirect(MysqlIO.java:2680) ~[mysql-connector-java-5.1.41.jar:5.1.41]
    at com.mysql.jdbc.ConnectionImpl.execSQL(ConnectionImpl.java:2497) ~[mysql-connector-java-5.1.41.jar:5.1.41]
    at com.mysql.jdbc.ConnectionImpl.execSQL(ConnectionImpl.java:2455) ~[mysql-connector-java-5.1.41.jar:5.1.41]
    at com.mysql.jdbc.StatementImpl.executeQuery(StatementImpl.java:1369) ~[mysql-connector-java-5.1.41.jar:5.1.41]
    at com.mysql.jdbc.ConnectionImpl.loadServerVariables(ConnectionImpl.java:3777) ~[mysql-connector-java-5.1.41.jar:5.1.41]
    at com.mysql.jdbc.ConnectionImpl.initializePropsFromServer(ConnectionImpl.java:3240) ~[mysql-connector-java-5.1.41.jar:5.1.41]
    at com.mysql.jdbc.ConnectionImpl.connectOneTryOnly(ConnectionImpl.java:2249) ~[mysql-connector-java-5.1.41.jar:5.1.41]
    at com.mysql.jdbc.ConnectionImpl.createNewIO(ConnectionImpl.java:2035) ~[mysql-connector-java-5.1.41.jar:5.1.41]
    at com.mysql.jdbc.ConnectionImpl.&lt;init&gt;(ConnectionImpl.java:790) ~[mysql-connector-java-5.1.41.jar:5.1.41]
    at com.mysql.jdbc.JDBC4Connection.&lt;init&gt;(JDBC4Connection.java:47) ~[mysql-connector-java-5.1.41.jar:5.1.41]
    at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) ~[na:1.8.0_131]
I have file application.properties here 
#specs.dir=/specs/
#
#################### Spring Boot Data Source Configuration ############
#spring.datasource.driver-class-name=com.mysql.jdbc.Driver
#spring.datasource.url=jdbc:mysql://localhost:3306/savingbooking?useSSL=false
#spring.datasource.username=root
#spring.datasource.password=ZAQ!2wsx
#spring.datasource.initialize=true
#spring.jpa.hibernate.ddl-auto=update
#spring.jpa.properties.hibernate.format_sql=true
#spring.jpa.show-sql=true
#spring.jpa.properties.hibernate.dialect=org.hibernate.dialect.MySQLDialect
Mysql workbench is 8.0 version
",<java><mysql><spring-boot><jdbc>,2462,0,28,347,1,5,16,62,80235,0.0,48,11,43,2018-04-23 15:04,2018-04-23 15:10,2018-04-23 15:10,0.0,0.0,Basic,13
50409788,MySQL 8 create new user with password not working,"I am using MySQL for several years and the command for the creating the new user till the MySQL 5.x version is as follow:
GRANT ALL PRIVILEGES ON *.* TO 'username'@'localhost' IDENTIFIED BY 'password';
Recently I installed the MySQL 8. In that, this command is not working.
It is throwing following error while firing above command:
ERROR 1064 (42000): You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near 'IDENTIFIED BY 'password'' at line 1
Is there any change of syntax in MySQL 8? What is the correct syntax for creating new user command in MySQL 8?
Note: I tried this syntax in MySQL 5.x versions. It is working correctly in that.
",<mysql><sql><database>,717,0,2,2440,2,29,42,42,53618,0.0,1886,2,42,2018-05-18 10:56,2018-05-18 15:11,2018-05-18 15:11,0.0,0.0,Basic,5
50180667,How can I connect to a database as another user?,"Im currently creating an API for a school project and everything is working good. My setup is: Node v10, Postgres, Koa and so on...
I currently have this:
CREATE ROLE sa WITH LOGIN PASSWORD 'some-password.';
CREATE DATABASE master WITH OWNER sa;
\c master;
When the init script runs in the docker machine the output I get is this one:
CREATE ROLE
CREATE DATABASE
You are now connected to database ""master"" as user ""postgres"".
So I did change the file to something like this:
CREATE ROLE sa WITH LOGIN PASSWORD 'some-password.';
CREATE DATABASE master WITH OWNER sa;
CONNECT TO master AS main USER sa;
And I get a syntax error:
STATEMENT:  CONNECT TO master AS sa USER sa;
psql:/docker-entrypoint-initdb.d/init.sql:4: ERROR:  syntax error at or near ""CONNECT""
I can't find anywhere in docs (or haven't look very good) how to connect from a .sql file to a database with an specific user.
How would I connect to 'master' with its owner, which is 'sa' from a .sql file?
",<postgresql><psql>,966,0,11,563,1,5,12,68,101774,0.0,5,4,42,2018-05-04 17:57,2018-05-04 18:45,2018-05-04 18:45,0.0,0.0,Basic,9
48956743,Embedded Postgres for Spring Boot Tests,"I'm building a Spring Boot app, backed by Postgres, using Flyway for database migrations. I've been bumping up against issues where I cannot produce a migration that generates the desired outcome in both Postgres, and the embedded unit test database (even with Postgres compatibility mode enabled). So I am looking at using embedded Postgres for unit tests.
I came across an embedded postgres implementation that looks promising, but don't really see how to set it up to run within Spring Boot's unit test framework only (for testing Spring Data repositories). How would one set this up using the mentioned tool or an alternative embedded version of Postgres?
",<spring><postgresql><spring-boot><flyway>,660,1,0,18871,14,73,102,39,75788,0.0,958,5,42,2018-02-23 21:52,2018-02-23 22:21,2018-02-27 15:11,0.0,4.0,Intermediate,30
51082758,How to explode multiple columns of a dataframe in pyspark,"I have a dataframe which consists lists in columns similar to the following. The length of the lists in all columns is not same.
Name  Age  Subjects                  Grades
[Bob] [16] [Maths,Physics,Chemistry] [A,B,C]
I want to explode the dataframe in such a way that i get the following output-
Name Age Subjects Grades
Bob  16   Maths     A
Bob  16  Physics    B
Bob  16  Chemistry  C
How can I achieve this?
",<python><dataframe><apache-spark><pyspark><apache-spark-sql>,412,0,6,698,3,9,25,58,57601,0.0,19,7,42,2018-06-28 12:19,2018-06-28 12:25,2018-06-28 14:14,0.0,0.0,Basic,9
48629799,Postgres image is not creating database,"According to these docs, I can specify the name of the database created by the postgres docker image with the env var POSTGRES_DB. I have set it in my docker-compose file, but it isn't being created.
Here's relevant section from the compose file:
pg:
    image: postgres:10
    volumes:
      - db-data:/var/lib/postgresql/data
    environment:
      POSTGRES_DB: user-auth
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: postgres
Here are the logs:
Attaching to userauth_pg_1
pg_1   | 2018-02-05 18:05:54.803 UTC [1] LOG:  listening on IPv4 address ""0.0.0.0"", port 5432
pg_1   | 2018-02-05 18:05:54.803 UTC [1] LOG:  listening on IPv6 address ""::"", port 5432
pg_1   | 2018-02-05 18:05:54.806 UTC [1] LOG:  listening on Unix socket ""/var/run/postgresql/.s.PGSQL.5432""
pg_1   | 2018-02-05 18:05:54.817 UTC [24] LOG:  database system was interrupted; last known up at 2018-02-05 18:03:26 UTC
pg_1   | 2018-02-05 18:05:54.942 UTC [24] LOG:  database system was not properly shut down; automatic recovery in progress
pg_1   | 2018-02-05 18:05:54.944 UTC [24] LOG:  redo starts at 0/1633ED0
pg_1   | 2018-02-05 18:05:54.944 UTC [24] LOG:  invalid record length at 0/1633F08: wanted 24, got 0
pg_1   | 2018-02-05 18:05:54.944 UTC [24] LOG:  redo done at 0/1633ED0
pg_1   | 2018-02-05 18:05:54.955 UTC [1] LOG:  database system is ready to accept connections
pg_1   | 2018-02-05 18:05:59.140 UTC [31] FATAL:  database ""user-auth"" does not exist
pg_1   | 2018-02-05 18:06:15.528 UTC [32] FATAL:  database ""user-auth"" does not exist
pg_1   | 2018-02-05 18:08:46.120 UTC [33] FATAL:  database ""user-auth"" does not exist
pg_1   | 2018-02-05 18:08:46.151 UTC [34] FATAL:  database ""user-auth"" does not exist
pg_1   | 2018-02-05 18:14:02.138 UTC [35] FATAL:  database ""user-auth"" does not exist
pg_1   | 2018-02-05 18:14:02.926 UTC [36] FATAL:  database ""user-auth"" does not exist
pg_1   | 2018-02-05 18:14:04.244 UTC [37] FATAL:  database ""user-auth"" does not exist
pg_1   | 2018-02-05 18:14:04.273 UTC [38] FATAL:  database ""user-auth"" does not exist
pg_1   | 2018-02-05 18:14:04.602 UTC [39] FATAL:  database ""user-auth"" does not exist
pg_1   | 2018-02-05 18:14:04.910 UTC [40] FATAL:  database ""user-auth"" does not exist
pg_1   | 2018-02-05 18:14:05.777 UTC [41] FATAL:  database ""user-auth"" does not exist
pg_1   | 2018-02-05 18:14:05.823 UTC [42] FATAL:  database ""user-auth"" does not exist
pg_1   | 2018-02-05 18:14:05.878 UTC [43] FATAL:  database ""user-auth"" does not exist
pg_1   | 2018-02-05 18:14:06.663 UTC [44] FATAL:  database ""user-auth"" does not exist
pg_1   | 2018-02-05 18:14:06.716 UTC [45] FATAL:  database ""user-auth"" does not exist
pg_1   | 2018-02-05 18:16:32.713 UTC [46] FATAL:  database ""user-auth"" does not exist
pg_1   | 2018-02-05 18:47:04.603 UTC [47] FATAL:  database ""user-auth"" does not exist
pg_1   | 2018-02-05 18:51:34.413 UTC [1] LOG:  received smart shutdown request
pg_1   | 2018-02-05 18:51:34.417 UTC [1] LOG:  worker process: logical replication launcher (PID 30) exited with exit code 1
pg_1   | 2018-02-05 18:51:34.419 UTC [25] LOG:  shutting down
pg_1   | 2018-02-05 18:51:34.434 UTC [1] LOG:  database system is shut down
pg_1   | 2018-02-05 19:08:42.934 UTC [1] LOG:  listening on IPv4 address ""0.0.0.0"", port 5432
pg_1   | 2018-02-05 19:08:42.934 UTC [1] LOG:  listening on IPv6 address ""::"", port 5432
pg_1   | 2018-02-05 19:08:42.937 UTC [1] LOG:  listening on Unix socket ""/var/run/postgresql/.s.PGSQL.5432""
pg_1   | 2018-02-05 19:08:42.951 UTC [25] LOG:  database system was shut down at 2018-02-05 18:51:34 UTC
pg_1   | 2018-02-05 19:08:42.956 UTC [1] LOG:  database system is ready to accept connections
pg_1   | 2018-02-05 19:09:04.316 UTC [32] FATAL:  database ""user-auth"" does not exist
pg_1   | 2018-02-05 19:09:18.081 UTC [33] FATAL:  database ""user-auth"" does not exist
",<postgresql><docker>,3825,1,47,2349,2,19,17,36,46297,0.0,490,6,42,2018-02-05 19:11,2019-01-15 13:50,2019-01-15 13:50,344.0,344.0,Basic,14
51121889,Why do we need template0 and template1 in PostgreSQL?,"I'm a beginner in PostgreSQL. I wonder why the \l command in psql shows databases template0 and template1.
I searched the web but unfortunately didn't find the right resources. But I did find that after removing both (template0 &amp; template1) we can't create new databases any more.
",<database><postgresql>,285,0,5,543,1,4,7,45,23198,0.0,0,1,41,2018-07-01 9:05,2018-07-01 11:45,,0.0,,Basic,4
51276703,how to store PostgreSQL jsonb using SpringBoot + JPA?,"I'm working on a migration software that will consume unknown data from REST services.
I already think about use MongoDB but I decide to not use it and use PostgreSQL.
After read this I'm trying to implement it in my SpringBoot app using Spring JPA but I don't know to map jsonb in my entity.
Tried this but understood nothing!
Here is where I am:
@Repository
@Transactional
public interface DnitRepository extends JpaRepository&lt;Dnit, Long&gt; {
    @Query(value = ""insert into dnit(id,data) VALUES (:id,:data)"", nativeQuery = true)
    void insertdata( @Param(""id"")Integer id,@Param(""data"") String data );
}
and ...
@RestController
public class TestController {
    @Autowired
    DnitRepository dnitRepository;  
    @RequestMapping(value = ""/dnit"", method = RequestMethod.GET)
    public String testBig() {
        dnitRepository.insertdata(2, someJsonDataAsString );
    }
}
and the table:
CREATE TABLE public.dnit
(
    id integer NOT NULL,
    data jsonb,
    CONSTRAINT dnit_pkey PRIMARY KEY (id)
)
How can I do this?
Note: I don't want/need an Entity to work on. My JSON will always be String but I need jsonb to query the DB
",<postgresql><spring-boot><spring-data-jpa><jsonb>,1137,2,27,1972,4,28,53,64,108223,0.0,407,5,41,2018-07-11 3:13,2018-07-11 13:28,2018-07-11 13:28,0.0,0.0,Basic,10
54885178,What's the difference between utf8_unicode_ci and utf8mb4_0900_ai_ci,"What is the difference between utf8mb4_0900_ai_ci and utf8_unicode_ci database text coding in mysql (especially in terms of performance) ?
Update:
There are similar differences between utf8mb4_unicode_ci and utf8mb4_0900_ai_ci?
",<mysql><unicode>,228,0,2,86767,31,374,349,77,34302,0.0,7499,1,41,2019-02-26 12:04,2019-03-06 16:16,2019-03-06 16:16,8.0,8.0,Intermediate,19
53149484,error: ALTER TYPE ... ADD cannot run inside a transaction block,"I am trying to add new type value to my existing types in PostgreSQL. But I get the following error
  error: ALTER TYPE ... ADD cannot run inside a transaction block
The query I used to add a new value to the type is 
ALTER TYPE public.request_type ADD VALUE ""Check"";
I am actually running above query in migrations file which is created using node-pg-migrate
Here public is my schema.
Any idea why this is failing?
Edit:
The below query executes fine when execute it in pgadmin
ALTER TYPE public.request_type ADD VALUE ""Check"";
But when I run above command through node-pg-migrate migrations it fails and throws above error
",<postgresql><enums><alter>,625,0,3,32938,39,121,164,69,32890,0.0,1300,7,41,2018-11-05 6:39,2018-11-05 8:18,,0.0,,Basic,10
52789531,"How do I solve «panic: sql: unknown driver ""postgres"" (forgotten import?)»?","I'm trying to INSERT data into POSTGRES from a .csv (pre-fixed width / tabular ) with GO.
What I've done:
package main
import (
    ""bufio""
    ""database/sql""
    ""encoding/csv""
    ""encoding/json""
    ""fmt""
    ""io""
    ""log""
    ""os""
)
type Consumidor struct {
    CPF string   `json:""CPF""`
    Private  string   `json:""Private""`
    Incompleto  string   `json:""Incompleto""`
    Compras   *Compras `json:""Compras,omitempty""`
}
type Compras struct {
    DataUltimacompra  string `json:""DataUltimacompra""`
    TicketMedio string `json:""TicketMedio""`
    TicketUltimaCompra string `json:""TicketUltimaCompra""`
    LojaMaisFrequente string `json:""LojaMaisFrequente""`
    LojaUltimaCompra string `json:""LojaUltimaCompra""`
}
const (
    host     = ""localhost""
    port     = 5432
    user     = ""postgres""
    password = """"
    dbname   = ""neoway""
)
func main() {
    csvFile, _ := os.Open(""data.csv"")
    reader := csv.NewReader(bufio.NewReader(csvFile))
    var dadosinsert []Consumidor
    for {
        line, error := reader.Read()
        if error == io.EOF {
            break
        } else if error != nil {
            log.Fatal(error)
        }
        dadosinsert = append(dadosinsert, Consumidor{
            CPF: line[0],
            Private:  line[1],
            Incompleto: line[2],
            Compras: &amp;Compras{
                DataUltimacompra:  line[3],
                TicketMedio:  line[4],
                TicketUltimaCompra: line[5],
                LojaMaisFrequente:  line[6],
                LojaUltimaCompra: line[7],
            },
        })
    }
    peopleJson, _ := json.Marshal(dadosinsert)
    fmt.Println(string(peopleJson))
    psqlInfo := fmt.Sprintf(""host=%s port=%d user=%s ""+
        ""password=%s dbname=%s sslmode=disable"",
        host, port, user, password, dbname)
    db, err := sql.Open(""postgres"", psqlInfo)
    if err != nil {
        panic(err)
    }
    defer db.Close()
    sqlStatement := `
INSERT INTO base_teste (CPF,""PRIVATE"",""INCOMPLETO"",""DATA DA ÚLTIMA COMPRA"",""TICKET MÉDIO"",""TICKET DA ÚLTIMA COMPRA"",""LOJA MAIS FREQUÊNTE"",""LOJA DA ÚLTIMA COMPRA"")
)
VALUES ($1, $2, $3, $4, $5, $6, 7$, 8$)
RETURNING id`
    id := 0
    err = db.QueryRow(sqlStatement, 30, ""a"", ""b"", ""c"").Scan(&amp;id)
    if err != nil {
        panic(err)
    }
    fmt.Println(""New record ID is:"", id)
}
when I run, I get this error
  [{""CPF"":""xxxxx"",""Private"":""TRUE"",""Incompleto"":""FALSE"",""Compras"":{""DataUltimacompra"":""12/10/2018"",""TicketMedio"":""200"",""TicketUltimaCompra"":""250"",""LojaMaisFrequente"":""111.111.111-99"",""LojaUltimaCompra"":""111.111.111-88""}}]
  panic: sql: unknown driver ""postgres"" (forgotten import?)
  goroutine 1 [running]: main.main()    C:/Users/Willian/Desktop/NEOWAY
  PROJECT/neoway csv prefixed width importer/main.go:70 +0xbed
  Process finished with exit code 2
",<postgresql><go>,2813,0,85,411,1,4,3,65,50141,0.0,0,1,41,2018-10-13 4:29,2018-10-13 10:23,,0.0,,Basic,7
48477861,"Laravel: String data, right truncated: 1406 Data too long for column","I have a table with a column 'hotel'. The project is created in Laravel 5.4, so I used Migrations.
$table-&gt;string('hotel', 50);
This is MYSQL VARCHAR (50). It was working good, because when I was developing I used short hotel names like &quot;HILTON NEW YORK 5&quot;*.
Now the project is on production and customer asked why they can't input long hotel names. I've tested it with such a mock hotel name as &quot;Long long long long long long long long long and very-very-very long hotel name 5 stars&quot;
It gave me an error:
&quot;SQLSTATE[22001]: String data, right truncated: 1406 Data too long for
column 'hotel' at row 1&quot;
I've opened database in my Sequel Pro and changed it
first to VARCHAR (255)
then to TEXT
After each change I tested it with the same &quot;Long long long long long long long long long and very-very-very long hotel name 5 starts&quot; and get the same error (see above).
I've checked the type of column with
SHOW FIELDS FROM table_name
and it gave me
Field | Type
hotel | text
so the type of the field is 'text' indeed  (65 535 characters).
Maybe it's somehow connected with Laravel Migration file (see above) where I set VARCHAR (50) in the beginning? But I can't re-run migration on production, because the table has data now.
Would appreciate any help.
UPDATE:
I discovered that it actually saves that long hotel name in the DB. But user still gets this annoying mistake every time after submitting the form...
",<php><mysql><laravel><text><types>,1449,0,2,1922,3,25,43,64,140378,0.0,207,12,41,2018-01-27 16:26,2018-01-27 16:29,2018-01-27 16:29,0.0,0.0,Basic,9
51119248,Electron app with database,"I'm creating a web app for ticket reservation. The only problem is the database. I don't want to tell my client to install XAMPP or set a database, etc. 
Is there any way to package the app with the database? 
",<javascript><sql><node.js><database><electron>,210,0,0,720,2,7,9,44,39844,0.0,5,1,41,2018-06-30 23:18,2018-07-01 1:12,2018-07-01 1:12,1.0,1.0,Intermediate,20
54149272,Equivalent of ON CONFLICT DO NOTHING for UPDATE postgres,"I want to update rows in my postgres database if the updated version wouldn't violate the primary key constraint. If it would, I want to leave the row as it is.
Assuming the table has primary keys on col1, col2, col3, if I run a query like this:
UPDATE table SET (col1, col2) = ('A', 'B') 
      WHERE col1='D' AND col2='E';
The query will fail and I will get a duplicate key error if there exists two entries:
'A', 'B', 'C'
'D', 'E', 'C'
i.e col3 is the same between an existing row and a row to be updated.
If I was INSERTing rows I would use ON CONFLICT DO NOTHING but I can't find an implementation of this for UPDATE. Does an equivalent exist?
",<sql><postgresql><sql-update><subquery><sql-insert>,649,0,9,909,1,7,20,77,50575,0.0,130,2,41,2019-01-11 15:15,2019-01-11 16:14,2019-01-11 17:12,0.0,0.0,Basic,9
53673763,"Azure Storage Emulator fails to init with ""The database 'AzureStorageEmulatorDb57' does not exist""","I am having an issue with Azure Storage Emulator. I tried to re-initialise the database and got the error below. 
This was after installing Visual Studio 2019 Preview but this may just be a co-incidence. I tried for an hour or so to get it running and then gave up and just  reset my machine with the ""keep my files"" option, re-installed Visual Studio 2017 and the Azure Tools but still see the same problem.  
I know a reset sounds a bit drastic but VS 2019 broke my Azure Functions in VS2017, they would not launch so I wanted a clean install. 
If I manually create the DB with sqllocaldb create (version 13.1.4001.0), the DB gets created fine but the init still fails with the same message.
Any ideas?
  C:\Program Files (x86)\Microsoft SDKs\Azure\Storage
  Emulator>AzureStorageEmulator.exe init
      Windows Azure Storage Emulator 5.7.0.0 command line tool
      Found SQL Instance (localdb)\MSSQLLocalDB.
      Creating database AzureStorageEmulatorDb57 on SQL instance '(localdb)\MSSQLLocalDB'.
      Cannot create database 'AzureStorageEmulatorDb57' : The database 'AzureStorageEmulatorDb57' does not exist. Supply a valid database
  name. To see available databases, use sys.databases..
      One or more initialization actions have failed. Resolve these errors before attempting to run the storage emulator again.
      Error: Cannot create database 'AzureStorageEmulatorDb57' : The database 'AzureStorageEmulatorDb57' does not exist. Supply a valid
  database name. To see available databases, use sys.databases..
",<azure-storage><sql-server-express><azure-storage-emulator>,1526,0,0,12970,7,60,87,54,15885,0.0,311,17,40,2018-12-07 16:51,2018-12-12 9:18,,5.0,,Basic,9
50372487,"Android Room database file is empty - .db, .db-shm, .db-wal","Using room in android for database. When I tried to see the data in sqlviewer then no tables found in database file
Myapp.db file is empty.
Data/data/packageName/databases/Myapp.db
",<android><sql><android-room>,181,0,0,1304,2,10,22,58,20934,0.0,40,5,40,2018-05-16 13:39,2018-05-28 13:56,2018-05-28 13:56,12.0,12.0,Basic,9
50014017,Why Presto is faster than Spark SQL,"Why is Presto faster than Spark SQL? 
Besides what is the difference between Presto and Spark SQL in computing architectures and memory management?
",<apache-spark-sql><presto>,148,0,0,1097,2,11,16,48,31727,0.0,10,3,40,2018-04-25 4:20,2018-04-26 17:41,2018-04-26 19:56,1.0,1.0,Intermediate,23
57595926,Could not import package. Warning SQL72012: The object exists in the target,"I exported my Azure database using Tasks > Export Data-tier Application in to a .bacpac file. Recently when I tried to import it into my local database server (Tasks > Import Data-tier Application), I encountered this error:
Could not import package.
Warning SQL72012: The object [MyDatabase_Data] exists in the target, but it will not be dropped even though you selected the 'Generate drop statements for objects that are in the target database but that are not in the source' check box.
Warning SQL72012: The object [MyDatabase_Log] exists in the target, but it will not be dropped even though you selected the 'Generate drop statements for objects that are in the target database but that are not in the source' check box.
Error SQL72014: .Net SqlClient Data Provider: Msg 12824, Level 16, State 1, Line 5 The sp_configure value 'contained database authentication' must be set to 1 in order to alter a contained database.  You may need to use RECONFIGURE to set the value_in_use.
Error SQL72045: Script execution error.  The executed script:
IF EXISTS (SELECT 1
           FROM   [master].[dbo].[sysdatabases]
           WHERE  [name] = N'$(DatabaseName)')
    BEGIN
        ALTER DATABASE [$(DatabaseName)]
            SET CONTAINMENT = PARTIAL 
            WITH ROLLBACK IMMEDIATE;
    END
Error SQL72014: .Net SqlClient Data Provider: Msg 5069, Level 16, State 1, Line 5 ALTER DATABASE statement failed.
Error SQL72045: Script execution error.  The executed script:
IF EXISTS (SELECT 1
           FROM   [master].[dbo].[sysdatabases]
           WHERE  [name] = N'$(DatabaseName)')
    BEGIN
        ALTER DATABASE [$(DatabaseName)]
            SET CONTAINMENT = PARTIAL 
            WITH ROLLBACK IMMEDIATE;
    END
 (Microsoft.SqlServer.Dac)
I followed the advice on other posts and tried to run this on SQL Azure database:
sp_configure 'contained database authentication', 1;  
GO  
RECONFIGURE;  
GO
However, it says 
Could not find stored procedure 'sp_configure'.
I understand the equivalent statement in Azure is: 
https://learn.microsoft.com/en-us/sql/t-sql/statements/alter-database-scoped-configuration-transact-sql?view=sql-server-2017
What is the equivalent statement to ""sp_configure 'contained database authentication', 1;""?
",<sql-server><azure-sql-database>,2244,2,32,1741,1,15,27,40,25251,0.0,120,4,40,2019-08-21 16:34,2019-08-22 1:20,,1.0,,Basic,2
48184300,"When I run test cases I get this error: psycopg2.OperationalError: cursor ""_django_curs_140351416325888_23"" does not exist","I'm trying to run test cases, but I get below error.
Run command : python manage.py test
Type 'yes' if you would like to try deleting the test database 'test_project_management_db', or 'no' to cancel: yes
Destroying old test database for alias 'default'...
Traceback (most recent call last):
  File &quot;manage.py&quot;, line 24, in &lt;module&gt;
    execute_from_command_line(sys.argv)
  File &quot;/home/rails/Desktop/projects/envs/project_manage_env/local/lib/python2.7/site-packages/django/core/management/__init__.py&quot;, line 363, in execute_from_command_line
    utility.execute()
  File &quot;/home/rails/Desktop/projects/envs/project_manage_env/local/lib/python2.7/site-packages/django/core/management/__init__.py&quot;, line 355, in execute
    self.fetch_command(subcommand).run_from_argv(self.argv)
  File &quot;/home/rails/Desktop/projects/envs/project_manage_env/local/lib/python2.7/site-packages/django/core/management/commands/test.py&quot;, line 29, in run_from_argv
    super(Command, self).run_from_argv(argv)
  File &quot;/home/rails/Desktop/projects/envs/project_manage_env/local/lib/python2.7/site-packages/django/core/management/base.py&quot;, line 283, in run_from_argv
    self.execute(*args, **cmd_options)
  File &quot;/home/rails/Desktop/projects/envs/project_manage_env/local/lib/python2.7/site-packages/django/core/management/base.py&quot;, line 330, in execute
    output = self.handle(*args, **options)
  File &quot;/home/rails/Desktop/projects/envs/project_manage_env/local/lib/python2.7/site-packages/django/core/management/commands/test.py&quot;, line 62, in handle
    failures = test_runner.run_tests(test_labels)
  File &quot;/home/rails/Desktop/projects/envs/project_manage_env/local/lib/python2.7/site-packages/django/test/runner.py&quot;, line 601, in run_tests
    old_config = self.setup_databases()
  File &quot;/home/rails/Desktop/projects/envs/project_manage_env/local/lib/python2.7/site-packages/django/test/runner.py&quot;, line 546, in setup_databases
    self.parallel, **kwargs
  File &quot;/home/rails/Desktop/projects/envs/project_manage_env/local/lib/python2.7/site-packages/django/test/utils.py&quot;, line 187, in setup_databases
    serialize=connection.settings_dict.get('TEST', {}).get('SERIALIZE', True),
  File &quot;/home/rails/Desktop/projects/envs/project_manage_env/local/lib/python2.7/site-packages/django/db/backends/base/creation.py&quot;, line 77, in create_test_db
    self.connection._test_serialized_contents = self.serialize_db_to_string()
  File &quot;/home/rails/Desktop/projects/envs/project_manage_env/local/lib/python2.7/site-packages/django/db/backends/base/creation.py&quot;, line 121, in serialize_db_to_string
    serializers.serialize(&quot;json&quot;, get_objects(), indent=None, stream=out)
  File &quot;/home/rails/Desktop/projects/envs/project_manage_env/local/lib/python2.7/site-packages/django/core/serializers/__init__.py&quot;, line 129, in serialize
    s.serialize(queryset, **options)
  File &quot;/home/rails/Desktop/projects/envs/project_manage_env/local/lib/python2.7/site-packages/django/core/serializers/base.py&quot;, line 80, in serialize
    for count, obj in enumerate(queryset, start=1):
  File &quot;/home/rails/Desktop/projects/envs/project_manage_env/local/lib/python2.7/site-packages/django/db/backends/base/creation.py&quot;, line 117, in get_objects
    for obj in queryset.iterator():
  File &quot;/home/rails/Desktop/projects/envs/project_manage_env/local/lib/python2.7/site-packages/django/db/models/query.py&quot;, line 53, in __iter__
    results = compiler.execute_sql(chunked_fetch=self.chunked_fetch)
  File &quot;/home/rails/Desktop/projects/envs/project_manage_env/local/lib/python2.7/site-packages/django/db/models/sql/compiler.py&quot;, line 880, in execute_sql
    cursor.close()
psycopg2.OperationalError: cursor &quot;_django_curs_140351416325888_23&quot; does not exist
",<python><django><postgresql><django-tests>,3900,0,40,513,1,4,7,40,16924,0.0,4,4,40,2018-01-10 9:37,2018-03-19 15:18,,68.0,,Basic,13
50603953,How to add 'created_at' and 'updated_at' columns?,"I need to add 'updated_at' and 'created_at' columns to some already existing table in MySQL database. I've added those colums using MySQL Workbench, but what query should I use to make them work properly? Thanks in advance ;)
",<mysql><sql><database>,226,0,0,471,1,6,12,73,108844,0.0,19,2,40,2018-05-30 11:50,2018-05-30 11:57,2018-05-30 11:57,0.0,0.0,Basic,9
49796452,WampServer - mysqld.exe can't start because MSVCR120.dll is missing,"I've tried to run wampserver on my local side, but mysql server doesn't run. 
when I try to install service, it give me error. I searched the answer all day and found some answers on here and there.
but any solution doesn't work for me. I tried to install warpserver on windows7 home OS vmware
Any help for me?
",<mysql><wordpress><windows-7><vmware><wampserver>,311,0,0,943,1,8,19,53,147725,0.0,9,9,39,2018-04-12 12:23,2018-04-12 12:27,2018-04-12 15:11,0.0,0.0,Basic,14
53735305,How to rename a column name in maria DB,"I am new to SQL, I was trying to change column name in my database's table. I am using 'xampp' with 'maria DB' (OS - Ubuntu 18.04)  
I tried all of the followings:  
ALTER TABLE subject RENAME COLUMN course_number TO course_id;
ALTER TABLE subject CHANGE course_number course_id;
ALTER TABLE subject CHANGE 'course_number' 'course_id';
ALTER TABLE subject  CHANGE COLUMN 'course_number'  course_id varchar(255);
ALTER TABLE subject CHANGE 'course_number' 'course_id' varchar(255);
But the only output I got was:  
  ERROR 1064 (42000): You have an error in your SQL syntax; check the manual that corresponds to your MariaDB server version for the right syntax to use near 'column course_number to course_id' at line 1  
Could someone please tell me what is the correct answer. I have no idea what to do further.
",<mysql><mariadb><rename><alter>,812,0,5,515,1,4,10,66,47244,0.0,59,4,39,2018-12-12 2:40,2018-12-16 4:32,2018-12-16 4:32,4.0,4.0,Basic,10
51014647,"AWS Postgres DB ""does not exist"" when connecting with PG","I can't seem to connect to my DB instance in AWS. I'm using the pg package and following the examples from the website is not working.
A search for ""aws postgres database does not exist"" really isn't returning anything helpful. Going through the open/closed issues on the PG github isnt helpful either.
Running $nc &lt;RDS endpoint&gt; &lt;port number&gt; returns a success message so it's definitely there. Every value placed in the Client config is copy/pasted from my DB instance.
I'm starting to wonder if the databases have a different name than what it shows in the ""Instances"" section of RDS on AWS?
const client = new Client({
  host     : '&lt;&lt;RDS ENDPOINT&gt;&gt;',
  database : '&lt;&lt;RDS NAME&gt;&gt;', // maybe this isnt the real name?
  user     : '&lt;&lt;username&gt;&gt;',
  password : '&lt;&lt;password&gt;&gt;',
  port     : &lt;&lt;port&gt;&gt;
});
client.connect()
  .then(data =&gt; {
    console.log('connected');
  })
  .catch(err =&gt; {
    console.log(err);
  })
",<postgresql><amazon-web-services><amazon-rds>,996,1,16,1564,1,21,37,44,16680,0.0,838,7,39,2018-06-24 23:03,2020-01-19 2:19,,574.0,,Basic,10
48102295,Rename column only if exists,"PostgreSQL does not allow 
ALTER TABLE t RENAME COLUMN IF EXISTS c1 TO c2
...or anything like that.  However, it's very convenient to be able to write scripts which modify DB structure which can be run again without first checking if it has already been run.
How do I write a PostgreSQL function to do exactly this?
",<postgresql><ddl><alter-table>,316,0,1,765,1,6,15,55,42429,0.0,63,5,39,2018-01-04 19:33,2018-01-06 17:52,2019-11-20 12:13,2.0,685.0,Basic,9
48128714,How to make an Inner Join in django?,"I want to show in an Html the name of the city, state, and country of a publication. But they are in different tables.
Here is my models.py
class country(models.Model):
    country_name = models.CharField(max_length=200, null=True)
    country_subdomain = models.CharField(max_length=3, null=True)
    def __str__(self):
        return self.country_name
class countrystate(models.Model):
    state_name = models.CharField(max_length=200, null=True)
    country = models.ForeignKey(country, on_delete=models.CASCADE, null=True)
    importance = models.IntegerField(null=True)
    def __str__(self):
        return self.state_name
class city(models.Model):
    city_name = models.CharField(max_length=200, null=True)
    countrystate = models.ForeignKey(countrystate, on_delete=models.CASCADE, null=True)
    def __str__(self):
        return self.city_name
class publication(models.Model):
    user = ForeignKey(users, on_delete=models.CASCADE, null=False)
    title= models.CharField(max_length=300, null=True)
    country=models.ForeignKey(country, on_delete=models.CASCADE, null=True)
    countrystate=models.ForeignKey(countrystate, on_delete=models.CASCADE, null=True)
    city=models.ForeignKey(city, on_delete=models.CASCADE, null=True)
    def __str__(self):
        return self.title
Here is my views.py
def publications(request):
    mypublications = publication.objects.filter(user_id=request.session['account_id'])
    dic.update({""plist"": mypublications })
    return render(request, 'blog/mypublications.html', dic)
In a django view, what is the equivalent of the next sql query?
SELECT p.user_id, p.title, c.cuntry_id, c.country_name, s.state_id, s.state_name, y.city_id, y.city_name FROM publication AS p
INNER JOIN country AS c ON c.id = p.country_id
INNER JOIN countrystate AS s ON s.id = p.countrystate_id
INNER JOIN city AS y ON y.id = p.city_id
",<python><mysql><django><orm><inner-join>,1865,0,36,1341,8,34,57,64,95825,0.0,61,5,39,2018-01-06 15:17,2018-01-06 15:29,2018-01-06 15:29,0.0,0.0,Basic,10
60409585,How to upgrade postgresql database from 10 to 12 without losing data for openproject,"My OpenProject management software is installed with default postgresql 10.
Currently the postgresql DB is 12, It is having lot of new features.
I want to upgrade my Postgres DB without losing the data in the DB.
My system is ubuntu 18.04 and hosted  openproject.
I searched the internet and could not find a step by step to upgrade postgresql.
Can you please guide me to install new DB and all data should be in the new DB.
thanks for your help.
",<postgresql><ubuntu-18.04><openproject>,447,0,0,859,3,14,22,45,73377,0.0,13,4,39,2020-02-26 8:22,2020-04-14 13:11,2020-06-04 15:55,48.0,99.0,Basic,14
49776619,sqlalchemy.exc.ArgumentError: Could not parse rfc1738 URL from string,"I'm learning flask web microframework and after initialization of my database I run flask db init I run flask db migrate, to migrate my models classes to the database and i got an error.  I work on Windows 10, the database is MySQL, and extensions install are flask-migrate, flask-sqlalchemy, flask-login.
(env) λ flask db migrate
Traceback (most recent call last):
  File ""c:\python36\Lib\runpy.py"", line 193, in _run_module_as_main
    ""__main__"", mod_spec)
  File ""c:\python36\Lib\runpy.py"", line 85, in _run_code
    exec(code, run_globals)
  File ""C:\Users\aka\Dev\dream-team\env\Scripts\flask.exe\__main__.py"", line 9, in &lt;module&gt;
  File ""c:\users\aka\dev\dream-team\env\lib\site-packages\flask\cli.py"", line 513, in main
    cli.main(args=args, prog_name=name)
  File ""c:\users\aka\dev\dream-team\env\lib\site-packages\flask\cli.py"", line 380, in main
    return AppGroup.main(self, *args, **kwargs)
  File ""c:\users\aka\dev\dream-team\env\lib\site-packages\click\core.py"", line 697, in main
    rv = self.invoke(ctx)
  File ""c:\users\aka\dev\dream-team\env\lib\site-packages\click\core.py"", line 1066, in invoke
    return _process_result(sub_ctx.command.invoke(sub_ctx))
  File ""c:\users\aka\dev\dream-team\env\lib\site-packages\click\core.py"", line 1066, in invoke
    return _process_result(sub_ctx.command.invoke(sub_ctx))
  File ""c:\users\aka\dev\dream-team\env\lib\site-packages\click\core.py"", line 895, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File ""c:\users\aka\dev\dream-team\env\lib\site-packages\click\core.py"", line 535, in invoke
    return callback(*args, **kwargs)
  File ""c:\users\aka\dev\dream-team\env\lib\site-packages\click\decorators.py"", line 17, in new_func
    return f(get_current_context(), *args, **kwargs)
  File ""c:\users\aka\dev\dream-team\env\lib\site-packages\flask\cli.py"", line 257, in decorator
    return __ctx.invoke(f, *args, **kwargs)
  File ""c:\users\aka\dev\dream-team\env\lib\site-packages\click\core.py"", line 535, in invoke
    return callback(*args, **kwargs)
  File ""c:\users\aka\dev\dream-team\env\lib\site-packages\flask_migrate\cli.py"", line 90, in migrate
    rev_id, x_arg)
  File ""c:\users\aka\dev\dream-team\env\lib\site-packages\flask_migrate\__init__.py"", line 197, in migrate
    version_path=version_path, rev_id=rev_id)
  File ""c:\users\aka\dev\dream-team\env\lib\site-packages\alembic\command.py"", line 176, in revision
    script_directory.run_env()
  File ""c:\users\aka\dev\dream-team\env\lib\site-packages\alembic\script\base.py"", line 427, in run_env
    util.load_python_file(self.dir, 'env.py')
  File ""c:\users\aka\dev\dream-team\env\lib\site-packages\alembic\util\pyfiles.py"", line 81, in load_python_file
    module = load_module_py(module_id, path)
  File ""c:\users\aka\dev\dream-team\env\lib\site-packages\alembic\util\compat.py"", line 83, in load_module_py
    spec.loader.exec_module(module)
  File ""&lt;frozen importlib._bootstrap_external&gt;"", line 678, in exec_module
  File ""&lt;frozen importlib._bootstrap&gt;"", line 219, in _call_with_frames_removed
  File ""migrations\env.py"", line 87, in &lt;module&gt;
    run_migrations_online()
  File ""migrations\env.py"", line 70, in run_migrations_online
    poolclass=pool.NullPool)
  File ""c:\users\aka\dev\dream-team\env\lib\site-packages\sqlalchemy\engine\__init__.py"", line 465, in engine_from_config
    return create_engine(url, **options)
  File ""c:\users\aka\dev\dream-team\env\lib\site-packages\sqlalchemy\engine\__init__.py"", line 424, in create_engine
    return strategy.create(*args, **kwargs)
  File ""c:\users\aka\dev\dream-team\env\lib\site-packages\sqlalchemy\engine\strategies.py"", line 50, in create
    u = url.make_url(name_or_url)
  File ""c:\users\aka\dev\dream-team\env\lib\site-packages\sqlalchemy\engine\url.py"", line 211, in make_url
    return _parse_rfc1738_args(name_or_url)
  File ""c:\users\aka\dev\dream-team\env\lib\site-packages\sqlalchemy\engine\url.py"", line 270, in _parse_rfc1738_args
    ""Could not parse rfc1738 URL from string '%s'"" % name)
sqlalchemy.exc.ArgumentError: Could not parse rfc1738 URL from string 'mysql/dt_admin:dt2016@localhost/dreamteam_db'
",<python><flask><flask-sqlalchemy><flask-login><flask-migrate>,4154,0,61,473,1,4,8,65,109734,0.0,2,6,38,2018-04-11 13:36,2018-04-12 15:46,,1.0,,Basic,14
50166869,Connect to SQL Server in local machine (host) from docker using host.docker.internal,"I'm trying to connect to my SQL Server instance running in my local computer using host.docker.internal (as recommended in https://docs.docker.com/docker-for-windows/networking/#use-cases-and-workarounds)
The host.docker.internal is successfully resolved to an IP, and it's ping-able
And I've opened up the port 1433 in my firewall configuration
Error message
  Connection refused 192.168.65.2:1433
My connection string
  Data Source=host.docker.internal,1433;Initial Catalog=;Persist Security Info=False;User ID=;Password=;MultipleActiveResultSets=True;Encrypt=True;TrustServerCertificate=False;Connection Timeout=30;
docker version
Client:
 Version:      18.03.1-ce
 API version:  1.37
 Go version:   go1.9.5
 Git commit:   9ee9f40
 Built:        Thu Apr 26 07:12:48 2018
 OS/Arch:      windows/amd64
 Experimental: false
 Orchestrator: swarm
Server:
 Engine:
  Version:      18.03.1-ce
  API version:  1.37 (minimum version 1.12)
  Go version:   go1.9.5
  Git commit:   9ee9f40
  Built:        Thu Apr 26 07:22:38 2018
  OS/Arch:      linux/amd64
  Experimental: true
Docker for windows version
",<sql-server><docker><docker-networking><docker-for-windows>,1098,3,21,4765,1,18,31,71,27103,0.0,463,1,38,2018-05-04 3:49,2018-05-04 8:11,2018-05-04 8:11,0.0,0.0,Basic,14
51292905,"Flask app with ArcGIS, Arcpy does not run","I have a script that gets a table from MSSQL database and then registers it with ArcGIS. It uses several other arcpy methods as well. I tried to combine it with Flask and developed an HTML interface where you can specify tables. The script runs on console perfectly well, however, when running with Flask on http://127.0.0.1:5000/ , the arcpy functions do not run, then the app throws errors.
I am using my local python directory, so I do not have any problem with importing arcpy on flask. So, I am able to use pymssql functions and create a new table, however when it comes to arcpy function, It throws does not exist error, however, the table exists. I feel like there is something wrong with running arcpy with Flask, but any help would be appreciated.
(2) I tried the same thing in Django but I am having the same problem.
Thanks
forms.py
class createGISLayer(FlaskForm):
    tCreateLayer = SubmitField('Create GIS Layer')
DashboardMain()
   try:
        cursor.execute(QueryCreate)
        print (""Table Created."")
        print(self.dbTablePath)
        descTable = arcpy.Describe(self.dbTablePath)
    except arcpy.ExecuteError:
        print(arcpy.GetMessages())
app.py
if formCreate.tCreateLayer.data and formCreate.validate_on_submit():
    if myLayer is not None:
        try:
            print(""Create GIS Layer"")
            myLayer.dashboardMain()
            flash('GIS Layer created!', 'success')
        except Exception as e:
            print(e.message)
            flash(e.message, 'danger')
index.html
&lt;!-- Create GIS Layer  --&gt;
&lt;div class=""content-section""&gt;
&lt;form name='idCreateGISLayer' action="""" method=""POST""&gt;
&lt;table style=""height: auto; margin-left: auto; margin-right: auto; width: 600px;""&gt;
&lt;tbody&gt;
&lt;tr&gt;
    {{ formCreate.hidden_tag() }}
    &lt;td style=""height: 39px; width: 259px""&gt;
        &lt;h2 style=""text-align: left;""&gt;&lt;font size=""3""&gt;&lt;strong&gt;(2) Create &lt;/strong&gt;&lt;/font&gt;&lt;/h2&gt;
    &lt;/td&gt;
    &lt;td style=""text-align: left; height: 39px;""&gt;
        &lt;div class=""auto-style2""&gt;                                                                
            {{ formCreate.tCreateLayer(class=""btn btn-outline-info"")}}
        &lt;/div&gt;
    &lt;/td&gt;
 &lt;/tr&gt;
 &lt;/tbody&gt;
 &lt;/table&gt;
 &lt;/form&gt;
 &lt;/div&gt;
ERROR
Table Created.
F:\Projects\Dashboard\Publish.sde\Publish.dbo.A_WebT1
""F:\Projects\Dashboard\Publish.sde\Publish.dbo.A_WebT1"" does not exist
screenshot
",<python><flask><arcpy><pymssql>,2496,3,43,634,0,5,9,62,1695,0.0,47,3,38,2018-07-11 19:26,2018-07-17 10:26,,6.0,,Basic,14
59330286,postgres: Index on a timestamp field,"I'm new to postgres and I have a question about the timestamp type.
To set the scene, I have a table like the one below:
CREATE TABLE IF NOT EXISTS tbl_example (
    example_id bigint not null,
    example_name text,
    example_timestamp timestamp,
    primary key (example_id)
);
Now I want to run a query to find me the list of examples based on a specific date, using the timestamp.
For example, the common query that will always be run is:
SELECT example_id, example_name, example_timestamp
 WHERE example_timestamp = date_trunc('datepart', example_timestamp)
 ORDER BY example_timestamp DESC;
However, to speed up the search process I was thinking of adding an index to the example_timestamp field:
CREATE INDEX idx_example_timestamp
          ON tbl_example (example_timestamp);
My question, is how does postgres perform the index on the timestamp - in other words will it  index the timestamp based on the date/ time, or will it go into the seconds/ milliseconds, etc?
Alternatively I was thinking of creating a new column with 'example_date' and indexing on this column instead to simplify things. I wasn't keen on having both a date and a timestamp field as I could get the date from the timestamp field, but for index purposes i thought maybe it might be best to create a separate field.
If anyone has any thoughts on this that would be appreciated?
",<postgresql><jpa-2.0><postgresql-9.4>,1361,0,11,1099,3,20,32,55,59707,0.0,1,3,38,2019-12-13 21:55,2019-12-13 22:48,,0.0,,Intermediate,23
58763542,"PG::InvalidParameterValue: ERROR: invalid value for parameter ""client_min_messages"": ""panic""","rake db:create showing error PG::InvalidParameterValue: ERROR:  invalid value for parameter ""client_min_messages"": ""panic""
HINT:  Available values: debug5, debug4, debug3, debug2, debug1, log, notice, warning, error. 
After bundle install tried to run rake db:create commond.
Created database.yml file inside the config folder please find below :
development:
  adapter: postgresql
  encoding: utf8
  database: thor_development1
  username: postgres
  password:
  host: localhost
test:
  adapter: postgresql
  encoding: utf8
  database: thor_test1
  username: postgres
  password:
  host: localhost
PG::InvalidParameterValue: ERROR:  invalid value for parameter ""client_min_messages"": ""panic""
HINT:  Available values: debug5, debug4, debug3, debug2, debug1, log, notice, warning, error.
: SET client_min_messages TO 'panic'
/Users/galaxy/.rvm/gems/ruby-2.1.2@folderName/gems/activerecord-4.1.6/lib/active_record/connection_adapters/postgresql/database_statements.rb:128:in `async_exec'
/Users/galaxy/.rvm/gems/ruby-2.1.2@folderName/gems/activerecord-4.1.6/lib/active_record/connection_adapters/postgresql/database_statements.rb:128:in `block in execute'
/Users/galaxy/.rvm/gems/ruby-2.1.2@folderName/gems/activerecord-4.1.6/lib/active_record/connection_adapters/abstract_adapter.rb:373:in `block in log'
/Users/galaxy/.rvm/gems/ruby-2.1.2@folderName/gems/activesupport-4.1.6/lib/active_support/notifications/instrumenter.rb:20:in `instrument'
/Users/galaxy/.rvm/gems/ruby-2.1.2@folderName/gems/activerecord-4.1.6/lib/active_record/connection_adapters/abstract_adapter.rb:367:in `log'
/Users/galaxy/.rvm/gems/ruby-2.1.2@folderName/gems/activerecord-4.1.6/lib/active_record/connection_adapters/postgresql/database_statements.rb:127:in `execute'
/Users/galaxy/.rvm/gems/ruby-2.1.2@folderName/gems/activerecord-4.1.6/lib/active_record/connection_adapters/postgresql/schema_statements.rb:274:in `client_min_messages='
/Users/galaxy/.rvm/gems/ruby-2.1.2@folderName/gems/activerecord-4.1.6/lib/active_record/connection_adapters/postgresql_adapter.rb:634:in `set_standard_conforming_strings'
/Users/galaxy/.rvm/gems/ruby-2.1.2@folderName/gems/activerecord-4.1.6/lib/active_record/connection_adapters/postgresql_adapter.rb:914:in `configure_connection'
/Users/galaxy/.rvm/gems/ruby-2.1.2@folderName/gems/activerecord-4.1.6/lib/active_record/connection_adapters/postgresql_adapter.rb:895:in `connect'
/Users/galaxy/.rvm/gems/ruby-2.1.2@folderName/gems/activerecord-4.1.6/lib/active_record/connection_adapters/postgresql_adapter.rb:568:in `initialize'
Trying to install in macOS Catalina
",<ruby-on-rails><ruby><postgresql><activerecord><rubygems>,2577,0,29,377,1,3,6,57,19545,0.0,0,10,38,2019-11-08 9:12,2019-11-15 20:16,,7.0,,Basic,14
62584640,Suggested way to run multiple sql statements in python?,"What would be the suggested way to run something like the following in python:
self.cursor.execute('SET FOREIGN_KEY_CHECKS=0; DROP TABLE IF EXISTS %s; SET FOREIGN_KEY_CHECKS=1' % (table_name,))
For example, should this be three separate self.cursor.execute(...) statements? Is there a specific method that should be used other than cursor.execute(...) to do something like this, or what is the suggested practice for doing this? Currently the code I have is as follows:
self.cursor.execute('SET FOREIGN_KEY_CHECKS=0;')
self.cursor.execute('DROP TABLE IF EXISTS %s;' % (table_name,))
self.cursor.execute('SET FOREIGN_KEY_CHECKS=1;')
self.cursor.execute('CREATE TABLE %s select * from mytable;' % (table_name,))
As you can see, everything is run separately...so I'm not sure if this is a good idea or not (or rather -- what the best way to do the above is). Perhaps BEGIN...END ?
",<python><mysql><mysql-python>,878,0,8,106276,181,504,871,75,50801,0.0,3486,9,38,2020-06-25 21:31,2020-06-28 7:37,2020-07-04 19:27,3.0,9.0,Basic,5
51614140,How to disable column-statistics in MySQL 8 permanently?,"Since MySQL 8 the column-statistics flag is enabled by default.
So if you try to dump some tables with MySQL Workbench 8.0.12, you get this error message:
  14:50:22 Dumping db (table_name)
  Running: mysqldump.exe --defaults-file=""c:\users\username\appdata\local\temp\tmpvu0mxn.cnf""  --user=db_user --host=db_host --protocol=tcp --port=1337 --default-character-set=utf8 --skip-triggers ""db_name"" ""table_name""
  mysqldump: Couldn't execute 'SELECT COLUMN_NAME,                       JSON_EXTRACT(HISTOGRAM, '$.""number-of-buckets-specified""')                FROM information_schema.COLUMN_STATISTICS                WHERE SCHEMA_NAME = 'db_name' AND TABLE_NAME = 'table_name';': Unknown table 'COLUMN_STATISTICS' in information_schema (1109)
  Operation failed with exitcode 2
  14:50:24 Export of C:\path\to\my\dump has finished with 1 errors
Is there any way in MySQL (Workbench) 8 to disable column-statistics permanently?
Workaround 1
An annoying workaround is doing it by hand via:
mysqldump --column-statistics=0 --host=...
Workaround 2
rename mysqldump
create a shell script (or batch on Windows) 
call the renamed mysqldump with the --column-statistics=0 argument within this script
save it as mysqldump
Workaround 3
download MySQL 5.7
extract mysqldump
use this mysqldump
For example in MySQL Workbench: Edit / Preferences... / Administration / Path to mysqldump Tool
Thanks in advance!
",<mysql><mysql-workbench><mysql-8.0>,1394,0,4,1200,4,12,25,71,51386,0.0,782,14,37,2018-07-31 13:07,2018-08-01 9:10,,1.0,,Intermediate,18
63109987,NameError: name '_mysql' is not defined after setting change to mysql,"I have a running Django blog with sqlite3 db at my local machine. What I want is to
convert sqlite3 db to mysql db
change Django settings.py file to serve MySQL db
Before I ran into the first step, I jumped into the second first. I followed this web page (on MacOS). I created databases called djangolocaldb on root user and have those infos in /etc/mysql/my.cnf like this:
# /etc/mysql/my.cnf
[client]
database=djangolocaldb
user=root
password=ROOTPASSWORD
default-character-set=utf8
Of course I created db, but not table within it.
mysql&gt; show databases;
+--------------------+
| Database           |
+--------------------+
| djangolocaldb      |
| employees          |
| information_schema |
| mydatabase         |
| mysql              |
| performance_schema |
| sys                |
+--------------------+
7 rows in set (0.00 sec)
I changed settings.py like this as the web page suggested. Here's how:
# settings.py
...
# Database
# https://docs.djangoproject.com/en/3.0/ref/settings/#databases
DATABASES = {
        'default': {
            'ENGINE': 'django.db.backends.mysql',
            #'NAME': os.path.join(BASE_DIR, 'db.sqlite3'),
            'OPTIONS' : {
                'read_default_file': '/etc/mysql/my.cnf',
                }
            }
        }
...
Now, when I run python manage.py runserver with my venv activated, I got a brutal traceback like this(I ran python manage.py migrate first, and the traceback looked almost the same anyway):
(.venv) ➜  django-local-blog git:(master) ✗ python manage.py runserver
Watching for file changes with StatReloader
Exception in thread django-main-thread:
Traceback (most recent call last):
  File &quot;/Users/gwanghyeongim/Documents/py/coreyMS_pj/django-local-blog/.venv/lib/python3.7/site-packages/MySQLdb/__init__.py&quot;, line 18, in &lt;module&gt;
    from . import _mysql
ImportError: dlopen(/Users/gwanghyeongim/Documents/py/coreyMS_pj/django-local-blog/.venv/lib/python3.7/site-packages/MySQLdb/_mysql.cpython-37m-darwin.so, 2): Library not loaded: @rpath/libmysqlclient.21.dylib
  Referenced from: /Users/gwanghyeongim/Documents/py/coreyMS_pj/django-local-blog/.venv/lib/python3.7/site-packages/MySQLdb/_mysql.cpython-37m-darwin.so
  Reason: image not found
During handling of the above exception, another exception occurred:
Traceback (most recent call last):
  File &quot;/Users/gwanghyeongim/.pyenv/versions/3.7.6/lib/python3.7/threading.py&quot;, line 926, in _bootstrap_inner
    self.run()
  File &quot;/Users/gwanghyeongim/.pyenv/versions/3.7.6/lib/python3.7/threading.py&quot;, line 870, in run
    self._target(*self._args, **self._kwargs)
  File &quot;/Users/gwanghyeongim/Documents/py/coreyMS_pj/django-local-blog/.venv/lib/python3.7/site-packages/django/utils/autoreload.py&quot;, line 53, in wrapper
    fn(*args, **kwargs)
  File &quot;/Users/gwanghyeongim/Documents/py/coreyMS_pj/django-local-blog/.venv/lib/python3.7/site-packages/django/core/management/commands/runserver.py&quot;, line 109, in inner_run
    autoreload.raise_last_exception()
  File &quot;/Users/gwanghyeongim/Documents/py/coreyMS_pj/django-local-blog/.venv/lib/python3.7/site-packages/django/utils/autoreload.py&quot;, line 76, in raise_last_exception
    raise _exception[1]
  File &quot;/Users/gwanghyeongim/Documents/py/coreyMS_pj/django-local-blog/.venv/lib/python3.7/site-packages/django/core/management/__init__.py&quot;, line 357, in execute
    autoreload.check_errors(django.setup)()
  File &quot;/Users/gwanghyeongim/Documents/py/coreyMS_pj/django-local-blog/.venv/lib/python3.7/site-packages/django/utils/autoreload.py&quot;, line 53, in wrapper
    fn(*args, **kwargs)
  File &quot;/Users/gwanghyeongim/Documents/py/coreyMS_pj/django-local-blog/.venv/lib/python3.7/site-packages/django/__init__.py&quot;, line 24, in setup
    apps.populate(settings.INSTALLED_APPS)
  File &quot;/Users/gwanghyeongim/Documents/py/coreyMS_pj/django-local-blog/.venv/lib/python3.7/site-packages/django/apps/registry.py&quot;, line 114, in populate
    app_config.import_models()
  File &quot;/Users/gwanghyeongim/Documents/py/coreyMS_pj/django-local-blog/.venv/lib/python3.7/site-packages/django/apps/config.py&quot;, line 211, in import_models
    self.models_module = import_module(models_module_name)
  File &quot;/Users/gwanghyeongim/.pyenv/versions/3.7.6/lib/python3.7/importlib/__init__.py&quot;, line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 1006, in _gcd_import
  File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 983, in _find_and_load
  File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 967, in _find_and_load_unlocked
  File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 677, in _load_unlocked
  File &quot;&lt;frozen importlib._bootstrap_external&gt;&quot;, line 728, in exec_module
  File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 219, in _call_with_frames_removed
  File &quot;/Users/gwanghyeongim/Documents/py/coreyMS_pj/django-local-blog/.venv/lib/python3.7/site-packages/django/contrib/auth/models.py&quot;, line 2, in &lt;module&gt;
    from django.contrib.auth.base_user import AbstractBaseUser, BaseUserManager
  File &quot;/Users/gwanghyeongim/Documents/py/coreyMS_pj/django-local-blog/.venv/lib/python3.7/site-packages/django/contrib/auth/base_user.py&quot;, line 47, in &lt;module&gt;
    class AbstractBaseUser(models.Model):
  File &quot;/Users/gwanghyeongim/Documents/py/coreyMS_pj/django-local-blog/.venv/lib/python3.7/site-packages/django/db/models/base.py&quot;, line 121, in __new__
    new_class.add_to_class('_meta', Options(meta, app_label))
  File &quot;/Users/gwanghyeongim/Documents/py/coreyMS_pj/django-local-blog/.venv/lib/python3.7/site-packages/django/db/models/base.py&quot;, line 325, in add_to_class
    value.contribute_to_class(cls, name)
  File &quot;/Users/gwanghyeongim/Documents/py/coreyMS_pj/django-local-blog/.venv/lib/python3.7/site-packages/django/db/models/options.py&quot;, line 208, in contribute_to_class
    self.db_table = truncate_name(self.db_table, connection.ops.max_name_length())
  File &quot;/Users/gwanghyeongim/Documents/py/coreyMS_pj/django-local-blog/.venv/lib/python3.7/site-packages/django/db/__init__.py&quot;, line 28, in __getattr__
    return getattr(connections[DEFAULT_DB_ALIAS], item)
  File &quot;/Users/gwanghyeongim/Documents/py/coreyMS_pj/django-local-blog/.venv/lib/python3.7/site-packages/django/db/utils.py&quot;, line 207, in __getitem__
    backend = load_backend(db['ENGINE'])
  File &quot;/Users/gwanghyeongim/Documents/py/coreyMS_pj/django-local-blog/.venv/lib/python3.7/site-packages/django/db/utils.py&quot;, line 111, in load_backend
    return import_module('%s.base' % backend_name)
  File &quot;/Users/gwanghyeongim/.pyenv/versions/3.7.6/lib/python3.7/importlib/__init__.py&quot;, line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File &quot;/Users/gwanghyeongim/Documents/py/coreyMS_pj/django-local-blog/.venv/lib/python3.7/site-packages/django/db/backends/mysql/base.py&quot;, line 16, in &lt;module&gt;
    import MySQLdb as Database
  File &quot;/Users/gwanghyeongim/Documents/py/coreyMS_pj/django-local-blog/.venv/lib/python3.7/site-packages/MySQLdb/__init__.py&quot;, line 24, in &lt;module&gt;
    version_info, _mysql.version_info, _mysql.__file__
NameError: name '_mysql' is not defined
So this NameError: name '_mysql' is not defined is the problem. I installed mysqlclient before, changed settings.py, made db in mysql, but none of the steps made it any helpful yet.
And I noticed that even I changed my settings.py back to sqlite3, my blog spit the same _mysql not defined error. So I ended up reverting my commit and now I'm back to sqlite3 (at least my blog is running with it).
I'm guessing it could be that I didn't convert data first, but I'm not 100% sure of it.
Any suggestion?
",<python><mysql><django><database><sqlite>,7935,2,112,1410,4,13,33,59,85864,0.0,1911,25,37,2020-07-27 6:44,2020-07-27 12:37,2020-07-27 12:37,0.0,0.0,Basic,13
48835309,Django nested transactions - “with transaction.atomic()” -- Seeking Clarification,"In Django nested transactions - “with transaction.atomic()” the question is, given this...
def functionA():
    with transaction.atomic():
        #save something
        functionB()
def functionB():
    with transaction.atomic():
        #save another thing
If functionB fails and rolls back, does functionA roll back too?
Kevin Christopher Henry replies with, ""Yes, if an exception happens in either function they will both be rolled back."" He then quotes the docs, which state:
  atomic blocks can be nested. In this case, when an inner block completes successfully, its effects can still be rolled back if an exception is raised in the outer block at a later point.
This documentation quote doesn't seem to address the original question. The doc is saying that when the INNER BLOCK (which is functionB) completes successfully, its effects can still be rolled back if the OUTER block (which is functionA) raises an exception. But the question refers to the opposite scenario. The question asks, if the INNER block (functionB)  FAILS, is the OUTER block (functionA) rolled back? This doc quote doesn't address that scenario.
However, further down in the doc we see this example...
from django.db import IntegrityError, transaction
@transaction.atomic
def viewfunc(request):
    create_parent()
    try:
        with transaction.atomic():
            generate_relationships()
    except IntegrityError:
        handle_exception()
    add_children()
...followed by this commentary...
  In this example, even if generate_relationships() causes a database error by breaking an integrity constraint, you can execute queries in add_children(), and the changes from create_parent() are still there.
If I'm reading the doc correctly it's saying the call to generate_relationships() (which is analogous to the call to functionB in the original question) can FAIL and the changes made in create_parent() and add_children() will be committed to the database. This seems to contradict Kevin Christopher Henry's answer.
What's puzzling to me is that I see the same question/answer in Django nested Transaction.atomic.
I'm new to both Django and stackoverflow, so I don't have a lot of confidence in my reading of the doc, but it seems to contradict both of these responses. I'm looking for some clarification from someone more experienced. Thanks you so much.
",<sql><django><transactions>,2349,3,33,473,0,4,6,66,6688,0.0,5,2,37,2018-02-16 21:45,2018-02-16 22:18,2018-02-17 0:00,0.0,1.0,Basic,13
50708608,Oracle SQLDeveloper on MacOS won't open after installation of correct Java,"I downloaded the Oracle SQLDeveloper, but when I opened it, it said that it requires a minimum of Java 8 and gave me the website for the download. I went on and downloaded Java 10.0.1, but when I went back on to open SQL, it continued saying it required a minimum of Java 8.
I checked that the Java 10.0.1 had installed correctly, and I'm pretty sure it has. It shows up in System Preferences and when clicked, it opens the Java Control Panel fine.
I'm on a MacOS X El Captain 10.11.6.
",<java><oracle><macos><java-8><oracle-sqldeveloper>,486,0,0,371,1,3,3,72,77033,0.0,0,17,37,2018-06-05 20:41,2018-06-05 20:54,,0.0,,Basic,14
64635617,How to set a nullable database field to NULL with typeorm?,"This seems like such a simple question to answer, but finding an answer for this seems impossible.
I am building a password reset feature for a backend application with Express and Typescript. I am using Postgres for the database and Typeorm for data manipulation. I have a User entity with these two columns in my database:
@Column({
    unique: true,
    nullable: true,
})
resetPasswordToken!: string;
@Column({ nullable: true, type: 'timestamp with time zone' })
resetPasswordExpiresAt!: Date;
When a user requests a password reset token the resetPasswordToken and resetPasswordExpiresAt fields get both filled with the desired values. With the token that was sent to the user's e-mail address, the user can reset his/her password. After the user's password is reset, I want to clear these two fields by setting them to null:
user.resetPasswordToken = null;
user.resetPasswordExpiresAt = null;
user.save()
But if I do this Typescript complains about the two lines where I assign the null value:
Type 'null' is not assignable to type 'string'.
and
Type 'null' is not assignable to type 'Date'.
If I change the columns in my entity to accept null like below, the errors disappear:
resetPasswordToken!: string | null;
...
resetPasswordExpiresAt!: Date | null;
But when I start my Express application I get the following error when Typeorm tries  to connect to my database:
Data type &quot;Object&quot; in &quot;User.resetPasswordToken&quot; is not supported by &quot;postgres&quot; database.
How do I set these fields to null?
",<typescript><postgresql><express><typeorm>,1528,0,14,1297,1,10,15,41,67258,0.0,37,5,37,2020-11-01 18:44,2020-11-02 11:35,2020-11-02 11:35,1.0,1.0,Basic,9
49931541,MySQL changing authentication type from standard to caching_sha2_password,"I've setup a new MySQL instance on a computer and every time I add a user it sets the Authentication Type to caching_sha2_password. 
This happens even if I set the Authentication Type to ""Standard"", it then changes it when I save the user. I've also changed the default authentication plug in to ""mysql_native_password"", but it still keeps doing it. 
With it using the caching_sha2_password I can't connect to the database from .net core as I get an error stating:
  MySqlException: Authentication method 'caching_sha2_password' not supported by any of the available plugins
How do I get it to save users with the Standard authentication type?
",<mysql><mysql-workbench>,644,0,4,1135,4,13,22,54,110665,0.0,17,6,37,2018-04-19 23:07,2018-04-20 12:06,2018-04-20 12:06,1.0,1.0,Basic,9
53183023,Android Room Exceptions,"What kinds of exceptions I should consider while working with Android Room.
From my research I found out that there is only one exception that might occur.
Room Exceptions
That is also when you are having Single&lt;T&gt; as a return type and you have an empty return. Other than that I couldn't find any other possible scenario that might throw an exception.
Of course, there might be some exceptions if you have some logical incorrect implementations, like
Editing scheme, but not implementing Migration
Not implementing OnConflictStrategy while inserting
Running Room on Main Thread while not allowing it with allowMainThreadQueries()
I did some research and tried out almost all possible cases, mostly with RxJava return types and I saw one exception mentioned above and that's it.
  Here is my tests that I run
I wanted to make sure that I have implementation for every possible scenario and not have some exception and unexpected crashes. I was thinking of occurrences of SQLite exceptions might happen, but I believe it's wrapped around Room and it will handle. (Not sure)
Can you give any other possible exceptions that might occur?
",<android><sqlite><rx-java><reactive-programming><android-room>,1140,2,5,6522,3,36,66,48,3904,0.0,164,1,37,2018-11-07 2:58,2023-10-05 13:20,,1793.0,,Basic,9
50987119,Backup Room database,"I'm trying to backup a room database programmatically.
For that, I'm simply copying the .sqlite file that contains the whole database
But, before copying, due to the fact that room has write ahead logging enabled, we must close the database so that -shm file and -wal file merge into a single .sqlite file. As pointed out here
I run .close() on RoomDatabase object: 
Everything works fine with the backup, BUT, later on, when I try to execute an INSERT query, I get this error: 
android.database.sqlite.SQLiteException: no such table: room_table_modification_log (code 1)
How can I properly re-open room db after I close it?
PS: .isOpen() on RoomDatabase object returns true before INSERT
Room version: 1.1.1-rc1
",<android><sqlite><android-room><sqliteopenhelper><android-architecture-components>,713,2,13,1022,1,12,24,50,16982,0.0,224,7,37,2018-06-22 11:39,2018-07-27 14:30,2018-07-27 14:30,35.0,35.0,Basic,9
52320576,In MySQL SERVER 8.0 the PASSWORD function not working,"Error while executing the PASSWORD function in MySQL Server version 8.0.12
I have the following query:
SELECT * 
FROM users 
WHERE login = 'FABIO' 
  AND pwd = PASSWORD('2018') 
LIMIT 0, 50000
I am getting this error:
  Error Code: 1064. You have an error in your SQL syntax; check the
  manual that corresponds to your MySQL server version for the right
  syntax to use near
",<mysql><mysql-8.0>,376,0,6,499,1,4,11,36,41276,0.0,19,4,37,2018-09-13 19:30,2018-09-13 19:38,2018-09-13 19:38,0.0,0.0,Basic,2
49963383,"""Authentication plugin 'caching_sha2_password'","I'm new to MySql environment and installed :
MySQL with the following commands:
sudo apt-get update
sudo apt-get install mysql-server
mysql_secure_installation
and also installed mysql workbench.
But when I'm trying to connect my localhost getting the follow error:
&quot;Authentication plugin 'caching_sha2_password' cannot be loaded: /usr/lib/mysql/plugin/caching_sha2_password.so: cannot open shared object file: No such file or directory&quot;
and even this is the first time I'm posting a question in stackoverflow, sorry for my presentation errors and syntax.
",<mysql>,566,1,3,373,1,3,8,49,64061,0.0,1,5,37,2018-04-22 7:00,2018-04-25 17:11,,3.0,,Advanced,38
57872910,The LINQ expression could not be translated and will be evaluated locally,"Im getting this WARNING in EntityFramework Core what is wrong?
I already set MSSQL Datebase to Case Sensitive.
Latin1_General_100_CS_AS
var test = await _context.Students
                .FirstOrDefaultAsync(m =&gt; m.LastName.Equals(""ALEXANDER"", StringComparison.InvariantCultureIgnoreCase));
  Microsoft.EntityFrameworkCore.Query:Warning: The LINQ expression
  'where [m].LastName.Equals(""ALEXANDER"", InvariantCultureIgnoreCase)'
  could not be translated and will be evaluated locally.
",<c#><sql-server><entity-framework><linq><entity-framework-core>,489,0,2,371,1,3,6,81,70644,0.0,0,4,37,2019-09-10 14:24,2019-09-10 15:24,,0.0,,Advanced,35
49922023,MYSQL 8.0 - unsupported redo log format,"I have recently updated mysql that was located under my xampp folder, and i've got the following errors, reporting from the log file :
2018-04-19T12:59:19.667059Z 0 [System] [MY-010116] [Server] C:\xampp\mysql\bin\mysqld.exe (mysqld 8.0.11) starting as process 9324
2018-04-19T12:59:20.025280Z 1 [ERROR] [MY-013090] [InnoDB] InnoDB: Unsupported redo log format (0). The redo log was created before MySQL 5.7.9
2018-04-19T12:59:20.026140Z 1 [ERROR] [MY-012930] [InnoDB] InnoDB: Plugin initialization aborted with error Generic error.
2018-04-19T12:59:20.229069Z 1 [ERROR] [MY-011013] [Server] Failed to initialize DD Storage Engine.
2018-04-19T12:59:20.230803Z 0 [ERROR] [MY-010020] [Server] Data Dictionary initialization failed.
2018-04-19T12:59:20.231371Z 0 [ERROR] [MY-010119] [Server] Aborting
2018-04-19T12:59:20.233136Z 0 [System] [MY-010910] [Server] C:\xampp\mysql\bin\mysqld.exe: Shutdown complete (mysqld 8.0.11)  MySQL Community Server - GPL.
I have been told if updating your mysql, you should comment out the deprecated configs that are located in your my.ini, but i had no idea what to comment out, so i left it as it is.
Any idea what causes this?
",<php><mysql><phpmyadmin><xampp>,1163,0,0,445,1,5,10,66,52141,0.0,14,4,36,2018-04-19 13:12,2018-05-17 21:52,2018-05-17 21:52,28.0,28.0,Advanced,38
50838199,Pyspark: Select all columns except particular columns,"I have a large number of columns in a PySpark dataframe, say 200. I want to select all the columns except say 3-4 of the columns. How do I select this columns without having to manually type the names of all the columns I want to select? 
",<python><sql><dataframe><pyspark>,239,0,0,7521,6,36,49,75,65342,0.0,1311,4,36,2018-06-13 13:13,2018-09-04 7:05,2018-09-04 7:05,83.0,83.0,Basic,2
